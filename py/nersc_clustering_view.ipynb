{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import fitsio\n",
    "from pycorr import TwoPointCorrelationFunction, TwoPointEstimator, project_to_multipoles, project_to_wp, utils, setup_logging\n",
    "from scipy.optimize import curve_fit\n",
    "from LSS.common_tools import mknz\n",
    "\n",
    "from dataloc import *\n",
    "\n",
    "# MAKE ALL PLOTS TEXT BIGGER\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# But legend a bit smaller\n",
    "plt.rcParams.update({'legend.fontsize': 12})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## No longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE BINS FOR WP CALCULATION\n",
    "edges = np.geomspace(0.1, 20, 16)\n",
    "\n",
    "# For my own use\n",
    "with open(WP_RADIAL_BINS_DESI_FILE, 'w') as f:\n",
    "    for i in range(len(edges)-1):\n",
    "        f.write(f'{edges[i]:.8f} {edges[i+1]:.8f}\\n')\n",
    "\n",
    "# For xirunpc.py script\n",
    "with open(WP_RADIAL_EDGE_DESI_FILE, 'w') as f:\n",
    "    for i in range(len(edges)):\n",
    "        f.write(f'{edges[i]:.8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cols_for_tbl(path, colname):\n",
    "    if os.path.isfile(path) == False:\n",
    "        print(f'{path} not found')\n",
    "        return\n",
    "    cols = fitsio.FITS(path)[1].get_colnames()\n",
    "    if colname not in cols:\n",
    "        print(f'{colname} not in {path}')\n",
    "    else:\n",
    "        print(f'{colname} found in {path}')\n",
    "    print(cols)\n",
    "check_cols_for_tbl('/dvs_ro/cfs/cdirs/desi/survey/catalogs/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_full_HPmapcut.dat.fits', 'QUIESCENT')\n",
    "check_cols_for_tbl('/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_NGC_clustering.dat.fits', 'QUIESCENT')\n",
    "check_cols_for_tbl('/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_NGC_0_clustering.ran.fits', 'QUIESCENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install corrfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wp_for(tracer, weights, survey, verspec, ver, bins, zmax, nran, njack, quiescent=None):\n",
    "    dir = os.path.join(CUSTOM_CLUSTERING_RESULTS_FOLDER, survey, 'LSS', verspec, 'LSScats', ver, 'rppi')\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        print(\"WARNING: Directory does not exist: \", dir)\n",
    "        return None\n",
    "\n",
    "    if quiescent is not None:\n",
    "        addon = '_QUIESCENT' + ('1' if quiescent else '0')\n",
    "    else:\n",
    "        addon = ''\n",
    "        \n",
    "    wp_fn = os.path.join(dir, f'wp_{tracer}_GCcomb_0.001_{zmax}_{weights}_{bins}_njack{njack}_nran{nran}_split20{addon}.txt')\n",
    "\n",
    "    if not os.path.exists(wp_fn):\n",
    "        print(\"WARNING: File does not exist: \", wp_fn)\n",
    "        return None\n",
    "\n",
    "    return np.loadtxt(wp_fn)\n",
    "\n",
    "def get_fn_for(weights, survey, verspec, ver, zmax, nran, njack, quiescent=None):\n",
    "    dir = os.path.join(CUSTOM_CLUSTERING_RESULTS_FOLDER, survey, 'LSS', verspec, 'LSScats', ver, 'rppi')\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        print(\"WARNING: Directory does not exist: \", dir)\n",
    "        return None\n",
    "\n",
    "    if quiescent is not None:\n",
    "        addon = '_QUIESCENT' + ('1' if quiescent else '0')\n",
    "    else:\n",
    "        addon = ''\n",
    "        \n",
    "    allcounts_fn = os.path.join(dir, f'allcounts_BGS_BRIGHT_GCcomb_0.001_{zmax}_{weights}_custom_njack{njack}_nran{nran}_split20{addon}.npy')\n",
    "    return allcounts_fn\n",
    "    #if not os.path.exists(allcounts_fn):\n",
    "    #    print(\"WARNING: File does not exist: \", allcounts_fn)\n",
    "    #    return None\n",
    "\n",
    "   # return np.load(allcounts_fn, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quiescent = False\n",
    "quiescent = None # False\n",
    "#nran = 18\n",
    "nran = 8\n",
    "#zmax = 0.22620\n",
    "zmax = 0.14977\n",
    "tracer = \"BGS_BRIGHT\" \n",
    "njack = [4, 8, 16, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 192, 256, 512, 1028]\n",
    "jacktest_results = []\n",
    "jacktset_obj = []\n",
    "jacktest_cov = []\n",
    "jacktest_corr = []\n",
    "for nj in njack:\n",
    "    jacktest_results.append(get_wp_for(tracer, 'pip_angular_bitwise', 'Y1', 'iron', 'v1.5pip', 'custom', zmax, nran, nj, quiescent=quiescent))\n",
    "    tpc = TwoPointEstimator.load(get_fn_for('pip_angular_bitwise', 'Y1', 'iron', 'v1.5pip', zmax, nran, nj, quiescent=quiescent))\n",
    "    s, xiell, cov = tpc.get_corr(return_sep=True, return_cov=True, mode='wp')\n",
    "    jacktset_obj.append(tpc)\n",
    "    jacktest_cov.append(cov)\n",
    "\n",
    "for cov in jacktest_cov:    \n",
    "    # ~C_ij = C_ij / sqrt(C_ii C_jj)\n",
    "    jacktest_corr.append(cov / np.sqrt(np.outer(np.diag(cov), np.diag(cov))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how the cov matrix is changing as the njack increases using subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    ii=(i+3)*2\n",
    "    im = axes[i].imshow(jacktest_corr[ii], cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    axes[i].set_title(f\"Corr Matrix (njack={njack[ii]})\")\n",
    "    \n",
    "    # Remvoe bin # labels\n",
    "    axes[i].set_xticks(np.arange(len(jacktest_corr[ii])))\n",
    "    axes[i].set_xticklabels([])\n",
    "    axes[i].set_yticks(np.arange(len(jacktest_corr[ii])))\n",
    "    axes[i].set_yticklabels([])\n",
    "\n",
    "# Create a single colorbar for all subplots\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.87, 0.15, 0.03, 0.7])\n",
    "cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "cbar.set_label('Correlation Coefficient')\n",
    "\n",
    "# Switch from bin numbers to rp values\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE SIGMA OF THE JACKKNIFE TESTS ONLY\n",
    "plt.figure()\n",
    "for i in range(len(jacktest_results)):\n",
    "    if i%2 == 0:\n",
    "        continue\n",
    "    wp = jacktest_results[i]\n",
    "    if wp is not None:\n",
    "        # color 128 one specially\n",
    "        color = 'red' if njack[i] == 64 else [0.0, 1-i/len(njack), 0.0]\n",
    "        plt.plot(wp[:,0], wp[:,3], label=f'njack={njack[i]}', marker='o', color=color)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$r_p$ $[h^{-1} Mpc]$')\n",
    "plt.ylabel(r'$\\sigma_{\\omega_p}$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit the results to a power law\n",
    "def power_law(x, a, b):\n",
    "    return a * x**b\n",
    "\n",
    "rps = jacktest_results[0][:,0] # They are all the same\n",
    "\n",
    "to_fit = jacktest_results[10]\n",
    "popt, pcov = curve_fit(power_law, rps, to_fit[:,2], sigma=to_fit[:,3], absolute_sigma=True)\n",
    "print(popt)\n",
    "\n",
    "# And plot the data and the fit\n",
    "plt.figure()\n",
    "for i in range(len(jacktest_results)):\n",
    "    wp = jacktest_results[i]\n",
    "    if wp is not None:\n",
    "        plt.errorbar(wp[:,0], wp[:,2], yerr=wp[:,3], label=f'njack={njack[i]}', fmt='.', capsize=2)\n",
    "plt.plot(rps, power_law(rps, *popt), label='Fit', linestyle='--')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(r'$w_p(r_p)$')\n",
    "plt.xlabel(r'$r_p$ [Mpc/h]') \n",
    "\n",
    "def chi2(y, yfit, cov):\n",
    "    return np.dot(y-yfit, np.linalg.solve(cov, y-yfit))\n",
    "\n",
    "chi2s = []\n",
    "for i in range(len(jacktest_results)):\n",
    "    wp = jacktest_results[i]\n",
    "    if wp is not None:\n",
    "        chi2s.append(chi2(wp[:,2], power_law(wp[:,0], *popt), jacktest_cov[i]))\n",
    "    else:\n",
    "        chi2s.append(None)\n",
    "\n",
    "# Plot the chi2 values as a function of njack\n",
    "plt.figure()\n",
    "plt.plot(njack[3:], chi2s[3:],  'o', label='Full Covariance')\n",
    "plt.xlabel('njack')\n",
    "plt.ylabel(r'$\\chi^2$')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.ylim(100,250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fit it to a broken power law\n",
    "def broken_power_law(x, a1, b1, a2, b2, x0):\n",
    "    return np.where(x < x0, a1 * x**b1, a2 * x**b2)\n",
    "\n",
    "rps = jacktest_results[0][:,0] # They are all the same\n",
    "\n",
    "to_fit = jacktest_results[10]\n",
    "popt, pcov = curve_fit(broken_power_law, rps, to_fit[:,2], sigma=to_fit[:,3], absolute_sigma=True)\n",
    "print(popt)\n",
    "\n",
    "# And plot the data and the fit\n",
    "plt.figure()\n",
    "for i in range(len(jacktest_results)):\n",
    "    wp = jacktest_results[i]\n",
    "    if wp is not None:\n",
    "        plt.errorbar(wp[:,0], wp[:,2], yerr=wp[:,3], label=f'njack={njack[i]}', fmt='.', capsize=2)\n",
    "plt.plot(rps, broken_power_law(rps, *popt), label='Fit', linestyle='--')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(r'$w_p(r_p)$')\n",
    "plt.xlabel(r'$r_p$ [Mpc/h]')\n",
    "\n",
    "# Calculate chi squared for the fit, using the covariance matrix from each njack test\n",
    "def chi2(y, yfit, cov):\n",
    "    return np.dot(y-yfit, np.linalg.solve(cov, y-yfit))\n",
    "\n",
    "chi2s = []\n",
    "for i in range(len(jacktest_results)):\n",
    "    wp = jacktest_results[i]\n",
    "    if wp is not None:\n",
    "        chi2s.append(chi2(wp[:,2], broken_power_law(wp[:,0], *popt), jacktest_cov[i]))\n",
    "    else:\n",
    "        chi2s.append(None)\n",
    "\n",
    "# Plot the chi2 values as a function of njack\n",
    "plt.figure()\n",
    "plt.plot(njack[3:], chi2s[3:],  'o', label='Full Covariance')\n",
    "plt.xlabel('njack')\n",
    "plt.ylabel(r'$\\chi^2$')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.ylim(100,250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmaxes = [0.06336, 0.09792, 0.14977, 0.22620, 0.33694, 0.49523] \n",
    "magbins = [-17, -18, -19, -20, -21, -22, -23]\n",
    "tracer = \"BGS_BRIGHT\" \n",
    "jack_official = 64\n",
    "red_results = []\n",
    "blue_results = []\n",
    "for z in zmaxes:\n",
    "    red_results.append(get_wp_for(tracer, 'pip_angular_bitwise', 'Y1', 'iron', 'v1.5pip', 'custom', z, 18, jack_official, True)) \n",
    "    blue_results.append(get_wp_for(tracer, 'pip_angular_bitwise', 'Y1', 'iron', 'v1.5pip', 'custom', z, 18, jack_official, False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDSS Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maglim = -22.4\n",
    "zmax = 0.245169\n",
    "zmin = 0.02\n",
    "# Make a luminosity threshold sample like SDSS to see if n(z) is same\n",
    "def make_sdsslike_cuts(fcd, maglim, zmax, zmin):\n",
    "    writename = fcd.replace('.dat.fits', f'_testcut.dat.fits')  \n",
    "    arr = fitsio.read(fcd)\n",
    "    arr = arr[arr['Z'] < zmax]\n",
    "    arr = arr[arr['Z'] > zmin]\n",
    "    arr = arr[arr['ABSMAG_R'] < maglim]\n",
    "    fitsio.write(writename, arr, clobber=True)\n",
    "\n",
    "make_sdsslike_cuts('/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_NGC_clustering.dat.fits', maglim, zmax, zmin)\n",
    "make_sdsslike_cuts('/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_SGC_clustering.dat.fits', maglim, zmax, zmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = '/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_NGC_clustering_testcut.dat.fits'\n",
    "ran = '/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_NGC_0_clustering.ran.fits'\n",
    "outpath = '/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_NGC_FOOTPRINT.txt'\n",
    "mknz(cat, ran, outpath, zmax=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = '/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_SGC_clustering_testcut.dat.fits'\n",
    "ran = '/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_SGC_0_clustering.ran.fits'\n",
    "outpath2 = '/global/cfs/cdirs/desi/users/ianw89/clustering/Y1/LSS/iron/LSScats/v1.5pip/BGS_BRIGHT_SGC_FOOTPRINT.txt'\n",
    "mknz(cat, ran, outpath2, zmax=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmid zlow zhigh n(z) Nbin Vol_bin\n",
    "# zmid zlow zhigh n(z) Nbin Vol_bin\n",
    "NGC_nz = np.loadtxt(outpath)\n",
    "SGC_nz = np.loadtxt(outpath2)\n",
    "\n",
    "# Function to combine the two to get an overall density, appropiatly weighting each by volume\n",
    "def combine_nz(nz1, nz2):\n",
    "    combined = np.zeros((len(nz1), 6))\n",
    "    combined[:,0] = nz1[:,0]\n",
    "    combined[:,1] = nz1[:,1]\n",
    "    combined[:,2] = nz1[:,2]\n",
    "    combined[:,4] = nz1[:,4] + nz2[:,4]\n",
    "    combined[:,5] = nz1[:,5] + nz2[:,5]\n",
    "    combined[:,3] = combined[:,4] / combined[:,5]\n",
    "    \n",
    "    return combined\n",
    "\n",
    "total_nz = combine_nz(NGC_nz, SGC_nz)\n",
    "\n",
    "print(f\"BGS BRIGHT Y1 number of galaxies with M_r < {maglim} and z < {zmax}: {total_nz[:,4].sum():,}\")\n",
    "print(f\"SDSS Zehavi 2011 number of galaxies with M_r < -22 and z < 0.245169 in : 11,385 \")\n",
    "\n",
    "# Function to integrate the two across a z range\n",
    "def galdensity(zmin, zmax):\n",
    "    # Find idx for zmin and zmax\n",
    "    idx1 = np.argmin(np.abs(NGC_nz[:,0] - zmin))\n",
    "    idx2 = np.argmin(np.abs(NGC_nz[:,0] - zmax))\n",
    "\n",
    "    # NGC\n",
    "    zwidth = NGC_nz[:,2] - NGC_nz[:,1]\n",
    "    integrated = NGC_nz[:,3] * zwidth \n",
    "    summed = integrated[idx1:idx2].sum()\n",
    "\n",
    "    # And now for SGC\n",
    "    idx1 = np.argmin(np.abs(SGC_nz[:,0] - zmin))\n",
    "    idx2 = np.argmin(np.abs(SGC_nz[:,0] - zmax))\n",
    "    zwidth = SGC_nz[:,2] - SGC_nz[:,1]\n",
    "    integrated = SGC_nz[:,3] * zwidth\n",
    "    summed += integrated[idx1:idx2].sum()\n",
    "\n",
    "    return summed\n",
    "\n",
    "#galdensity(0.02, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot(NGC_nz[:,0], NGC_nz[:,3], label='BGS BRIGHT NGC')\n",
    "#plt.plot(SGC_nz[:,0], SGC_nz[:,3], '--', label='BGS BRIGHT SGC')\n",
    "plt.plot(total_nz[:,0], total_nz[:,3], label='BGS BRIGHT')\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$n(z)~[(h/$Mpc$)^3]$')\n",
    "plt.xlim(0.01, 0.26)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.title(\"BGS BRIGHT Y1 Density; $M_r<-22$, $z<0.245$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue/Red Lum Bins Comparison\n",
    "datafolder = PARAMS_SDSS_FOLDER\n",
    "def read_sdss_wp_file(fname):\n",
    "    if not os.path.exists(fname):\n",
    "        print(f'File {fname} not found')\n",
    "        return None, None, None\n",
    "    data = np.loadtxt(fname, skiprows=0, dtype='float')\n",
    "    wp = data[:,1]\n",
    "    wp_err = data[:,2]\n",
    "    radius = data[:,0]\n",
    "    return wp,wp_err,radius\n",
    "\n",
    "# BGS BRIGHT with zlims like what Jeremy did for SDSS\n",
    "zmaxes = [0.02586, 0.0406, 0.06336, 0.0981, 0.1504]\n",
    "magbins = [-17, -18, -19, -20, -21, -22]\n",
    "tracer = \"BGS_BRIGHT\" \n",
    "red_likesdss_results = []\n",
    "blue_likesdss_results = []\n",
    "for z in zmaxes:\n",
    "    red_likesdss_results.append(get_wp_for(tracer, 'pip_angular_bitwise', 'Y1', 'iron', 'v1.5pip', 'custom', z, 18, 0, True)) \n",
    "    blue_likesdss_results.append(get_wp_for(tracer, 'pip_angular_bitwise', 'Y1', 'iron', 'v1.5pip', 'custom', z, 18, 0, False))\n",
    "\n",
    "for i in range(len(zmaxes)):\n",
    "    magmin = magbins[i]\n",
    "    magmax = magbins[i+1]\n",
    "\n",
    "    if red_likesdss_results[i] is None and blue_likesdss_results[i] is None:\n",
    "        continue\n",
    "\n",
    "    plt.figure()\n",
    "    if red_likesdss_results[i] is not None:\n",
    "        if np.shape(red_likesdss_results[i])[1] == 3:\n",
    "            plt.plot(red_likesdss_results[i][:,0], red_likesdss_results[i][:,2], '.', color='r')\n",
    "        else:\n",
    "            plt.errorbar(red_likesdss_results[i][:,0], red_likesdss_results[i][:,2], yerr=red_likesdss_results[i][:,3], fmt='.', color='r', capsize=2)\n",
    "    if blue_likesdss_results[i] is not None:\n",
    "        if np.shape(blue_likesdss_results[i])[1] == 3:\n",
    "            plt.plot(blue_likesdss_results[i][:,0], blue_likesdss_results[i][:,2], '.', color='b')\n",
    "        else:\n",
    "            plt.errorbar(blue_likesdss_results[i][:,0], blue_likesdss_results[i][:,2], yerr=blue_likesdss_results[i][:,3], fmt='.', color='b', capsize=2)\n",
    "\n",
    "    # SDSS Data\n",
    "    # TODO think about error bars I'm plotting differently now\n",
    "    fname=datafolder + f'wp_red_M{np.abs(magmin):d}.dat'\n",
    "    wp, wp_err, radius = read_sdss_wp_file(fname)\n",
    "    if wp is not None:\n",
    "        plt.errorbar(radius, wp, yerr=wp_err, fmt='.', color='darkred', capsize=2, ecolor='darkred')\n",
    "\n",
    "    fname=datafolder + f'wp_blue_M{np.abs(magmin):d}.dat'\n",
    "    wp, wp_err, radius = read_sdss_wp_file(fname)\n",
    "    if wp is not None:\n",
    "        plt.errorbar(radius, wp, yerr=wp_err, fmt='.', color='darkblue', capsize=2, ecolor='darkblue')\n",
    "\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel(r'$w_p(r_p)$')\n",
    "    plt.xlabel(r'$r_p$ [Mpc/h]') \n",
    "    plt.title(f'{tracer}: ${magbins[i+1]}<M_r<{magbins[i]}$  ; $z<{zmaxes[i]}$')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do similar but for the luminosity threshold version which is not color split\n",
    "def get_threshold_wp(tracer, weights, survey, verspec, ver, bins, zmax, nran, njack, quiescent=None):\n",
    "    dir = os.path.join(CUSTOM_CLUSTERING_RESULTS_FOLDER, survey, 'LSS', verspec, 'LSScats', ver, 'rppi')\n",
    "    if not os.path.exists(dir):\n",
    "        print(\"WARNING: Directory does not exist: \", dir)\n",
    "        return None\n",
    "    if quiescent is not None:\n",
    "        addon = '_QUIESCENT' + ('1' if quiescent else '0')\n",
    "    else:\n",
    "        addon = ''\n",
    "    wp_fn = os.path.join(dir, f'wp_{tracer}_GCcomb_0.02_{zmax}_{weights}_{bins}_njack{njack}_nran{nran}_split20{addon}.txt')\n",
    "    if not os.path.exists(wp_fn):\n",
    "        print(\"WARNING: File does not exist: \", wp_fn)\n",
    "        return None\n",
    "    return np.loadtxt(wp_fn)\n",
    "\n",
    "# BGS BRIGHT with zlims like Zehavi et al 2011 Luminosity threshold samples\n",
    "zmaxes = [0.041695, 0.052536, 0.064211, 0.084892, 0.106407, 0.132425, 0.15894, 0.198804, 0.245169]\n",
    "magbins = [-18, -18.5, -19, -19.5, -20, -20.5, -21, -21.5, -22.4]\n",
    "thresholds_likesdss = []\n",
    "for z in zmaxes:\n",
    "    thresholds_likesdss.append(get_threshold_wp(tracer, 'pip_angular_bitwise', 'Y1', 'iron', 'v1.5pip', 'custom', z, 18, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot them all\n",
    "plt.figure(figsize=(6, 6))\n",
    "colors = ['k', 'k', 'cyan', 'blue', 'darkgreen', 'limegreen', 'k', 'r', 'magenta']\n",
    "for i in [8,7,6,5,3]:\n",
    "\n",
    "    if thresholds_likesdss[i] is None:\n",
    "        continue\n",
    "\n",
    "    if thresholds_likesdss[i] is not None:\n",
    "        if np.shape(thresholds_likesdss[i])[1] == 3:\n",
    "            plt.plot(thresholds_likesdss[i][:,0], thresholds_likesdss[i][:,2], 'o', color=colors[i], label=f'$M_r<{magbins[i]}$')\n",
    "        else:\n",
    "            plt.errorbar(thresholds_likesdss[i][:,0], thresholds_likesdss[i][:,2], yerr=thresholds_likesdss[i][:,3], fmt='.', color=colors[i], capsize=2)\n",
    "\n",
    "\n",
    "# SDSS Data\n",
    "sdss_magbins = [19.5, 20.5, 21, 21.5, 22]\n",
    "colors = ['blue', 'limegreen', 'k', 'r', 'magenta']\n",
    "sdss_magbins.reverse()\n",
    "colors.reverse()\n",
    "for m in sdss_magbins:\n",
    "    # TODO\n",
    "    fn = PARAMS_SDSS_FOLDER + f'sdss-thresh-{m:.1f}.csv'\n",
    "    if not os.path.exists(fn):\n",
    "        print(f'File {fn} not found')\n",
    "        continue\n",
    "    data = np.loadtxt(fn, skiprows=1, dtype='float', delimiter=',')\n",
    "    plt.plot(data[:,0], data[:,1], '-', label=f'SDSS $M_r<-{m}$', color=colors.pop(0))\n",
    "\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(r'$w_p(r_p)$')\n",
    "plt.xlabel(r'$r_p$ [Mpc/h]') \n",
    "plt.legend()\n",
    "plt.ylim(2, 1500)\n",
    "plt.xlim(0.1, 40)\n",
    "# Add ticks on top and bottom\n",
    "plt.gca().yaxis.set_ticks_position('both')\n",
    "plt.gca().xaxis.set_ticks_position('both')\n",
    "plt.gca().yaxis.set_tick_params(which='both', direction='in')\n",
    "plt.gca().xaxis.set_tick_params(which='both', direction='in')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
