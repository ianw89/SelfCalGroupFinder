{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from astropy.table import Table\n",
    "import math\n",
    "import Corrfunc\n",
    "from os.path import dirname, abspath, join as pjoin\n",
    "from Corrfunc.io import read_catalog\n",
    "from copy import deepcopy\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "import plotting as pp\n",
    "import groupcatalog as gc\n",
    "from nnanalysis import *\n",
    "import catalog_definitions as cat\n",
    "from redshift_guesser import SimpleRedshiftGuesser, PhotometricRedshiftGuesser\n",
    "from groupcatalog import TestGroupCatalog, BGSGroupCatalog\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the chisqr() function has changed\n",
    "catalog: gc.SDSSGroupCatalog = gc.deserialize(cat.sdss_colors_chi)\n",
    "result = catalog.chisqr()\n",
    "# Chi^2 can wander a bit from run to run with the same settings, so we allow a bit of tolerance\n",
    "assert np.isclose(result[0], 97.0, rtol=0.0, atol=2.0), \"Chi squared test failed\" # pinning previous result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_color = GLOBAL_RED_COLOR_CUT - 0.1\n",
    "red_color = GLOBAL_RED_COLOR_CUT + 0.1\n",
    "\n",
    "blue_dn = -1\n",
    "red_dn = 3\n",
    "\n",
    "results = is_quiescent_BGS_smart(np.array([7,8,9]), np.array([red_dn, np.nan, blue_dn]), np.array([blue_color, blue_color, red_color]))\n",
    "assert results[0] == True\n",
    "assert results[1] == False\n",
    "assert results[2] == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test of multiple versions of SimpleRedshiftGuesser\n",
    "# Ensure it handles arrays of inputs and gives a reasonable answer for a couple obvious cases\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0,18.0,12.0])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5])\n",
    "t_q = np.array([True, True, False])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([0.1, 0.2, 0.3])\n",
    "nn_dist = np.array([250.0, 3.0, 30.0])\n",
    "nn_q = np.array([True, True, False])\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='5.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='4.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.12, z[2]\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='2.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test on scores from the SV3 bins file \n",
    "target_prob_obs = None #[0.5]\n",
    "target_app_mag = [19.0, 19.0, 18.0, 14.0]\n",
    "target_quiescent = [1.0, 0.0, 1.0, 1.0]\n",
    "neighbor_z = [0.1, 0.2, 0.05, 0.3]\n",
    "neighbor_ang_dist = [30.0, 150.0, 2.0, 15.0]\n",
    "nn_quiescent = [1.0, 0.0, 1.0, 1.0]\n",
    "\n",
    "nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE)\n",
    "score_b = nna.get_score(target_prob_obs, target_app_mag, target_quiescent, neighbor_z, neighbor_ang_dist, nn_quiescent)\n",
    "print(score_b)\n",
    "\n",
    "assert score_b[0] > 0.01, f\"Reasonable parameters should have a non-zero score, but got {score_b[0]}\"\n",
    "#assert score_b[1] < 0.1, f\"Very high angular distance should have a low score, but got {score_b[1]}\" # BUG is it that issue I saw where edge value is True and spreads?\n",
    "assert score_b[2] > 0.4, f\"Very low angular distance should have a high score, but got {score_b[2]}\"\n",
    "assert score_b[3] < 0.1, f\"Bright target with neighbor at high z should have a low score even at close distance {score_b[3]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that Scipy linear interp is doing what we want inside the NNAnalyzer\n",
    "nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE)\n",
    "frac, all_counts, simz_counts = nna.integrate_out_dimension((0,6))\n",
    "\n",
    "print(frac.shape)\n",
    "first=frac[0,0,5,9,5]\n",
    "second=frac[0,0,5,10,5]\n",
    "mid = (first+second)/2\n",
    "print(first, second, mid)\n",
    "\n",
    "score = nna.get_score(None, [(APP_MAG_BINS[9]+APP_MAG_BINS[10]) / 2], [0.0], [Z_BINS[5]], [ANGULAR_BINS[5]], [0.0])\n",
    "\n",
    "assert np.isclose(mid, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tests for PhotometricRedshiftGuesser\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0, 18.0, 12.0, 17.1])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5, 0.9])\n",
    "t_q = np.array([True, True, False, False])\n",
    "t_zphot = np.array([0.105, 0.230, 0.011, 0.070])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([[0.1, 0.2, 0.3, 0.35],\n",
    "                 [0.2, 0.3, 0.1, 0.03]])\n",
    "nn_dist = np.array([[250.0, 3.0,  30.0, 4.0],\n",
    "                    [260.0, 40.0, 40.0, 8.0]])\n",
    "nn_q = np.array([[True, True, False, True],\n",
    "                 [False, False, False, True]])\n",
    "\n",
    "scorer = PhotometricRedshiftGuesser.from_files(BGS_Y3_LOST_APP_TO_Z_FILE, BGS_Y3_LOST_APP_AND_ZPHOT_TO_Z_FILE, NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE, Mode.PHOTOZ_PLUS_v3)\n",
    "scorer.debug = True\n",
    "params = ([0.8104, 0.9215, 2.867 ], [0.9102, 0.7376, 3.0275], [0.8986, 1.0397, 2.6287], [0.7488, 0.9489, 2.9319]) # 3. params\n",
    "\n",
    "z, assignment_type = scorer.choose_redshift(nn_z, nn_dist, t_zphot, t_pobs, t_app_mag, t_q, nn_q, params)\n",
    "\n",
    "print(z)\n",
    "print(assignment_type)\n",
    "\n",
    "# TODO more tests\n",
    "\n",
    "assert assignment_type[0] <= -1, \"Should not use a neighbor\"\n",
    "assert assignment_type[1] == 1, \"should use neighbor 1 \"\n",
    "assert assignment_type[2] <= -1, \"should not use a neighbor\"\n",
    "assert assignment_type[3] == 2, \"should use neighbor 2\"\n",
    "\n",
    "assert np.isnan(z).sum() == 0, \"z should not have any NaNs\"\n",
    "assert z[0] > 0.0, \"z[0] should be greater than 0.0\"\n",
    "assert z[1] == 0.2, \"z[1] should be 0.2\"\n",
    "assert z[2] < 0.1, \"z[2] should be less than 0.1\"\n",
    "assert z[3] == 0.03, \"z[3] should be 0.03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out sim_z_score function\n",
    "# Test out smooth redshift comparison function works as desired for the relevant redshift differences\n",
    "x=np.arange(-0.100, 0.105, 0.0005)\n",
    "plt.plot(x, powerlaw_score_1(0.2, 0.2+x), label=\"Powerlaw 1\")\n",
    "plt.axvline(0.005, color='r')\n",
    "plt.axvline(-0.005, color='r')\n",
    "plt.plot(x, powerlaw_score_2(0.2, 0.2+x), color='purple', label=\"Powerlaw 2\")\n",
    "plt.plot(x, rounded_tophat_score(0.2, 0.2-x), color='g', label=\"close enough smooth\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Redshift difference\")\n",
    "plt.ylabel(\"Similarity score\")\n",
    "\n",
    "# Make sure the extremes are working as expected\n",
    "assert powerlaw_score_1(0.1, 0.3) < 0.01\n",
    "assert powerlaw_score_1(0.2, 0.3) < 0.05 and powerlaw_score_1(0.2, 0.3) > 0.01\n",
    "assert powerlaw_score_1(0.2, 0.25) < 0.1 and powerlaw_score_1(0.2, 0.25) > 0.05\n",
    "assert powerlaw_score_1(0.2, 0.210) > 0.2, powerlaw_score_1(0.2, 0.210)\n",
    "assert powerlaw_score_1(0.2, 0.205) > 0.95, powerlaw_score_1(0.2, 0.205)\n",
    "assert powerlaw_score_1(0.2, 0.203) > 0.99, powerlaw_score_1(0.2, 0.203)\n",
    "assert np.isclose(powerlaw_score_1(0.2, 0.2001), 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure scipy's linear interp works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIC Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D test of my N-dimensional CIC binning function\n",
    "data_1d = np.array([\n",
    "    0.0, \n",
    "    3.5, \n",
    "])\n",
    "first_dim  = np.linspace(0, 5, 6)\n",
    "\n",
    "bin_counts = cic_binning(data_1d, [first_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6,), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_1d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0], 1)\n",
    "assert np.isclose(bin_counts[3], 0.5)\n",
    "assert np.isclose(bin_counts[4], 0.5)\n",
    "assert np.isclose(bin_counts[5], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D test of my N-dimensional CIC binning function\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0], # Test corner case\n",
    "    [0.0, -0.5], # Test left edge case\n",
    "    [3.5, 3.5], # Test middle case\n",
    "    [2, 5.9],\n",
    "    [0.5, 40.0], # Test right edge case\n",
    "    [-7.0, -3.0], # Extra edge case\n",
    "])\n",
    "first_dim  = np.linspace(0, 5, 6)\n",
    "second_dim  = np.linspace(0, 6, 7)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6, 7), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_2d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 3.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[2,5], 0.1), bin_counts[2,5]\n",
    "assert np.isclose(bin_counts[2,6], 0.9), bin_counts[2,6]\n",
    "assert np.isclose(bin_counts[3,3], 0.25), bin_counts[3,3]\n",
    "assert np.isclose(bin_counts[3,4], 0.25), bin_counts[3,4]\n",
    "assert np.isclose(bin_counts[4,3], 0.25), bin_counts[4,3]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[0,6], 0.5), bin_counts[0,6]\n",
    "assert np.isclose(bin_counts[1,6], 0.5), bin_counts[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D test of CIC binning\n",
    "data_3d = np.array([\n",
    "    [0.0, 0.0, 0.0],  # Test corner case\n",
    "    [1.5, 1.5, 1.5],  # Test middle case\n",
    "    [10.0, 10.0, -10.0],  #  edge case\n",
    "    [0.0, -1.0, 1.6]\n",
    "])\n",
    "first_dim_3d = np.linspace(0, 3, 4)\n",
    "second_dim_3d = np.linspace(0, 4, 5)\n",
    "third_dim_3d = np.linspace(0, 2, 3)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_3d = cic_binning(data_3d, [first_dim_3d, second_dim_3d, third_dim_3d])\n",
    "print(bin_counts_3d)\n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_3d) == (4, 5, 3), np.shape(bin_counts_3d)\n",
    "assert np.isclose(np.sum(bin_counts_3d), len(data_3d)), np.sum(bin_counts_3d)\n",
    "assert np.isclose(bin_counts_3d[0,0,0], 1.0), bin_counts_3d[0,0,0]\n",
    "assert np.isclose(bin_counts_3d[1,1,1], 1/8), bin_counts_3d[1,1,1]\n",
    "assert np.isclose(bin_counts_3d[1,1,2], 1/8), bin_counts_3d[1,1,2]\n",
    "assert np.isclose(bin_counts_3d[1,2,1], 1/8), bin_counts_3d[1,2,1]\n",
    "assert np.isclose(bin_counts_3d[1,2,2], 1/8), bin_counts_3d[1,2,2]\n",
    "assert np.isclose(bin_counts_3d[2,1,1], 1/8), bin_counts_3d[2,1,1]\n",
    "assert np.isclose(bin_counts_3d[2,1,2], 1/8), bin_counts_3d[2,1,2]\n",
    "assert np.isclose(bin_counts_3d[2,2,1], 1/8), bin_counts_3d[2,2,1]\n",
    "assert np.isclose(bin_counts_3d[2,2,2], 1/8), bin_counts_3d[2,2,2]\n",
    "assert np.isclose(bin_counts_3d[3,4,0], 1.0), bin_counts_3d[3,4,0]\n",
    "assert np.isclose(bin_counts_3d[0,0,1], 0.4), bin_counts_3d[3,4,1]\n",
    "assert np.isclose(bin_counts_3d[0,0,2], 0.6), bin_counts_3d[3,4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with weights\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim], weights=[0.66, 2.99])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 0.66), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 2.99), bin_counts[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with repeats\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 0.0), bin_counts[0,1]\n",
    "assert np.isclose(bin_counts[1,0], 0.0), bin_counts[1,0]\n",
    "assert np.isclose(bin_counts[1,1], 3.0), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-1.0, -1.2],  \n",
    "    [0.5, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(-1, 1, 3)\n",
    "second_dim  = np.linspace(-1, 1, 3)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (3, 3), np.shape(bin_counts)\n",
    "assert np.isclose(np.sum(bin_counts), 2.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[1,2], 0.5), bin_counts[1,1]\n",
    "assert np.isclose(bin_counts[2,2], 0.5), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with log data\n",
    "data_2d = np.array([\n",
    "    [3.0, 1.0],  \n",
    "    [1.5, 2.0],  \n",
    "])\n",
    "first_dim  = np.linspace(1, 4, 4) # log data though; 2.0 means 100.0\n",
    "second_dim  = np.linspace(0, 3, 4)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim], logscale=[10, False])\n",
    "print(bin_counts)\n",
    "print(data_2d)\n",
    "\n",
    "assert np.shape(bin_counts) == (4, 4), np.shape(bin_counts)\n",
    "assert np.isclose(np.sum(bin_counts), 2.0), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[2,1], 1.0), bin_counts[2,1]\n",
    "assert bin_counts[0,2] > 0.6, bin_counts[0,2]\n",
    "assert bin_counts[1,2] < 0.4, bin_counts[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress test of CIC binning\n",
    "data_stress = np.random.rand(1000000, 5) # 5M rows of random data\n",
    "dim_stress = np.linspace(0, 1, 11)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_stress = cic_binning(data_stress, [dim_stress, dim_stress, dim_stress, dim_stress, dim_stress])   \n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_stress) == (11, 11, 11, 11, 11), np.shape(bin_counts_stress)\n",
    "assert np.isclose(np.sum(bin_counts_stress), len(data_stress)), np.sum(bin_counts_stress)\n",
    "\n",
    "with np.printoptions(precision=1, suppress=True, linewidth=100):\n",
    "    print(np.sum(np.sum(np.sum(bin_counts_stress, axis=0), axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-0.01, APP_MAG_BINS[3]],  \n",
    "    [0.01, APP_MAG_BINS[3]],  \n",
    "    [0.03, APP_MAG_BINS[3]],  \n",
    "    [0.12, APP_MAG_BINS[3]],  \n",
    "    [0.21, APP_MAG_BINS[3]],  \n",
    "    [0.40, APP_MAG_BINS[3]],  \n",
    "    [0.50, APP_MAG_BINS[5]],  \n",
    "])\n",
    "first_dim  = Z_BINS\n",
    "second_dim  = APP_MAG_BINS\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True, linewidth=200):\n",
    "    print(bin_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: which is faster, boolean indexing or integer indexing?\n",
    "arr = np.random.rand(20000000)\n",
    "bool_filter = arr < 0.1\n",
    "N = 20\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "test2 = np.zeros(len(arr))\n",
    "t1 = time.time()\n",
    "for n in range(N):\n",
    "    test += arr[bool_filter]\n",
    "    test2[bool_filter] += arr[bool_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for bool filter: {t2-t1}\")\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "t1 = time.time()\n",
    "idx_filter = np.flatnonzero(bool_filter)\n",
    "for n in range(N):\n",
    "    test += arr[idx_filter]\n",
    "    test2[idx_filter] += arr[idx_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for idx filter: {t2-t1}\")\n",
    "\n",
    "# Answer: idx filter is faster. And order doesn't matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function signature is write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base, frac_area):\n",
    "\n",
    "# Generate some sample data to write\n",
    "NUM_ROWS = 500000\n",
    "ra = np.random.rand(NUM_ROWS)\n",
    "dec = np.random.rand(NUM_ROWS)\n",
    "z_eff = np.random.rand(NUM_ROWS)\n",
    "log_L_gal = np.random.rand(NUM_ROWS)\n",
    "V_max = np.random.rand(NUM_ROWS)\n",
    "colors = np.random.randint(0, 2, NUM_ROWS)\n",
    "chi = np.random.rand(NUM_ROWS)\n",
    "outname_base = OUTPUT_FOLDER + 'speed-write-test'\n",
    "outname_base2 = OUTPUT_FOLDER + 'speed-write-test2'\n",
    "\n",
    "# Write data using write_dat_files\n",
    "start_time = time.time()\n",
    "write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base)\n",
    "end_time = time.time()\n",
    "time_v1 = end_time - start_time\n",
    "\n",
    "# Write data using write_dat_files_v2\n",
    "start_time = time.time()\n",
    "write_dat_files_v2(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base2)\n",
    "end_time = time.time()\n",
    "time_v2 = end_time - start_time\n",
    "\n",
    "# Compare the contents of the two files\n",
    "with open(outname_base + '.dat', 'rb') as f1, open(outname_base2 + '.dat', 'rb') as f2:\n",
    "    data_v1 = f1.read()\n",
    "    data_v2 = f2.read()\n",
    "\n",
    "assert data_v1.strip() == data_v2.strip(), \"The outputs of write_dat_files and write_dat_files_v2 are not the same\"\n",
    "\n",
    "# Print the time taken by each function\n",
    "print(f\"Time taken by write_dat_files: {time_v1} seconds\")\n",
    "print(f\"Time taken by write_dat_files_v2: {time_v2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat1 = np.random.rand(1000,1000)\n",
    "dataMat2 = np.random.rand(2,500000)\n",
    "dataMat3 = np.random.rand(500000,2)\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test1.txt','w') as f:\n",
    "    np.savetxt(f,dataMat1,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test2.txt','w') as f:\n",
    "    np.savetxt(f,dataMat2,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test3.txt','w') as f:\n",
    "    np.savetxt(f,dataMat3,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test4.txt','w') as f:\n",
    "    fmt = ' '.join(['%g']*dataMat3.shape[1])\n",
    "    fmt = '\\n'.join([fmt]*dataMat3.shape[0])\n",
    "    data = fmt % tuple(dataMat3.ravel())        \n",
    "    f.write(data)\n",
    "end = time.perf_counter()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run once, unless you want to change the test data\n",
    "#catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.create_test_dat_files() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV3_test = BGSGroupCatalog(\"SV3 Test\", Mode.SIMPLE_v4, 19.5, 21.0, num_passes=10, drop_passes=3, data_cut='sv3', sdss_fill=False)\n",
    "SV3_test.GF_props = cat.GF_PROPS_BGS_VANILLA.copy()\n",
    "\n",
    "SV3_test.preprocess()\n",
    "\n",
    "# Read in BGS_SV3_ANY_FULL_FILE and ensure no precision is lost from there to SV3_test.preprocess_file and the like\n",
    "merged_table = Table.read(IAN_BGS_SV3_MERGED_FILE, format='fits')\n",
    "print(merged_table['RA'][0:10])\n",
    "\n",
    "# read in and print out the first few lines of SV3_test.preprocess_file\n",
    "with open(SV3_test.preprocess_file, 'r') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')\n",
    "\n",
    "#with open(SV3_test.preprocess_file + \"~\", 'r') as f:\n",
    "#    for i in range(10):\n",
    "#        print(f.readline(), end='')\n",
    "\n",
    "galprops_file = str.replace(SV3_test.GF_outfile, \".out\", \"_galprops.pkl\")\n",
    "galprops = pickle.load(open(galprops_file, \"rb\"))\n",
    "print(galprops[0:10])\n",
    "\n",
    "#with open(galprops_file + \"~\", 'r') as f:\n",
    "#    for i in range(10):\n",
    "#        print(f.readline(), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test an orphaned satellite in final iteration scenario.\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['iterations'] = 1 # By running with 1 iteration only on these data, we expose a situation where satellites are orphaned in the final iteration\n",
    "catalog.run_group_finder(silent=True, verbose=False) \n",
    "catalog.postprocess()\n",
    "#df=catalog.all_data.loc[catalog.all_data['Z'] < 0.1]\n",
    "#pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)\n",
    "catalog.sanity_tests() # Includes tests on the orphaned satellites, effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['iterations'] = 5 # By running with 1 iteration only on these data, we expose a situation where satellites are orphaned in the final iteration\n",
    "catalog.run_group_finder(silent=True, verbose=False) \n",
    "catalog.postprocess()\n",
    "#df=catalog.all_data.loc[catalog.all_data['Z'] < 0.1]\n",
    "#pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)\n",
    "catalog.sanity_tests() # Includes tests on the orphaned satellites, effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C Group Finder Tests\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "SILENT = True\n",
    "\n",
    "# Baseline vanilla group finder test \n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.run_group_finder(silent=SILENT) \n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "baseline_total_mass = df['M_HALO'].sum()\n",
    "assert len(np.unique(df['IGRP'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "m1=df['M_HALO'].to_numpy()\n",
    "\n",
    "# Test that when omega0 are 0, the others don't matter\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['omegaL_sf'] = 123\n",
    "catalog.GF_props['sigma_sf'] = 345\n",
    "catalog.GF_props['omegaL_q'] = 456\n",
    "catalog.GF_props['sigma_q'] = 678\n",
    "catalog.GF_props['omega0_sf'] = 0.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=SILENT)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "assert np.isclose(df['M_HALO'].sum(), baseline_total_mass)\n",
    "m2=df['M_HALO'].to_numpy()\n",
    "\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.GF_props['colors'] = 1\n",
    "catalog.GF_props['omegaL_sf'] = 10.0\n",
    "catalog.GF_props['sigma_sf'] = 3.0\n",
    "catalog.GF_props['omegaL_q'] = 0.0\n",
    "catalog.GF_props['sigma_q'] = 0.0\n",
    "catalog.GF_props['omega0_sf'] = 10.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=SILENT)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) >= 200 # these parameters make assigned halos smaller\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert df['WEIGHT'].sum() < 246 \n",
    "# TODO BUG I feel like this should be true, but it's not. Weighting doesn't preseve the halo mass function\n",
    "#assert np.isclose(df['M_HALO'].sum(), baseline_total_mass) \n",
    "m3=df['M_HALO'].to_numpy()\n",
    "\n",
    "plt.hist(np.stack([np.log10(m1), np.log10(m2), np.log10(m3)], axis=-1))\n",
    "\n",
    "\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C Group Finder Tests\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "SILENT = True\n",
    "\n",
    "# Baseline vanilla group finder test \n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.run_group_finder(silent=SILENT) \n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "baseline_total_mass = df['M_HALO'].sum()\n",
    "assert len(np.unique(df['IGRP'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "m1=df['M_HALO'].to_numpy()\n",
    "\n",
    "# Test that when omega0 are 0, the others don't matter\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['omegaL_sf'] = 123\n",
    "catalog.GF_props['sigma_sf'] = 345\n",
    "catalog.GF_props['omegaL_q'] = 456\n",
    "catalog.GF_props['sigma_q'] = 678\n",
    "catalog.GF_props['omega0_sf'] = 0.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=SILENT)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "assert np.isclose(df['M_HALO'].sum(), baseline_total_mass)\n",
    "m2=df['M_HALO'].to_numpy()\n",
    "\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.GF_props['colors'] = 1\n",
    "catalog.GF_props['omegaL_sf'] = 10.0\n",
    "catalog.GF_props['sigma_sf'] = 3.0\n",
    "catalog.GF_props['omegaL_q'] = 0.0\n",
    "catalog.GF_props['sigma_q'] = 0.0\n",
    "catalog.GF_props['omega0_sf'] = 10.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=SILENT)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) >= 200 # these parameters make assigned halos smaller\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert df['WEIGHT'].sum() < 246 \n",
    "# TODO BUG I feel like this should be true, but it's not. Weighting doesn't preseve the halo mass function\n",
    "#assert np.isclose(df['M_HALO'].sum(), baseline_total_mass) \n",
    "m3=df['M_HALO'].to_numpy()\n",
    "\n",
    "plt.hist(np.stack([np.log10(m1), np.log10(m2), np.log10(m3)], axis=-1))\n",
    "\n",
    "\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test purity and completeness calculations\n",
    "# TODO get a test of this workin as I've had a lot of bugs here.\n",
    "import plotting as pp \n",
    "\n",
    "testcat = TestGroupCatalog(\"Test\")\n",
    "testcat.run_group_finder(silent=True)\n",
    "testcat.postprocess()\n",
    "testcat.all_data['TARGETID'] = testcat.all_data.index\n",
    "\n",
    "truthcat = TestGroupCatalog(\"Test\")\n",
    "truthcat.run_group_finder(silent=True)\n",
    "truthcat.postprocess()\n",
    "truthcat.all_data['TARGETID'] = truthcat.all_data.index\n",
    "\n",
    "# BUG 246 galaxies to have no truth redshift. ?\n",
    "pp.test_purity_and_completeness(testcat, truth_catalog=truthcat)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End to end test of chi squared on SDSS with 14 parameters\n",
    "catalog = deepcopy(cat.sdss_colors_chi)\n",
    "catalog.run_group_finder(popmock=True, silent=True)\n",
    "#catalog: gc.SDSSGroupCatalog = gc.deserialize(cat.sdss_colors_chi)\n",
    "result = catalog.chisqr()\n",
    "# 98.95, 98.99, 97.70, 97.68\n",
    "# Used to be 96.21 but don't know why changed\n",
    "assert np.isclose(result[0], 97.0, rtol=0.0, atol=2.0), \"Chi squared test failed\" # pinning previous result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
