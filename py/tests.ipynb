{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from astropy.table import Table\n",
    "import math\n",
    "import Corrfunc\n",
    "import pandas as pd\n",
    "from os.path import dirname, abspath, join as pjoin\n",
    "from Corrfunc.io import read_catalog\n",
    "from copy import deepcopy\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "import plotting as pp\n",
    "import groupcatalog as gc\n",
    "from nnanalysis import *\n",
    "import catalog_definitions as cat\n",
    "from redshift_guesser import SimpleRedshiftGuesser, PhotometricRedshiftGuesser\n",
    "from groupcatalog import TestGroupCatalog, BGSGroupCatalog\n",
    "from calibrationdata import CalibrationData\n",
    "import hod\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_catalogs_match(first: pd.DataFrame, second: pd.DataFrame):\n",
    "\n",
    "    assert len(first) == len(second), f\"Number of galaxies mismatch: {len(first)} vs {len(second)}\"\n",
    "    assert np.allclose(first['RA'], second['RA']), f\"{(first['RA'] != second['RA']).sum()} mismatches in RA\"\n",
    "    assert np.allclose(first['DEC'], second['DEC']), f\"{(first['DEC'] != second['DEC']).sum()} mismatches in DEC\"\n",
    "    assert np.allclose(first['Z'], second['Z']), f\"{(first['Z'] != second['Z']).sum()} mismatches in Z\"\n",
    "    assert np.allclose(first['L_GAL'], second['L_GAL']), f\"{(first['L_GAL'] != second['L_GAL']).sum()} mismatches in L_GAL\"\n",
    "    assert np.allclose(first['VMAX'], second['VMAX']), f\"{(first['VMAX'] != second['VMAX']).sum()} mismatches in VMAX\"\n",
    "    assert np.allclose(first['IGRP'], second['IGRP']), f\"{(first['IGRP'] != second['IGRP']).sum()} mismatches in IGRP\"\n",
    "    assert np.allclose(first['P_SAT'], second['P_SAT']), f\"{(first['P_SAT'] != second['P_SAT']).sum()} mismatches in P_SAT\"\n",
    "    assert np.allclose(first['M_HALO'], second['M_HALO']), f\"{(first['M_HALO'] != second['M_HALO']).sum()} mismatches in M_HALO\"\n",
    "    assert np.allclose(first['N_SAT'], second['N_SAT']), f\"{(first['N_SAT'] != second['N_SAT']).sum()} mismatches in N_SAT\"\n",
    "    assert np.allclose(first['L_TOT'], second['L_TOT']), f\"{(first['L_TOT'] != second['L_TOT']).sum()} mismatches in L_TOT\"\n",
    "    assert np.allclose(first['WEIGHT'], second['WEIGHT']), f\"{(first['WEIGHT'] != second['WEIGHT']).sum()} mismatches in WEIGHT\"\n",
    "    assert np.allclose(first['CHI1_WEIGHT'], second['CHI1_WEIGHT']), f\"{(first['CHI1_WEIGHT'] != second['CHI1_WEIGHT']).sum()} mismatches in CHI1_WEIGHT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logL = 10\n",
    "answer1 = SOLAR_L_R_BAND - 2.5 * logL\n",
    "answer2 =  SOLAR_L_R_BAND - (logL / 0.39794)\n",
    "print(f\"answer1: {answer1}, answer2: {answer2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = -20\n",
    "logL = abs_mag_r_to_log_solar_L(mag)\n",
    "mag_after = log_solar_L_to_abs_mag_r(logL)\n",
    "print(f\"mag: {mag}, logL: {logL}, mag_after: {mag_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_color = GLOBAL_RED_COLOR_CUT - 0.1\n",
    "red_color = GLOBAL_RED_COLOR_CUT + 0.1\n",
    "\n",
    "blue_dn = -1\n",
    "red_dn = 3\n",
    "\n",
    "results = is_quiescent_BGS_dn4000(np.array([7,8,9]), np.array([red_dn, np.nan, blue_dn]), np.array([blue_color, blue_color, red_color]))\n",
    "assert results[0] == True\n",
    "assert results[1] == False\n",
    "assert results[2] == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test of multiple versions of SimpleRedshiftGuesser\n",
    "# Ensure it handles arrays of inputs and gives a reasonable answer for a couple obvious cases\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0,18.0,12.0])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5])\n",
    "t_q = np.array([True, True, False])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([0.1, 0.2, 0.3])\n",
    "nn_dist = np.array([250.0, 3.0, 30.0])\n",
    "nn_q = np.array([True, True, False])\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='5.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='4.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.12, z[2]\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='2.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test on scores from the SV3 bins file \n",
    "target_neighbor= [1,1,1,1,1,8]\n",
    "target_app_mag = [19.0, 19.0, 18.0, 14.0, 19.0, 19.0]\n",
    "target_quiescent = [1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
    "neighbor_z = [0.1, 0.2, 0.05, 0.3, 0.1, 0.1]\n",
    "neighbor_ang_dist = [30.0, 150.0, 2.0, 15.0, 60.0, 60.0]\n",
    "nn_quiescent = [1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE_V2)\n",
    "#nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE)\n",
    "score_b = nna.get_score(target_neighbor, target_app_mag, target_quiescent, neighbor_z, neighbor_ang_dist, nn_quiescent)\n",
    "print(score_b)\n",
    "\n",
    "assert score_b[0] > 0.01, f\"Reasonable parameters should have a non-zero score, but got {score_b[0]}\"\n",
    "#assert score_b[1] < 0.1, f\"Very high angular distance should have a low score, but got {score_b[1]}\" # BUG is it that issue I saw where edge value is True and spreads?\n",
    "assert score_b[2] > 0.4, f\"Very low angular distance should have a high score, but got {score_b[2]}\"\n",
    "assert score_b[3] < 0.1, f\"Bright target with neighbor at high z should have a low score even at close distance {score_b[3]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that Scipy linear interp is doing what we want inside the NNAnalyzer\n",
    "nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE_V2)\n",
    "frac, all_counts, simz_counts = nna.integrate_out_dimension((0,6))\n",
    "\n",
    "print(frac.shape)\n",
    "first=frac[0,0,5,9,5]\n",
    "second=frac[0,0,5,10,5]\n",
    "mid = (first+second)/2\n",
    "print(first, second, mid)\n",
    "\n",
    "score = nna.get_score(None, [(APP_MAG_BINS[9]+APP_MAG_BINS[10]) / 2], [0.0], [Z_BINS[5]], [ANGULAR_BINS[5]], [0.0])\n",
    "\n",
    "assert np.isclose(mid, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tests for PhotometricRedshiftGuesser\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0, 18.0, 12.0, 17.1])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5, 0.9])\n",
    "t_q = np.array([True, True, False, False])\n",
    "t_zphot = np.array([0.105, 0.230, 0.011, 0.070])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([[0.1, 0.2, 0.3, 0.35],\n",
    "                 [0.2, 0.3, 0.1, 0.03]])\n",
    "nn_dist = np.array([[250.0, 3.0,  30.0, 4.0],\n",
    "                    [260.0, 40.0, 40.0, 8.0]])\n",
    "nn_q = np.array([[True, True, False, True],\n",
    "                 [False, False, False, True]])\n",
    "\n",
    "scorer = PhotometricRedshiftGuesser.from_files(BGS_Y3_LOST_APP_TO_Z_FILE, BGS_Y3_LOST_APP_AND_ZPHOT_TO_Z_FILE, NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE_V2, Mode.PHOTOZ_PLUS_v3)\n",
    "scorer.debug = True\n",
    "params = ([0.8104, 0.9215, 2.867 ], [0.9102, 0.7376, 3.0275], [0.8986, 1.0397, 2.6287], [0.7488, 0.9489, 2.9319]) # 3. params\n",
    "\n",
    "z, assignment_type = scorer.choose_redshift(nn_z, nn_dist, t_zphot, t_pobs, t_app_mag, t_q, nn_q, params)\n",
    "\n",
    "print(z)\n",
    "print(assignment_type)\n",
    "\n",
    "# TODO more tests\n",
    "\n",
    "assert assignment_type[0] <= -1, \"Should not use a neighbor\"\n",
    "assert assignment_type[1] == 1, \"should use neighbor 1 \"\n",
    "assert assignment_type[2] <= -1, \"should not use a neighbor\"\n",
    "assert assignment_type[3] == 2, \"should use neighbor 2\"\n",
    "\n",
    "assert np.isnan(z).sum() == 0, \"z should not have any NaNs\"\n",
    "assert z[0] > 0.0, \"z[0] should be greater than 0.0\"\n",
    "assert z[1] == 0.2, \"z[1] should be 0.2\"\n",
    "assert z[2] < 0.1, \"z[2] should be less than 0.1\"\n",
    "assert z[3] == 0.03, \"z[3] should be 0.03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out sim_z_score function\n",
    "# Test out smooth redshift comparison function works as desired for the relevant redshift differences\n",
    "x=np.arange(-0.100, 0.105, 0.0005)\n",
    "plt.plot(x, powerlaw_score_1(0.2, 0.2+x), label=\"Powerlaw 1\")\n",
    "plt.axvline(0.005, color='r')\n",
    "plt.axvline(-0.005, color='r')\n",
    "plt.plot(x, powerlaw_score_2(0.2, 0.2+x), color='purple', label=\"Powerlaw 2\")\n",
    "plt.plot(x, rounded_tophat_score(0.2, 0.2-x), color='g', label=\"close enough smooth\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Redshift difference\")\n",
    "plt.ylabel(\"Similarity score\")\n",
    "\n",
    "# Make sure the extremes are working as expected\n",
    "assert powerlaw_score_1(0.1, 0.3) < 0.01\n",
    "assert powerlaw_score_1(0.2, 0.3) < 0.05 and powerlaw_score_1(0.2, 0.3) > 0.01\n",
    "assert powerlaw_score_1(0.2, 0.25) < 0.1 and powerlaw_score_1(0.2, 0.25) > 0.05\n",
    "assert powerlaw_score_1(0.2, 0.210) > 0.2, powerlaw_score_1(0.2, 0.210)\n",
    "assert powerlaw_score_1(0.2, 0.205) > 0.95, powerlaw_score_1(0.2, 0.205)\n",
    "assert powerlaw_score_1(0.2, 0.203) > 0.99, powerlaw_score_1(0.2, 0.203)\n",
    "assert np.isclose(powerlaw_score_1(0.2, 0.2001), 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIC Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D test of my N-dimensional CIC binning function\n",
    "data_1d = np.array([\n",
    "    0.0, \n",
    "    3.5, \n",
    "])\n",
    "first_dim  = np.linspace(0, 5, 6)\n",
    "\n",
    "bin_counts = cic_binning(data_1d, [first_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6,), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_1d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0], 1)\n",
    "assert np.isclose(bin_counts[3], 0.5)\n",
    "assert np.isclose(bin_counts[4], 0.5)\n",
    "assert np.isclose(bin_counts[5], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D test of my N-dimensional CIC binning function\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0], # Test corner case\n",
    "    [0.0, -0.5], # Test left edge case\n",
    "    [3.5, 3.5], # Test middle case\n",
    "    [2, 5.9],\n",
    "    [0.5, 40.0], # Test right edge case\n",
    "    [-7.0, -3.0], # Extra edge case\n",
    "])\n",
    "first_dim  = np.linspace(0, 5, 6)\n",
    "second_dim  = np.linspace(0, 6, 7)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6, 7), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_2d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 3.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[2,5], 0.1), bin_counts[2,5]\n",
    "assert np.isclose(bin_counts[2,6], 0.9), bin_counts[2,6]\n",
    "assert np.isclose(bin_counts[3,3], 0.25), bin_counts[3,3]\n",
    "assert np.isclose(bin_counts[3,4], 0.25), bin_counts[3,4]\n",
    "assert np.isclose(bin_counts[4,3], 0.25), bin_counts[4,3]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[0,6], 0.5), bin_counts[0,6]\n",
    "assert np.isclose(bin_counts[1,6], 0.5), bin_counts[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D test of CIC binning\n",
    "data_3d = np.array([\n",
    "    [0.0, 0.0, 0.0],  # Test corner case\n",
    "    [1.5, 1.5, 1.5],  # Test middle case\n",
    "    [10.0, 10.0, -10.0],  #  edge case\n",
    "    [0.0, -1.0, 1.6]\n",
    "])\n",
    "first_dim_3d = np.linspace(0, 3, 4)\n",
    "second_dim_3d = np.linspace(0, 4, 5)\n",
    "third_dim_3d = np.linspace(0, 2, 3)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_3d = cic_binning(data_3d, [first_dim_3d, second_dim_3d, third_dim_3d])\n",
    "print(bin_counts_3d)\n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_3d) == (4, 5, 3), np.shape(bin_counts_3d)\n",
    "assert np.isclose(np.sum(bin_counts_3d), len(data_3d)), np.sum(bin_counts_3d)\n",
    "assert np.isclose(bin_counts_3d[0,0,0], 1.0), bin_counts_3d[0,0,0]\n",
    "assert np.isclose(bin_counts_3d[1,1,1], 1/8), bin_counts_3d[1,1,1]\n",
    "assert np.isclose(bin_counts_3d[1,1,2], 1/8), bin_counts_3d[1,1,2]\n",
    "assert np.isclose(bin_counts_3d[1,2,1], 1/8), bin_counts_3d[1,2,1]\n",
    "assert np.isclose(bin_counts_3d[1,2,2], 1/8), bin_counts_3d[1,2,2]\n",
    "assert np.isclose(bin_counts_3d[2,1,1], 1/8), bin_counts_3d[2,1,1]\n",
    "assert np.isclose(bin_counts_3d[2,1,2], 1/8), bin_counts_3d[2,1,2]\n",
    "assert np.isclose(bin_counts_3d[2,2,1], 1/8), bin_counts_3d[2,2,1]\n",
    "assert np.isclose(bin_counts_3d[2,2,2], 1/8), bin_counts_3d[2,2,2]\n",
    "assert np.isclose(bin_counts_3d[3,4,0], 1.0), bin_counts_3d[3,4,0]\n",
    "assert np.isclose(bin_counts_3d[0,0,1], 0.4), bin_counts_3d[3,4,1]\n",
    "assert np.isclose(bin_counts_3d[0,0,2], 0.6), bin_counts_3d[3,4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with weights\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim], weights=[0.66, 2.99])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 0.66), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 2.99), bin_counts[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with repeats\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 0.0), bin_counts[0,1]\n",
    "assert np.isclose(bin_counts[1,0], 0.0), bin_counts[1,0]\n",
    "assert np.isclose(bin_counts[1,1], 3.0), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-1.0, -1.2],  \n",
    "    [0.5, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(-1, 1, 3)\n",
    "second_dim  = np.linspace(-1, 1, 3)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (3, 3), np.shape(bin_counts)\n",
    "assert np.isclose(np.sum(bin_counts), 2.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[1,2], 0.5), bin_counts[1,1]\n",
    "assert np.isclose(bin_counts[2,2], 0.5), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with log data\n",
    "data_2d = np.array([\n",
    "    [3.0, 1.0],  # 1000.0, 1.0\n",
    "    [1.5, 2.0],  # 31.6, 2.0\n",
    "])\n",
    "first_dim  = np.linspace(1, 4, 4) # log data though; 10 100 1000 10000\n",
    "second_dim  = np.linspace(0, 3, 4)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim], logscale=[10, False])\n",
    "print(bin_counts)\n",
    "print(data_2d)\n",
    "\n",
    "assert np.shape(bin_counts) == (4, 4), np.shape(bin_counts)\n",
    "assert np.isclose(np.sum(bin_counts), 2.0), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[2,1], 1.0), bin_counts[2,1]\n",
    "assert bin_counts[0,2] > 0.75, bin_counts[0,2] # 10^1.5 ~ 31.6, compared to 10 vs 100\n",
    "assert bin_counts[1,2] < 0.25, bin_counts[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with log data\n",
    "data = np.array([16.4, 18.05])\n",
    "print(APP_MAG_BINS)\n",
    "\n",
    "bin_counts = cic_binning(data, [APP_MAG_BINS], logscale=[2.5])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == np.shape(APP_MAG_BINS)\n",
    "assert bin_counts[2] > 0.7, bin_counts[2]\n",
    "assert bin_counts[5] < 0.1, bin_counts[2]\n",
    "assert bin_counts[6] > 0.9, bin_counts[2]\n",
    "assert bin_counts[7] == 0, bin_counts[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress test of CIC binning\n",
    "data_stress = np.random.rand(1000000, 5) # 5M rows of random data\n",
    "dim_stress = np.linspace(0, 1, 11)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_stress = cic_binning(data_stress, [dim_stress, dim_stress, dim_stress, dim_stress, dim_stress])   \n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_stress) == (11, 11, 11, 11, 11), np.shape(bin_counts_stress)\n",
    "assert np.isclose(np.sum(bin_counts_stress), len(data_stress)), np.sum(bin_counts_stress)\n",
    "\n",
    "with np.printoptions(precision=1, suppress=True, linewidth=100):\n",
    "    print(np.sum(np.sum(np.sum(bin_counts_stress, axis=0), axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-0.01, APP_MAG_BINS[3]],  \n",
    "    [0.01, APP_MAG_BINS[3]],  \n",
    "    [0.03, APP_MAG_BINS[3]],  \n",
    "    [0.12, APP_MAG_BINS[3]],  \n",
    "    [0.21, APP_MAG_BINS[3]],  \n",
    "    [0.40, APP_MAG_BINS[3]],  \n",
    "    [0.50, APP_MAG_BINS[5]],  \n",
    "])\n",
    "first_dim  = Z_BINS\n",
    "second_dim  = APP_MAG_BINS\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True, linewidth=200):\n",
    "    print(bin_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D test with uneven bins\n",
    "data_1d = np.array([\n",
    "    2.5,\n",
    "    4.0, \n",
    "    14.0,\n",
    "])\n",
    "first_dim  = np.array([0, 1, 3, 4, 5, 15])\n",
    "\n",
    "bin_counts = cic_binning(data_1d, [first_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6,), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_1d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0], 0)\n",
    "assert np.isclose(bin_counts[1], 0.25)\n",
    "assert np.isclose(bin_counts[2], 0.75)\n",
    "assert np.isclose(bin_counts[3], 1.0)\n",
    "assert np.isclose(bin_counts[4], 0.1)\n",
    "assert np.isclose(bin_counts[5], 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: which is faster, boolean indexing or integer indexing?\n",
    "arr = np.random.rand(20000000)\n",
    "bool_filter = arr < 0.1\n",
    "N = 20\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "test2 = np.zeros(len(arr))\n",
    "t1 = time.time()\n",
    "for n in range(N):\n",
    "    test += arr[bool_filter]\n",
    "    test2[bool_filter] += arr[bool_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for bool filter: {t2-t1}\")\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "t1 = time.time()\n",
    "idx_filter = np.flatnonzero(bool_filter)\n",
    "for n in range(N):\n",
    "    test += arr[idx_filter]\n",
    "    test2[idx_filter] += arr[idx_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for idx filter: {t2-t1}\")\n",
    "\n",
    "# Answer: idx filter is faster. And order doesn't matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function signature is write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base, frac_area):\n",
    "\n",
    "# Generate some sample data to write\n",
    "NUM_ROWS = 500000\n",
    "ra = np.random.rand(NUM_ROWS)\n",
    "dec = np.random.rand(NUM_ROWS)\n",
    "z_eff = np.random.rand(NUM_ROWS)\n",
    "log_L_gal = np.random.rand(NUM_ROWS)\n",
    "V_max = np.random.rand(NUM_ROWS)\n",
    "colors = np.random.randint(0, 2, NUM_ROWS)\n",
    "chi = np.random.rand(NUM_ROWS)\n",
    "outname_base2 = OUTPUT_FOLDER + 'speed-write-test2'\n",
    "\n",
    "# Write data using write_dat_files\n",
    "start_time = time.time()\n",
    "write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base2)\n",
    "end_time = time.time()\n",
    "time_v2 = end_time - start_time\n",
    "\n",
    "# Compare the contents of the two files\n",
    "with open(outname_base2 + '.dat', 'rb') as f2:\n",
    "    data_v2 = f2.read()\n",
    "\n",
    "#assert data_v1.strip() == data_v2.strip(), \"The outputs of write_dat_files and write_dat_files_v2 are not the same\"\n",
    "\n",
    "# Print the time taken by each function\n",
    "print(f\"Time taken by write_dat_files_v2: {time_v2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat1 = np.random.rand(1000,1000)\n",
    "dataMat2 = np.random.rand(2,500000)\n",
    "dataMat3 = np.random.rand(500000,2)\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test1.txt','w') as f:\n",
    "    np.savetxt(f,dataMat1,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test2.txt','w') as f:\n",
    "    np.savetxt(f,dataMat2,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test3.txt','w') as f:\n",
    "    np.savetxt(f,dataMat3,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test4.txt','w') as f:\n",
    "    fmt = ' '.join(['%g']*dataMat3.shape[1])\n",
    "    fmt = '\\n'.join([fmt]*dataMat3.shape[0])\n",
    "    data = fmt % tuple(dataMat3.ravel())        \n",
    "    f.write(data)\n",
    "end = time.perf_counter()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run once, unless you want to change the test data\n",
    "#catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.create_test_dat_files() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Ensure that numerical precision is kept the same from the input to the output files\n",
    "testcat = deepcopy(cat.bgs_sv3_pz_2_6_10p_c2)\n",
    "testcat.sdss_fill = False\n",
    "testcat.preprocess()\n",
    "\n",
    "# read in and print out the first few lines of SV3_test.preprocess_file\n",
    "with open(testcat.preprocess_file, 'r') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')\n",
    "\n",
    "galprops_file = str.replace(testcat.GF_outfile, \".out\", \"_galprops.pkl\")\n",
    "galprops = pickle.load(open(galprops_file, \"rb\"))\n",
    "print(galprops[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test an orphaned satellite in final iteration scenario.\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['iterations'] = 1 # By running with 1 iteration only on these data, we expose a situation where satellites are orphaned in the final iteration\n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "#df=catalog.all_data.loc[catalog.all_data['Z'] < 0.1]\n",
    "#pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)\n",
    "catalog.sanity_tests(skiphod=True) # Includes tests on the orphaned satellites, effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does parallel and serial versions give same assignments after N iterations ?\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "iterations_to_check = [1,2,3,4]\n",
    "for it in iterations_to_check:\n",
    "    catalog.GF_props['iterations'] = it\n",
    "    catalog.run_group_finder(silent=True, serial=True)\n",
    "    catalog.postprocess()\n",
    "    df1 = catalog.all_data.copy()\n",
    "\n",
    "    tests = 5 # Should be stable over multiple runs\n",
    "    while tests > 0:\n",
    "        tests -= 1\n",
    "        catalog.run_group_finder(silent=True, serial=False)\n",
    "        catalog.postprocess()\n",
    "        df2 = catalog.all_data\n",
    "\n",
    "        #with np.printoptions(threshold=sys.maxsize, linewidth=100):\n",
    "            #print(df1['IGRP'].to_numpy()[51])\n",
    "            #print(df2['IGRP'].to_numpy()[51])\n",
    "\n",
    "        # Its possible and OK for P_SAT to differ for centrals near bigger centrals because parallization makes it so that\n",
    "        # althought things end up the same at the end, we may abort checking something earlier in same cases.\n",
    "        sats1 = df1.loc[df1['IS_SAT']]\n",
    "        sats2 = df2.loc[df2['IS_SAT']]\n",
    "\n",
    "        assert np.allclose(df1['IGRP'].to_numpy(), df2['IGRP'].to_numpy()), f\"IGRP does not agree at index {np.where(df1['IGRP'].to_numpy() != df2['IGRP'].to_numpy())[0]}\"\n",
    "        assert np.allclose(sats1['P_SAT'].to_numpy(), sats2['P_SAT'].to_numpy()), f\"P_SAT does not agree at index {np.where(df1['P_SAT'].to_numpy() != df2['P_SAT'].to_numpy())[0]}\"\n",
    "        assert np.allclose(df1['L_TOT'].to_numpy(), df2['L_TOT'].to_numpy()), f\"L_TOT does not agree at index {np.where(df1['L_TOT'].to_numpy() != df2['L_TOT'].to_numpy())[0]}\"\n",
    "        assert np.allclose(df1['M_HALO'].to_numpy(), df2['M_HALO'].to_numpy()), f\"M_HALO does not agree at index {np.where(df1['M_HALO'].to_numpy() != df2['M_HALO'].to_numpy())[0]}\"\n",
    "\n",
    "print(\"Basic parallel stability test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Tests on Test Catalog with multiple iterations\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['iterations'] = 5 \n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "catalog.sanity_tests(skiphod=True) # Includes tests on the orphaned satellites, effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinning Results for Test Catalog\n",
    "\n",
    "# Baseline vanilla group finder test \n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "centrals = df.loc[~df['IS_SAT']]\n",
    "baseline_total_mass = centrals['M_HALO'].sum()\n",
    "assert len(np.unique(df['IGRP'])) == 200, len(np.unique(df['IGRP']))\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "m1=centrals['M_HALO'].to_numpy()\n",
    "\n",
    "# Test that when omega0 are 0, the others don't matter\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['omegaL_sf'] = 123\n",
    "catalog.GF_props['sigma_sf'] = 345\n",
    "catalog.GF_props['omegaL_q'] = 456\n",
    "catalog.GF_props['sigma_q'] = 678\n",
    "catalog.GF_props['omega0_sf'] = 0.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "centrals = df.loc[~df['IS_SAT']]\n",
    "assert len(np.unique(df['IGRP'])) == 200, len(np.unique(df['IGRP']))\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "assert np.isclose(centrals['M_HALO'].sum(), baseline_total_mass)\n",
    "m2=centrals['M_HALO'].to_numpy()\n",
    "assert np.allclose(m1, m2), \"M_HALO should be identical when omega0 are 0\"\n",
    "\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.GF_props['colors'] = 1\n",
    "catalog.GF_props['omegaL_sf'] = 10.0\n",
    "catalog.GF_props['sigma_sf'] = 3.0\n",
    "catalog.GF_props['omegaL_q'] = 0.0\n",
    "catalog.GF_props['sigma_q'] = 0.0\n",
    "catalog.GF_props['omega0_sf'] = 10.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "centrals = df.loc[~df['IS_SAT']]\n",
    "assert len(np.unique(df['IGRP'])) > 200 # these parameters make assigned halos smaller\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert df['WEIGHT'].sum() < 246 \n",
    "# When you change parameters, we get a different total DM mass. Hmm. TODO is this a BUG? \n",
    "#assert np.isclose(centrals['M_HALO'].sum(), baseline_total_mass), f\"Expected {np.log10(baseline_total_mass):.3f}, got {np.log10(centrals['M_HALO'].sum()):.3f}\"\n",
    "m3=centrals['M_HALO'].to_numpy()\n",
    "\n",
    "#bins = np.linspace(11, 14.5, 15)\n",
    "#plt.hist([np.log10(m1), np.log10(m2), np.log10(m3)], bins=bins, label=['Baseline', 'Omega0=0', 'Omega0=10'])\n",
    "#plt.xlabel(\"log10(M_halo)\")\n",
    "#plt.legend()\n",
    "\n",
    "#pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)\n",
    "\n",
    "print(\"Test Catalog Pinning tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing serial vs parallel in full SDSS data with published parameters (SLOW TEST, ~1.5 min)\n",
    "\n",
    "# Version 1 is serial\n",
    "catalog1 = deepcopy(cat.sdss_colors_chi)\n",
    "catalog1.caldata = CalibrationData.SDSS_4bin(catalog1.mag_cut, catalog1.GF_props['frac_area'])\n",
    "catalog1.run_group_finder(popmock=True, silent=True, serial=True)\n",
    "previous_hod = catalog1.hod.copy()\n",
    "gals1 = pd.read_csv(catalog1.GF_outfile, delimiter=' ', names=\n",
    "                          ('RA', 'DEC', 'Z', 'L_GAL', 'VMAX', 'P_SAT', 'M_HALO', 'N_SAT', 'L_TOT', 'IGRP', 'WEIGHT', 'CHI1_WEIGHT'),\n",
    "                          dtype={'RA': np.float64, 'DEC': np.float64, 'Z': np.float64, 'L_GAL': np.float64, 'VMAX': np.float64,\n",
    "                                 'P_SAT': np.float64, 'M_HALO': np.float64, 'N_SAT': np.int32, 'L_TOT': np.float64, 'IGRP': np.int64, 'WEIGHT': np.float64, 'CHI1_WEIGHT': np.float64})\n",
    "\n",
    "# Version 2 is parallel\n",
    "catalog2 = deepcopy(cat.sdss_colors_chi)\n",
    "catalog2.caldata = CalibrationData.SDSS_4bin(catalog2.mag_cut, catalog2.GF_props['frac_area'])\n",
    "catalog2.run_group_finder(popmock=True, silent=True, serial=False)\n",
    "new_hod = catalog2.hod\n",
    "gals2 = pd.read_csv(catalog2.GF_outfile, delimiter=' ', names=\n",
    "                          ('RA', 'DEC', 'Z', 'L_GAL', 'VMAX', 'P_SAT', 'M_HALO', 'N_SAT', 'L_TOT', 'IGRP', 'WEIGHT', 'CHI1_WEIGHT'),\n",
    "                          dtype={'RA': np.float64, 'DEC': np.float64, 'Z': np.float64, 'L_GAL': np.float64, 'VMAX': np.float64,\n",
    "                                 'P_SAT': np.float64, 'M_HALO': np.float64, 'N_SAT': np.int32, 'L_TOT': np.float64, 'IGRP': np.int64, 'WEIGHT': np.float64, 'CHI1_WEIGHT': np.float64})\n",
    "\n",
    "\n",
    "# Passes for serial then serial\n",
    "# TODO BUG Fails for serial then parallel for ~27 IGRPs \n",
    "# That number gets bigger for sdss_colors and bigger again for sdss_colors_chi\n",
    "assert_catalogs_match(gals1, gals2)\n",
    "\n",
    "# Check that the HODs are the same\n",
    "assert np.shape(previous_hod) == np.shape(new_hod), f\"Shape mismatch: {np.shape(previous_hod)} vs {np.shape(new_hod)}\"\n",
    "if not np.allclose(previous_hod, new_hod):\n",
    "    print(\"HOD mismatch detected!\")\n",
    "    #results = np.isclose(previous_hod, new_hod, rtol=0.01, atol=0.0001)\n",
    "    #with np.printoptions(suppress=True, threshold=sys.maxsize, linewidth=500):\n",
    "        #print(previous_hod)\n",
    "        #print(results.astype(int).T)\n",
    "    for row in range(len(previous_hod)):\n",
    "        for col in range(len(previous_hod[row])):\n",
    "            assert np.isclose(previous_hod[row][col], new_hod[row][col]), f\"Row {row}, Col {col} mismatch: {previous_hod[row][col]} vs {new_hod[row][col]}\"\n",
    "\n",
    "print(\"SDSS repeatability test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published = cat.sdss_published\n",
    "published.postprocess()\n",
    "\n",
    "# Compare to published catalog TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hods_from_cpp = hod.HODTabulated.from_cpp(catalog1.hodfit, catalog1.caldata)\n",
    "fig=pp.hod_bins_plot(catalog1, hods_from_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that chi squared values are the same\n",
    "catalog1.calc_wp_for_mock()\n",
    "result1 = catalog1.chisqr()\n",
    "catalog2.calc_wp_for_mock()\n",
    "result2 = catalog2.chisqr()\n",
    "for c in range(len(result1)):\n",
    "    assert np.allclose(result1[c], result2[c]), f\"Chi squared mismatch: {result1[c]} vs {result2[c]}\"\n",
    "\n",
    "#assert np.isclose(result[0], 94.0, rtol=0.0, atol=3.0), \"Chi squared test failed\" # pinning previous result\n",
    "\n",
    "# TODO BUG This fails when running with parallelization on\n",
    "# This is the results you get from serial execution. Parallel version is quite different!! \n",
    "assert np.isclose(result1[0], 107.3, rtol=0.01, atol=1.0), \"Chi squared test failed\" # pinning previous result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger Data Set Stability Test in Serial Mode\n",
    "catalog1 = deepcopy(cat.bgs_sv3_pz_2_6_10p_c2)\n",
    "catalog1.GF_props['iterations'] = 15 # Ensure convergence\n",
    "catalog1.run_group_finder(popmock=False, silent=True, serial=True)\n",
    "catalog1.postprocess()\n",
    "df1 = catalog1.all_data.copy()\n",
    "catalog1.run_group_finder(popmock=False, silent=True, serial=True)\n",
    "catalog1.postprocess()\n",
    "\n",
    "assert_catalogs_match(df1, catalog1.all_data)\n",
    "\n",
    "# And Parallel Mode\n",
    "catalog1.run_group_finder(popmock=False, silent=False, serial=False)\n",
    "catalog1.postprocess()\n",
    "\n",
    "# TODO BUG Fails still\n",
    "assert_catalogs_match(df1, catalog1.all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds should all be fixed such that the chi squared is stable from run to run including python preprocessing\n",
    "catalog = deepcopy(cat.bgs_sv3_pz_2_6_10p_c2)\n",
    "\n",
    "catalog.preprocess()\n",
    "catalog.run_group_finder(popmock=True, silent=True)\n",
    "catalog.calc_wp_for_mock()\n",
    "result1 = catalog.chisqr()\n",
    "\n",
    "catalog.preprocess()\n",
    "catalog.run_group_finder(popmock=True, silent=True)\n",
    "catalog.calc_wp_for_mock()\n",
    "result2 = catalog.chisqr()\n",
    "\n",
    "assert np.isclose(result1[0], result2[0]), \"Chi squared should be stable from run to run\"\n",
    "assert np.isclose(result1[0], 690.8, rtol=0.0, atol=0.1), \"Chi squared should be stable from run to run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = deepcopy(cat.bgs_sv3_pz_2_6_10p_c2)\n",
    "\n",
    "catalog.run_group_finder(popmock=True, silent=False)\n",
    "catalog.calc_wp_for_mock()\n",
    "result1 = catalog.chisqr()\n",
    "\n",
    "hods_from_cpp = hod.HODTabulated.from_cpp(catalog.hod, catalog.caldata) # TODO if this is all set, can save it off (and maybe replace the .hod property)\n",
    "fig=pp.hod_bins_plot(catalog, hods_from_cpp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
