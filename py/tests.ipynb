{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from astropy.table import Table\n",
    "import math\n",
    "import Corrfunc\n",
    "from os.path import dirname, abspath, join as pjoin\n",
    "from Corrfunc.io import read_catalog\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "import plotting as pp\n",
    "import groupcatalog as gc\n",
    "from nnanalysis import *\n",
    "import catalog_definitions as cat\n",
    "from redshift_guesser import SimpleRedshiftGuesser, PhotometricRedshiftGuesser\n",
    "from groupcatalog import TestGroupCatalog, BGSGroupCatalog\n",
    "from calibrationdata import CalibrationData\n",
    "import hod\n",
    "import bgs_helpers\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# timing helper\n",
    "def time_func(func, args, repeats=5):\n",
    "    t0 = time.perf_counter()\n",
    "    out = None\n",
    "    for _ in range(repeats):\n",
    "        out = func(*args)\n",
    "    t1 = time.perf_counter()\n",
    "    return (t1 - t0) / repeats, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that identifying unobserved galaxies from a table works correctly in all cases\n",
    "\n",
    "# Create a test astropy table\n",
    "table = Table()\n",
    "# Add a masked column named 'Z'\n",
    "table['Z'] = np.ma.array([0.1, np.nan, 99.9, 0.4, 0.5], mask=[False, False, False, True, False])\n",
    "unobserved_truth = np.array([False, True, True, True, False])\n",
    "test = bgs_helpers.determine_unobserved_from_z(table['Z'])\n",
    "\n",
    "assert (test == unobserved_truth).all(), f\"determine_unobserved_from_z did not work as expected: {test}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_cache = LuminosityDistanceCache()\n",
    "\n",
    "# Generate a large array of random redshifts\n",
    "test_z = np.random.uniform(0.001, 0.5, 100000)\n",
    "\n",
    "# --- Performance Test ---\n",
    "\n",
    "# 1. Using the cache\n",
    "start_time = time.perf_counter()\n",
    "dist_cached = ld_cache.luminosity_distance(test_z)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Cached lookup took: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# 2. Using astropy directly (will be much slower)\n",
    "start_time = time.perf_counter()\n",
    "dist_astropy = get_cosmology().luminosity_distance(test_z).to(u.Mpc).value\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Astropy direct call took: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# --- Verification ---\n",
    "\n",
    "# Check that the interpolated values are very close to the direct calculation\n",
    "max_rel_error = np.max(np.abs(dist_cached - dist_astropy) / dist_astropy)\n",
    "print(f\"Maximum relative error: {max_rel_error:.2e}\")\n",
    "assert max_rel_error < 1e-6 # Should be very accurate with enough points\n",
    "\n",
    "# --- Roundtrip Test ---\n",
    "test_dist = np.random.uniform(10, 2000, 1000)\n",
    "z_from_dist = ld_cache.z_at_value(test_dist)\n",
    "dist_roundtrip = ld_cache.luminosity_distance(z_from_dist)\n",
    "assert np.allclose(test_dist, dist_roundtrip, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logL = 10\n",
    "answer1 = SOLAR_L_R_BAND - 2.5 * logL\n",
    "answer2 =  SOLAR_L_R_BAND - (logL / 0.39794) # No idea why I used to do this\n",
    "print(f\"answer1: {answer1}, answer2: {answer2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = np.random.uniform(-25, -11, 1000)\n",
    "logL = abs_mag_r_to_log_solar_L(mag)\n",
    "mag_after = log_solar_L_to_abs_mag_r(logL)\n",
    "assert np.allclose(mag, mag_after), \"Magnitude conversion didn't round trip correctly\"\n",
    "\n",
    "lum = abs_mag_r_to_solar_L(mag)\n",
    "mag_after = log_solar_L_to_abs_mag_r(np.log10(lum))\n",
    "assert np.allclose(mag, mag_after), \"Magnitude conversion didn't round trip correctly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# prepare test redshifts\n",
    "z = np.random.uniform(0.001, 0.5, 10000)\n",
    "\n",
    "# warm up / correctness check\n",
    "astropy_volumes = get_cosmology().comoving_volume(z).value\n",
    "my_volumes = get_volume_at_z(z, 1.0)\n",
    "assert np.allclose(astropy_volumes, my_volumes), f\"Volume mismatch (max abs diff={np.max(np.abs(astropy_volumes-my_volumes)):.3e})\"\n",
    "\n",
    "# timing helper\n",
    "def time_func(func, args, repeats):\n",
    "    t0 = time.perf_counter()\n",
    "    out = None\n",
    "    for _ in range(repeats):\n",
    "        out = func(*args)\n",
    "    t1 = time.perf_counter()\n",
    "    return (t1 - t0) / repeats, out\n",
    "\n",
    "repeats = 10\n",
    "t_ast, out_ast = time_func(lambda zz: get_cosmology().comoving_volume(zz).value, (z,), repeats=repeats)\n",
    "t_my, out_my   = time_func(lambda zz: get_volume_at_z(zz, 1.0), (z,), repeats=repeats)\n",
    "\n",
    "print(f\"Astropy comoving_volume: {t_ast:.6f} s/call (avg over {repeats})\")\n",
    "print(f\"get_volume_at_z         : {t_my:.6f} s/call (avg over {repeats})\")\n",
    "print(f\"Astropy / mine ratio    : {t_ast / t_my:.3f}\")\n",
    "\n",
    "# numerical comparison summary\n",
    "max_abs = np.max(np.abs(out_ast - out_my))\n",
    "max_rel = max_abs / np.max(np.abs(out_ast))\n",
    "print(f\"Max abs diff = {max_abs:.6e}, Max rel diff = {max_rel:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = np.array([-19.5, -20.5, -21.5])\n",
    "vmax = get_max_observable_volume(mags, 0.01, 0.5, 19.5, 1.0)  \n",
    "assert vmax[0] < vmax[1] < vmax[2], \"Expected vmax to increase with increasing luminosity\"\n",
    "\n",
    "vmax2 = get_max_observable_volume(mags, 0.1, 0.5, 19.5, 1.0)  \n",
    "assert vmax2[0] < vmax[0], \"Expected vmax to decrease with increasing z_min\"\n",
    "\n",
    "vmax3 = get_max_observable_volume(mags, 0.01, 0.2, 19.5, 1.0)\n",
    "assert vmax3[2] < vmax[2], \"Expected vmax to decrease with decreasing z_max if the galaxy is visible at z_max\"\n",
    "\n",
    "vmax4 = get_max_observable_volume(mags, 0.01, 0.4, 19.5, 1.0)\n",
    "assert vmax4[0] == vmax[0], \"Expected vmax to stay the same if the galaxy is not visible at z_max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_color = GLOBAL_RED_COLOR_CUT - 0.1\n",
    "red_color = GLOBAL_RED_COLOR_CUT + 0.1\n",
    "\n",
    "blue_dn = -1\n",
    "red_dn = 3\n",
    "\n",
    "results = is_quiescent_BGS_dn4000(np.array([7,8,9]), np.array([red_dn, np.nan, blue_dn]), np.array([blue_color, blue_color, red_color]))\n",
    "assert results[0] == True\n",
    "assert results[1] == False\n",
    "assert results[2] == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test of multiple versions of SimpleRedshiftGuesser\n",
    "# Ensure it handles arrays of inputs and gives a reasonable answer for a couple obvious cases\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0,18.0,12.0])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5])\n",
    "t_q = np.array([True, True, False])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([0.1, 0.2, 0.3])\n",
    "nn_dist = np.array([250.0, 3.0, 30.0])\n",
    "nn_q = np.array([True, True, False])\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='5.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='4.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.12, z[2]\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='2.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test on scores from the SV3 bins file \n",
    "target_neighbor= [1,1,1,1,1,8]\n",
    "target_app_mag = [19.0, 19.0, 18.0, 14.0, 19.0, 19.0]\n",
    "target_quiescent = [1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
    "neighbor_z = [0.1, 0.2, 0.05, 0.3, 0.1, 0.1]\n",
    "neighbor_ang_dist = [30.0, 150.0, 2.0, 15.0, 60.0, 60.0]\n",
    "nn_quiescent = [1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE_V2)\n",
    "#nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE)\n",
    "score_b = nna.get_score(target_neighbor, target_app_mag, target_quiescent, neighbor_z, neighbor_ang_dist, nn_quiescent)\n",
    "print(score_b)\n",
    "\n",
    "assert score_b[0] > 0.01, f\"Reasonable parameters should have a non-zero score, but got {score_b[0]}\"\n",
    "#assert score_b[1] < 0.1, f\"Very high angular distance should have a low score, but got {score_b[1]}\" # BUG is it that issue I saw where edge value is True and spreads?\n",
    "assert score_b[2] > 0.4, f\"Very low angular distance should have a high score, but got {score_b[2]}\"\n",
    "assert score_b[3] < 0.1, f\"Bright target with neighbor at high z should have a low score even at close distance {score_b[3]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that Scipy linear interp is doing what we want inside the NNAnalyzer\n",
    "nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE_V2)\n",
    "frac, all_counts, simz_counts = nna.integrate_out_dimension((0,6))\n",
    "\n",
    "print(frac.shape)\n",
    "first=frac[0,0,5,9,5]\n",
    "second=frac[0,0,5,10,5]\n",
    "mid = (first+second)/2\n",
    "print(first, second, mid)\n",
    "\n",
    "score = nna.get_score(None, [(APP_MAG_BINS[9]+APP_MAG_BINS[10]) / 2], [0.0], [Z_BINS[5]], [ANGULAR_BINS[5]], [0.0])\n",
    "\n",
    "assert np.isclose(mid, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tests for PhotometricRedshiftGuesser\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0, 18.0, 12.0, 17.1])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5, 0.9])\n",
    "t_q = np.array([True, True, False, False])\n",
    "t_zphot = np.array([0.105, 0.230, 0.011, 0.070])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([[0.1, 0.2, 0.3, 0.35],\n",
    "                 [0.2, 0.3, 0.1, 0.03]])\n",
    "nn_dist = np.array([[250.0, 3.0,  30.0, 4.0],\n",
    "                    [260.0, 40.0, 40.0, 8.0]])\n",
    "nn_q = np.array([[True, True, False, True],\n",
    "                 [False, False, False, True]])\n",
    "\n",
    "scorer = PhotometricRedshiftGuesser.from_files(BGS_Y3_LOST_APP_TO_Z_FILE, BGS_Y3_LOST_APP_AND_ZPHOT_TO_Z_FILE, NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE_V2, Mode.PHOTOZ_PLUS_v3)\n",
    "scorer.debug = True\n",
    "params = ([0.8104, 0.9215, 2.867 ], [0.9102, 0.7376, 3.0275], [0.8986, 1.0397, 2.6287], [0.7488, 0.9489, 2.9319]) # 3. params\n",
    "\n",
    "z, assignment_type = scorer.choose_redshift(nn_z, nn_dist, t_zphot, t_pobs, t_app_mag, t_q, nn_q, params)\n",
    "\n",
    "print(z)\n",
    "print(assignment_type)\n",
    "\n",
    "# TODO more tests\n",
    "\n",
    "assert assignment_type[0] <= -1, \"Should not use a neighbor\"\n",
    "assert assignment_type[1] == 1, \"should use neighbor 1 \"\n",
    "assert assignment_type[2] <= -1, \"should not use a neighbor\"\n",
    "assert assignment_type[3] == 2, \"should use neighbor 2\"\n",
    "\n",
    "assert np.isnan(z).sum() == 0, \"z should not have any NaNs\"\n",
    "assert z[0] > 0.0, \"z[0] should be greater than 0.0\"\n",
    "assert z[1] == 0.2, \"z[1] should be 0.2\"\n",
    "assert z[2] < 0.1, \"z[2] should be less than 0.1\"\n",
    "assert z[3] == 0.03, \"z[3] should be 0.03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out sim_z_score function\n",
    "# Test out smooth redshift comparison function works as desired for the relevant redshift differences\n",
    "x=np.arange(-0.100, 0.105, 0.0005)\n",
    "plt.plot(x, powerlaw_score_1(0.2, 0.2+x), label=\"Powerlaw 1\")\n",
    "plt.axvline(0.005, color='r')\n",
    "plt.axvline(-0.005, color='r')\n",
    "plt.plot(x, powerlaw_score_2(0.2, 0.2+x), color='purple', label=\"Powerlaw 2\")\n",
    "plt.plot(x, rounded_tophat_score(0.2, 0.2-x), color='g', label=\"close enough smooth\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Redshift difference\")\n",
    "plt.ylabel(\"Similarity score\")\n",
    "\n",
    "# Make sure the extremes are working as expected\n",
    "assert powerlaw_score_1(0.1, 0.3) < 0.01\n",
    "assert powerlaw_score_1(0.2, 0.3) < 0.05 and powerlaw_score_1(0.2, 0.3) > 0.01\n",
    "assert powerlaw_score_1(0.2, 0.25) < 0.1 and powerlaw_score_1(0.2, 0.25) > 0.05\n",
    "assert powerlaw_score_1(0.2, 0.210) > 0.2, powerlaw_score_1(0.2, 0.210)\n",
    "assert powerlaw_score_1(0.2, 0.205) > 0.95, powerlaw_score_1(0.2, 0.205)\n",
    "assert powerlaw_score_1(0.2, 0.203) > 0.99, powerlaw_score_1(0.2, 0.203)\n",
    "assert np.isclose(powerlaw_score_1(0.2, 0.2001), 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIC Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D test of my N-dimensional CIC binning function\n",
    "data_1d = np.array([\n",
    "    0.0, \n",
    "    3.5, \n",
    "])\n",
    "first_dim  = np.linspace(0, 5, 6)\n",
    "\n",
    "bin_counts = cic_binning(data_1d, [first_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6,), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_1d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0], 1)\n",
    "assert np.isclose(bin_counts[3], 0.5)\n",
    "assert np.isclose(bin_counts[4], 0.5)\n",
    "assert np.isclose(bin_counts[5], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D test of my N-dimensional CIC binning function\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0], # Test corner case\n",
    "    [0.0, -0.5], # Test left edge case\n",
    "    [3.5, 3.5], # Test middle case\n",
    "    [2, 5.9],\n",
    "    [0.5, 40.0], # Test right edge case\n",
    "    [-7.0, -3.0], # Extra edge case\n",
    "])\n",
    "first_dim  = np.linspace(0, 5, 6)\n",
    "second_dim  = np.linspace(0, 6, 7)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6, 7), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_2d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 3.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[2,5], 0.1), bin_counts[2,5]\n",
    "assert np.isclose(bin_counts[2,6], 0.9), bin_counts[2,6]\n",
    "assert np.isclose(bin_counts[3,3], 0.25), bin_counts[3,3]\n",
    "assert np.isclose(bin_counts[3,4], 0.25), bin_counts[3,4]\n",
    "assert np.isclose(bin_counts[4,3], 0.25), bin_counts[4,3]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[0,6], 0.5), bin_counts[0,6]\n",
    "assert np.isclose(bin_counts[1,6], 0.5), bin_counts[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D test of CIC binning\n",
    "data_3d = np.array([\n",
    "    [0.0, 0.0, 0.0],  # Test corner case\n",
    "    [1.5, 1.5, 1.5],  # Test middle case\n",
    "    [10.0, 10.0, -10.0],  #  edge case\n",
    "    [0.0, -1.0, 1.6]\n",
    "])\n",
    "first_dim_3d = np.linspace(0, 3, 4)\n",
    "second_dim_3d = np.linspace(0, 4, 5)\n",
    "third_dim_3d = np.linspace(0, 2, 3)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_3d = cic_binning(data_3d, [first_dim_3d, second_dim_3d, third_dim_3d])\n",
    "print(bin_counts_3d)\n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_3d) == (4, 5, 3), np.shape(bin_counts_3d)\n",
    "assert np.isclose(np.sum(bin_counts_3d), len(data_3d)), np.sum(bin_counts_3d)\n",
    "assert np.isclose(bin_counts_3d[0,0,0], 1.0), bin_counts_3d[0,0,0]\n",
    "assert np.isclose(bin_counts_3d[1,1,1], 1/8), bin_counts_3d[1,1,1]\n",
    "assert np.isclose(bin_counts_3d[1,1,2], 1/8), bin_counts_3d[1,1,2]\n",
    "assert np.isclose(bin_counts_3d[1,2,1], 1/8), bin_counts_3d[1,2,1]\n",
    "assert np.isclose(bin_counts_3d[1,2,2], 1/8), bin_counts_3d[1,2,2]\n",
    "assert np.isclose(bin_counts_3d[2,1,1], 1/8), bin_counts_3d[2,1,1]\n",
    "assert np.isclose(bin_counts_3d[2,1,2], 1/8), bin_counts_3d[2,1,2]\n",
    "assert np.isclose(bin_counts_3d[2,2,1], 1/8), bin_counts_3d[2,2,1]\n",
    "assert np.isclose(bin_counts_3d[2,2,2], 1/8), bin_counts_3d[2,2,2]\n",
    "assert np.isclose(bin_counts_3d[3,4,0], 1.0), bin_counts_3d[3,4,0]\n",
    "assert np.isclose(bin_counts_3d[0,0,1], 0.4), bin_counts_3d[3,4,1]\n",
    "assert np.isclose(bin_counts_3d[0,0,2], 0.6), bin_counts_3d[3,4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with weights\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim], weights=[0.66, 2.99])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 0.66), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 2.99), bin_counts[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with repeats\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 0.0), bin_counts[0,1]\n",
    "assert np.isclose(bin_counts[1,0], 0.0), bin_counts[1,0]\n",
    "assert np.isclose(bin_counts[1,1], 3.0), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-1.0, -1.2],  \n",
    "    [0.5, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(-1, 1, 3)\n",
    "second_dim  = np.linspace(-1, 1, 3)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (3, 3), np.shape(bin_counts)\n",
    "assert np.isclose(np.sum(bin_counts), 2.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[1,2], 0.5), bin_counts[1,1]\n",
    "assert np.isclose(bin_counts[2,2], 0.5), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with log data\n",
    "data_2d = np.array([\n",
    "    [3.0, 1.0],  # 1000.0, 1.0\n",
    "    [1.5, 2.0],  # 31.6, 2.0\n",
    "])\n",
    "first_dim  = np.linspace(1, 4, 4) # log data though; 10 100 1000 10000\n",
    "second_dim  = np.linspace(0, 3, 4)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim], logscale=[10, False])\n",
    "print(bin_counts)\n",
    "print(data_2d)\n",
    "\n",
    "assert np.shape(bin_counts) == (4, 4), np.shape(bin_counts)\n",
    "assert np.isclose(np.sum(bin_counts), 2.0), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[2,1], 1.0), bin_counts[2,1]\n",
    "assert bin_counts[0,2] > 0.75, bin_counts[0,2] # 10^1.5 ~ 31.6, compared to 10 vs 100\n",
    "assert bin_counts[1,2] < 0.25, bin_counts[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with log data\n",
    "data = np.array([16.4, 18.05])\n",
    "print(APP_MAG_BINS)\n",
    "\n",
    "bin_counts = cic_binning(data, [APP_MAG_BINS], logscale=[2.5])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == np.shape(APP_MAG_BINS)\n",
    "assert bin_counts[2] > 0.7, bin_counts[2]\n",
    "assert bin_counts[5] < 0.1, bin_counts[2]\n",
    "assert bin_counts[6] > 0.9, bin_counts[2]\n",
    "assert bin_counts[7] == 0, bin_counts[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress test of CIC binning\n",
    "data_stress = np.random.rand(1000000, 5) # 5M rows of random data\n",
    "dim_stress = np.linspace(0, 1, 11)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_stress = cic_binning(data_stress, [dim_stress, dim_stress, dim_stress, dim_stress, dim_stress])   \n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_stress) == (11, 11, 11, 11, 11), np.shape(bin_counts_stress)\n",
    "assert np.isclose(np.sum(bin_counts_stress), len(data_stress)), np.sum(bin_counts_stress)\n",
    "\n",
    "with np.printoptions(precision=1, suppress=True, linewidth=100):\n",
    "    print(np.sum(np.sum(np.sum(bin_counts_stress, axis=0), axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-0.01, APP_MAG_BINS[3]],  \n",
    "    [0.01, APP_MAG_BINS[3]],  \n",
    "    [0.03, APP_MAG_BINS[3]],  \n",
    "    [0.12, APP_MAG_BINS[3]],  \n",
    "    [0.21, APP_MAG_BINS[3]],  \n",
    "    [0.40, APP_MAG_BINS[3]],  \n",
    "    [0.50, APP_MAG_BINS[5]],  \n",
    "])\n",
    "first_dim  = Z_BINS\n",
    "second_dim  = APP_MAG_BINS\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True, linewidth=200):\n",
    "    print(bin_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D test with uneven bins\n",
    "data_1d = np.array([\n",
    "    2.5,\n",
    "    4.0, \n",
    "    14.0,\n",
    "])\n",
    "first_dim  = np.array([0, 1, 3, 4, 5, 15])\n",
    "\n",
    "bin_counts = cic_binning(data_1d, [first_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6,), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_1d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0], 0)\n",
    "assert np.isclose(bin_counts[1], 0.25)\n",
    "assert np.isclose(bin_counts[2], 0.75)\n",
    "assert np.isclose(bin_counts[3], 1.0)\n",
    "assert np.isclose(bin_counts[4], 0.1)\n",
    "assert np.isclose(bin_counts[5], 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: which is faster, boolean indexing or integer indexing?\n",
    "arr = np.random.rand(20000000)\n",
    "bool_filter = arr < 0.1\n",
    "N = 20\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "test2 = np.zeros(len(arr))\n",
    "t1 = time.time()\n",
    "for n in range(N):\n",
    "    test += arr[bool_filter]\n",
    "    test2[bool_filter] += arr[bool_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for bool filter: {t2-t1}\")\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "t1 = time.time()\n",
    "idx_filter = np.flatnonzero(bool_filter)\n",
    "for n in range(N):\n",
    "    test += arr[idx_filter]\n",
    "    test2[idx_filter] += arr[idx_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for idx filter: {t2-t1}\")\n",
    "\n",
    "# Answer: idx filter is faster. And order doesn't matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function signature is write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base, frac_area):\n",
    "\n",
    "# Generate some sample data to write\n",
    "NUM_ROWS = 500000\n",
    "ra = np.random.rand(NUM_ROWS)\n",
    "dec = np.random.rand(NUM_ROWS)\n",
    "z_eff = np.random.rand(NUM_ROWS)\n",
    "log_L_gal = np.random.rand(NUM_ROWS)\n",
    "V_max = np.random.rand(NUM_ROWS)\n",
    "colors = np.random.randint(0, 2, NUM_ROWS)\n",
    "chi = np.random.rand(NUM_ROWS)\n",
    "outname_base2 = OUTPUT_FOLDER + 'speed-write-test2'\n",
    "\n",
    "# Write data using write_dat_files\n",
    "start_time = time.time()\n",
    "write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base2)\n",
    "end_time = time.time()\n",
    "time_v2 = end_time - start_time\n",
    "\n",
    "# Compare the contents of the two files\n",
    "with open(outname_base2 + '.dat', 'rb') as f2:\n",
    "    data_v2 = f2.read()\n",
    "\n",
    "#assert data_v1.strip() == data_v2.strip(), \"The outputs of write_dat_files and write_dat_files_v2 are not the same\"\n",
    "\n",
    "# Print the time taken by each function\n",
    "print(f\"Time taken by write_dat_files_v2: {time_v2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat1 = np.random.rand(1000,1000)\n",
    "dataMat2 = np.random.rand(2,500000)\n",
    "dataMat3 = np.random.rand(500000,2)\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test1.txt','w') as f:\n",
    "    np.savetxt(f,dataMat1,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test2.txt','w') as f:\n",
    "    np.savetxt(f,dataMat2,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test3.txt','w') as f:\n",
    "    np.savetxt(f,dataMat3,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test4.txt','w') as f:\n",
    "    fmt = ' '.join(['%g']*dataMat3.shape[1])\n",
    "    fmt = '\\n'.join([fmt]*dataMat3.shape[0])\n",
    "    data = fmt % tuple(dataMat3.ravel())        \n",
    "    f.write(data)\n",
    "end = time.perf_counter()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run once, unless you want to change the test data\n",
    "#catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.create_test_dat_files() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcat = deepcopy(cat.bgs_sv3_pz_2_6_10p_c2)\n",
    "testcat.sdss_fill = False\n",
    "testcat.preprocess()\n",
    "\n",
    "# read in and print out the first few lines of SV3_test.preprocess_file\n",
    "with open(testcat.preprocess_file, 'r') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')\n",
    "\n",
    "galprops_file = str.replace(testcat.GF_outfile, \".out\", \"_galprops.pkl\")\n",
    "galprops = pickle.load(open(galprops_file, \"rb\"))\n",
    "print(galprops[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test an orphaned satellite in final iteration scenario.\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['iterations'] = 1 # By running with 1 iteration only on these data, we expose a situation where satellites are orphaned in the final iteration\n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "#df=catalog.all_data.loc[catalog.all_data['Z'] < 0.1]\n",
    "#pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)\n",
    "catalog.sanity_tests(skiphod=True) # Includes tests on the orphaned satellites, effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['iterations'] = 5 \n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "#df=catalog.all_data.loc[catalog.all_data['Z'] < 0.1]\n",
    "#pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)\n",
    "catalog.sanity_tests(skiphod=True) # Includes tests on the orphaned satellites, effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C Group Finder Tests\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Baseline vanilla group finder test \n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "baseline_total_mass = df['M_HALO'].sum()\n",
    "assert len(np.unique(df['IGRP'])) == 200, len(np.unique(df['IGRP']))\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "m1=df['M_HALO'].to_numpy()\n",
    "\n",
    "# Test that when omega0 are 0, the others don't matter\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['omegaL_sf'] = 123\n",
    "catalog.GF_props['sigma_sf'] = 345\n",
    "catalog.GF_props['omegaL_q'] = 456\n",
    "catalog.GF_props['sigma_q'] = 678\n",
    "catalog.GF_props['omega0_sf'] = 0.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) == 200, len(np.unique(df['IGRP']))\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "assert np.isclose(df['M_HALO'].sum(), baseline_total_mass)\n",
    "m2=df['M_HALO'].to_numpy()\n",
    "\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.GF_props['colors'] = 1\n",
    "catalog.GF_props['omegaL_sf'] = 10.0\n",
    "catalog.GF_props['sigma_sf'] = 3.0\n",
    "catalog.GF_props['omegaL_q'] = 0.0\n",
    "catalog.GF_props['sigma_q'] = 0.0\n",
    "catalog.GF_props['omega0_sf'] = 10.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) >= 200 # these parameters make assigned halos smaller\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert df['WEIGHT'].sum() < 246 \n",
    "# When you change parameters, we get a different number of gropus and thus total mass.\n",
    "# assert np.isclose(df['M_HALO'].sum(), baseline_total_mass), f\"Expected {np.log10(baseline_total_mass)}, got {np.log10(df['M_HALO'].sum())}\"\n",
    "m3=df['M_HALO'].to_numpy()\n",
    "\n",
    "plt.hist(np.stack([np.log10(m1), np.log10(m2), np.log10(m3)], axis=-1))\n",
    "\n",
    "\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C Group Finder Tests\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Baseline vanilla group finder test \n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "baseline_total_mass = df['M_HALO'].sum()\n",
    "# TODO this result is not stable...\n",
    "assert len(np.unique(df['IGRP'])) == 200, len(np.unique(df['IGRP']))\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "m1=df['M_HALO'].to_numpy()\n",
    "\n",
    "# Test that when omega0 are 0, the others don't matter\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['omegaL_sf'] = 123\n",
    "catalog.GF_props['sigma_sf'] = 345\n",
    "catalog.GF_props['omegaL_q'] = 456\n",
    "catalog.GF_props['sigma_q'] = 678\n",
    "catalog.GF_props['omega0_sf'] = 0.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) == 200, len(np.unique(df['IGRP']))\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert np.isclose(df['WEIGHT'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "assert np.isclose(df['M_HALO'].sum(), baseline_total_mass)\n",
    "m2=df['M_HALO'].to_numpy()\n",
    "\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.GF_props['colors'] = 1\n",
    "catalog.GF_props['omegaL_sf'] = 10.0\n",
    "catalog.GF_props['sigma_sf'] = 3.0\n",
    "catalog.GF_props['omegaL_q'] = 0.0\n",
    "catalog.GF_props['sigma_q'] = 0.0\n",
    "catalog.GF_props['omega0_sf'] = 10.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['IGRP'])) >= 200 # these parameters make assigned halos smaller\n",
    "assert len(df) == 246 \n",
    "assert df['QUIESCENT'].sum() == 129\n",
    "assert df['WEIGHT'].sum() < 246 \n",
    "# TODO BUG I feel like this should be true, but it's not. Weighting doesn't preseve the halo mass function\n",
    "#assert np.isclose(df['M_HALO'].sum(), baseline_total_mass) \n",
    "m3=df['M_HALO'].to_numpy()\n",
    "\n",
    "plt.hist(np.stack([np.log10(m1), np.log10(m2), np.log10(m3)], axis=-1))\n",
    "\n",
    "\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df['DEC']), np.max(df['DEC']), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing repeatability\n",
    "catalog1 = deepcopy(cat.sdss_colors_chi)\n",
    "catalog1.caldata = CalibrationData.SDSS_4bin(catalog1.mag_cut, catalog1.GF_props['frac_area'])\n",
    "catalog1.run_group_finder(popmock=True, silent=True)\n",
    "previous_hod = catalog1.hod.copy()\n",
    "gals1 =  main_df = pd.read_csv(catalog1.GF_outfile, delimiter=' ', names=\n",
    "                          ('RA', 'DEC', 'Z', 'L_GAL', 'VMAX', 'P_SAT', 'M_HALO', 'N_SAT', 'L_TOT', 'IGRP', 'WEIGHT', 'CHI1_WEIGHT'),\n",
    "                          dtype={'RA': np.float64, 'DEC': np.float64, 'Z': np.float64, 'L_GAL': np.float64, 'VMAX': np.float64,\n",
    "                                 'P_SAT': np.float64, 'M_HALO': np.float64, 'N_SAT': np.int32, 'L_TOT': np.float64, 'IGRP': np.int64, 'WEIGHT': np.float64, 'CHI1_WEIGHT': np.float64})\n",
    "\n",
    "catalog2 = deepcopy(cat.sdss_colors_chi)\n",
    "catalog2.caldata = CalibrationData.SDSS_4bin(catalog2.mag_cut, catalog2.GF_props['frac_area'])\n",
    "catalog2.run_group_finder(popmock=True, silent=True)\n",
    "new_hod = catalog2.hod\n",
    "gals2 =  main_df = pd.read_csv(catalog1.GF_outfile, delimiter=' ', names=\n",
    "                          ('RA', 'DEC', 'Z', 'L_GAL', 'VMAX', 'P_SAT', 'M_HALO', 'N_SAT', 'L_TOT', 'IGRP', 'WEIGHT', 'CHI1_WEIGHT'),\n",
    "                          dtype={'RA': np.float64, 'DEC': np.float64, 'Z': np.float64, 'L_GAL': np.float64, 'VMAX': np.float64,\n",
    "                                 'P_SAT': np.float64, 'M_HALO': np.float64, 'N_SAT': np.int32, 'L_TOT': np.float64, 'IGRP': np.int64, 'WEIGHT': np.float64, 'CHI1_WEIGHT': np.float64})\n",
    "\n",
    "assert len(gals1) == len(gals2), f\"Number of galaxies mismatch: {len(gals1)} vs {len(gals2)}\"\n",
    "assert np.allclose(gals1['RA'], gals2['RA'])\n",
    "assert np.allclose(gals1['DEC'], gals2['DEC'])\n",
    "assert np.allclose(gals1['Z'], gals2['Z'])\n",
    "assert np.allclose(gals1['L_GAL'], gals2['L_GAL'])\n",
    "assert np.allclose(gals1['VMAX'], gals2['VMAX'])\n",
    "# TODO BUG This fails when running with parallelization on\n",
    "#assert np.allclose(gals1['IGRP'], gals2['IGRP']), f\"{(gals1['IGRP'] != gals2['IGRP']).sum()} mismatches in IGRP\"\n",
    "#assert np.allclose(gals1['P_SAT'], gals2['P_SAT'])\n",
    "#assert np.allclose(gals1['M_HALO'], gals2['M_HALO'])\n",
    "#assert np.allclose(gals1['N_SAT'], gals2['N_SAT'])\n",
    "#assert np.allclose(gals1['L_TOT'], gals2['L_TOT'])\n",
    "#assert np.allclose(gals1['WEIGHT'], gals2['WEIGHT'])\n",
    "assert np.allclose(gals1['CHI1_WEIGHT'], gals2['CHI1_WEIGHT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check that the HODs are the same to at least 10% precision. \n",
    "# TODO BUG This fails when running with parallelization on. Enough assignments have changed to change HOD\n",
    "assert np.shape(previous_hod) == np.shape(new_hod), f\"Shape mismatch: {np.shape(previous_hod)} vs {np.shape(new_hod)}\"\n",
    "results = np.isclose(previous_hod, new_hod, rtol=0.1, atol=0.0001)\n",
    "#with np.printoptions(suppress=True, threshold=sys.maxsize, linewidth=500):\n",
    "    #print(previous_hod)\n",
    "    #print(results.astype(int).T)\n",
    "for row in range(len(previous_hod)):\n",
    "    for col in range(len(previous_hod[row])):\n",
    "        assert np.isclose(previous_hod[row][col], new_hod[row][col], rtol=0.1, atol=0.0001), f\"Row {row}, Col {col} mismatch: {previous_hod[row][col]} vs {new_hod[row][col]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hods_from_cpp = hod.HODTabulated.from_cpp(catalog1.hod, catalog1.caldata) # TODO if this is all set, can save it off (and maybe replace the .hod property)\n",
    "fig=pp.hod_bins_plot(catalog1, hods_from_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that chi squared values are the same\n",
    "catalog1.calc_wp_for_mock()\n",
    "result1 = catalog1.chisqr()\n",
    "catalog2.calc_wp_for_mock()\n",
    "result2 = catalog2.chisqr()\n",
    "assert np.isclose(result1, result2), f\"Chi squared mismatch: {result1} vs {result2}\"\n",
    "\n",
    "#assert np.isclose(result[0], 94.0, rtol=0.0, atol=3.0), \"Chi squared test failed\" # pinning previous result\n",
    "\n",
    "# TODO BUG This fails when running with parallelization on\n",
    "# This is the results you get from serial execution. Parallel version is quite different!! \n",
    "assert np.isclose(result1[0], 107.3, rtol=0.01, atol=1.0), \"Chi squared test failed\" # pinning previous result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds should all be fixed such that the chi squared is stable from run to run including python preprocessing\n",
    "catalog = deepcopy(cat.bgs_sv3_pz_2_6_10p_c2)\n",
    "\n",
    "catalog.preprocess()\n",
    "catalog.run_group_finder(popmock=True, silent=True)\n",
    "catalog.calc_wp_for_mock()\n",
    "result1 = catalog.chisqr()\n",
    "\n",
    "catalog.preprocess()\n",
    "catalog.run_group_finder(popmock=True, silent=True)\n",
    "catalog.calc_wp_for_mock()\n",
    "result2 = catalog.chisqr()\n",
    "\n",
    "assert np.isclose(result1[0], result2[0]), \"Chi squared should be stable from run to run\"\n",
    "assert np.isclose(result1[0], 690.8, rtol=0.0, atol=0.1), \"Chi squared should be stable from run to run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = deepcopy(cat.bgs_sv3_pz_2_6_10p_c2)\n",
    "\n",
    "catalog.preprocess()\n",
    "catalog.run_group_finder(popmock=True, silent=True)\n",
    "catalog.calc_wp_for_mock()\n",
    "result1 = catalog.chisqr()\n",
    "\n",
    "hods_from_cpp = hod.HODTabulated.from_cpp(catalog.hod, catalog.caldata) # TODO if this is all set, can save it off (and maybe replace the .hod property)\n",
    "fig=pp.hod_bins_plot(catalog, hods_from_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
