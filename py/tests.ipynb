{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from astropy.table import Table\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "import groupcatalog as gc\n",
    "from nnanalysis import *\n",
    "import catalog_definitions as cat\n",
    "from redshift_guesser import SimpleRedshiftGuesser, PhotometricRedshiftGuesser\n",
    "from groupcatalog import TestGroupCatalog, BGSGroupCatalog\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_color = GLOBAL_RED_COLOR_CUT - 0.1\n",
    "red_color = GLOBAL_RED_COLOR_CUT + 0.1\n",
    "\n",
    "blue_dn = -1\n",
    "red_dn = 3\n",
    "\n",
    "results = is_quiescent_BGS_smart(np.array([7,8,9]), np.array([red_dn, np.nan, blue_dn]), np.array([blue_color, blue_color, red_color]))\n",
    "assert results[0] == True\n",
    "assert results[1] == False\n",
    "assert results[2] == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test of multiple versions of SimpleRedshiftGuesser\n",
    "# Ensure it handles arrays of inputs and gives a reasonable answer for a couple obvious cases\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0,18.0,12.0])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5])\n",
    "t_q = np.array([True, True, False])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([0.1, 0.2, 0.3])\n",
    "nn_dist = np.array([250.0, 3.0, 30.0])\n",
    "nn_q = np.array([True, True, False])\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='5.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='4.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1, z[2]\n",
    "\n",
    "simple = SimpleRedshiftGuesser(None, None, ver='2.0')\n",
    "z, assignment_type = simple.choose_redshift(nn_z, nn_dist, t_pobs, t_app_mag, t_q, nn_q)\n",
    "\n",
    "assert not assignment_type[0]\n",
    "assert assignment_type[1]\n",
    "assert not assignment_type[2]\n",
    "assert z[0] > 0.0\n",
    "assert z[1] == 0.2\n",
    "assert z[2] < 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test on scores from the SV3 bins file \n",
    "target_prob_obs = None #[0.5]\n",
    "target_app_mag = [19.0, 19.0, 18.0, 14.0]\n",
    "target_quiescent = [1.0, 0.0, 1.0, 1.0]\n",
    "neighbor_z = [0.1, 0.2, 0.05, 0.3]\n",
    "neighbor_ang_dist = [30.0, 150.0, 2.0, 15.0]\n",
    "nn_quiescent = [1.0, 0.0, 1.0, 1.0]\n",
    "\n",
    "nna = NNAnalyzer_cic.from_results_file(NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE)\n",
    "score_b = nna.get_score(target_prob_obs, target_app_mag, target_quiescent, neighbor_z, neighbor_ang_dist, nn_quiescent)\n",
    "print(score_b)\n",
    "\n",
    "assert score_b[0] > 0.01, f\"Reasonable parameters should have a non-zero score, but got {score_b[0]}\"\n",
    "#assert score_b[1] < 0.1, f\"Very high angular distance should have a low score, but got {score_b[1]}\" # BUG is it that issue I saw where edge value is True and spreads?\n",
    "assert score_b[2] > 0.4, f\"Very low angular distance should have a high score, but got {score_b[2]}\"\n",
    "assert score_b[3] < 0.1, f\"Bright target with neighbor at high z should have a low score even at close distance {score_b[3]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tests for PhotometricRedshiftGuesser\n",
    "\n",
    "# Target (lost galaxies) properties\n",
    "t_app_mag = np.array([19.0,18.0,12.0])\n",
    "t_pobs = np.array([0.5, 0.5, 0.5])\n",
    "t_q = np.array([True, True, False])\n",
    "t_zphot = np.array([0.105, 0.230, 0.011])\n",
    "\n",
    "# Neighbor properties\n",
    "nn_z = np.array([[0.1, 0.2, 0.3],\n",
    "                 [0.2, 0.3, 0.1]])\n",
    "nn_dist = np.array([[250.0, 3.0,  30.0],\n",
    "                    [260.0, 40.0, 40.0]])\n",
    "nn_q = np.array([[True, True, False],\n",
    "                 [False, False, False]])\n",
    "\n",
    "scorer = PhotometricRedshiftGuesser.from_files(BGS_Y3_LOST_APP_TO_Z_FILE, NEIGHBOR_ANALYSIS_SV3_BINS_SMOOTHED_FILE, Mode.PHOTOZ_PLUS_v1)\n",
    "params = ((0.8, 1.0, 3),(0.8, 1.0, 3),(0.8, 1.0, 3),(0.8, 1.0, 3))\n",
    "z, assignment_type = scorer.choose_redshift(nn_z, nn_dist, t_zphot, t_pobs, t_app_mag, t_q, nn_q, params)\n",
    "\n",
    "print(z)\n",
    "print(assignment_type)\n",
    "\n",
    "# TODO more tests\n",
    "\n",
    "assert assignment_type[0] == AssignedRedshiftFlag.PSEUDO_RANDOM.value\n",
    "assert assignment_type[1] == 1, \"should use neighbor 1 \"\n",
    "assert assignment_type[2] == AssignedRedshiftFlag.PSEUDO_RANDOM.value\n",
    "\n",
    "assert np.isnan(z).sum() == 0, \"z should not have any NaNs\"\n",
    "assert z[0] > 0.0, \"z[0] should be greater than 0.0\"\n",
    "assert z[1] == 0.2, \"z[1] should be 0.2\"\n",
    "assert z[2] < 0.1, \"z[2] should be less than 0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out sim_z_score function\n",
    "# Test out smooth redshift comparison function works as desired for the relevant redshift differences\n",
    "x=np.arange(-0.100, 0.105, 0.0005)\n",
    "plt.plot(x, sim_z_score(0.2, 0.2+x))\n",
    "plt.plot(x, close_enough_smooth(0.2, 0.2-x))\n",
    "plt.axvline(0.005, color='g')\n",
    "plt.axvline(-0.005, color='g')\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Redshift difference\")\n",
    "plt.ylabel(\"Similarity score\")\n",
    "\n",
    "# Make sure the extremes are working as expected\n",
    "assert sim_z_score(0.1, 0.3) < 0.01\n",
    "assert sim_z_score(0.2, 0.3) < 0.05 and sim_z_score(0.2, 0.3) > 0.01\n",
    "assert sim_z_score(0.2, 0.25) < 0.1 and sim_z_score(0.2, 0.25) > 0.05\n",
    "assert sim_z_score(0.2, 0.210) > 0.2, sim_z_score(0.2, 0.210)\n",
    "assert sim_z_score(0.2, 0.205) > 0.95, sim_z_score(0.2, 0.205)\n",
    "assert sim_z_score(0.2, 0.203) > 0.99, sim_z_score(0.2, 0.203)\n",
    "assert np.isclose(sim_z_score(0.2, 0.2001), 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIC Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D test of my N-dimensional CIC binning function\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0], # Test corner case\n",
    "    [0.0, -0.5], # Test left edge case\n",
    "    [3.5, 3.5], # Test middle case\n",
    "    [2, 5.9],\n",
    "    [0.5, 40.0], # Test right edge case\n",
    "    [-7.0, -3.0], # Extra edge case\n",
    "])\n",
    "first_dim  = np.linspace(0, 5, 6)\n",
    "second_dim  = np.linspace(0, 6, 7)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (6, 7), np.shape(bin_counts)\n",
    "assert np.sum(bin_counts) == len(data_2d), np.sum(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 3.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[2,5], 0.1), bin_counts[2,5]\n",
    "assert np.isclose(bin_counts[2,6], 0.9), bin_counts[2,6]\n",
    "assert np.isclose(bin_counts[3,3], 0.25), bin_counts[3,3]\n",
    "assert np.isclose(bin_counts[3,4], 0.25), bin_counts[3,4]\n",
    "assert np.isclose(bin_counts[4,3], 0.25), bin_counts[4,3]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[4,4], 0.25), bin_counts[4,4]\n",
    "assert np.isclose(bin_counts[0,6], 0.5), bin_counts[0,6]\n",
    "assert np.isclose(bin_counts[1,6], 0.5), bin_counts[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D test of CIC binning\n",
    "data_3d = np.array([\n",
    "    [0.0, 0.0, 0.0],  # Test corner case\n",
    "    [1.5, 1.5, 1.5],  # Test middle case\n",
    "    [10.0, 10.0, -10.0],  #  edge case\n",
    "    [0.0, -1.0, 1.6]\n",
    "])\n",
    "first_dim_3d = np.linspace(0, 3, 4)\n",
    "second_dim_3d = np.linspace(0, 4, 5)\n",
    "third_dim_3d = np.linspace(0, 2, 3)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_3d = cic_binning(data_3d, [first_dim_3d, second_dim_3d, third_dim_3d])\n",
    "print(bin_counts_3d)\n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_3d) == (4, 5, 3), np.shape(bin_counts_3d)\n",
    "assert np.isclose(np.sum(bin_counts_3d), len(data_3d)), np.sum(bin_counts_3d)\n",
    "assert np.isclose(bin_counts_3d[0,0,0], 1.0), bin_counts_3d[0,0,0]\n",
    "assert np.isclose(bin_counts_3d[1,1,1], 1/8), bin_counts_3d[1,1,1]\n",
    "assert np.isclose(bin_counts_3d[1,1,2], 1/8), bin_counts_3d[1,1,2]\n",
    "assert np.isclose(bin_counts_3d[1,2,1], 1/8), bin_counts_3d[1,2,1]\n",
    "assert np.isclose(bin_counts_3d[1,2,2], 1/8), bin_counts_3d[1,2,2]\n",
    "assert np.isclose(bin_counts_3d[2,1,1], 1/8), bin_counts_3d[2,1,1]\n",
    "assert np.isclose(bin_counts_3d[2,1,2], 1/8), bin_counts_3d[2,1,2]\n",
    "assert np.isclose(bin_counts_3d[2,2,1], 1/8), bin_counts_3d[2,2,1]\n",
    "assert np.isclose(bin_counts_3d[2,2,2], 1/8), bin_counts_3d[2,2,2]\n",
    "assert np.isclose(bin_counts_3d[3,4,0], 1.0), bin_counts_3d[3,4,0]\n",
    "assert np.isclose(bin_counts_3d[0,0,1], 0.4), bin_counts_3d[3,4,1]\n",
    "assert np.isclose(bin_counts_3d[0,0,2], 0.6), bin_counts_3d[3,4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with weights\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim], weights=[0.66, 2.99])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 0.66), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 2.99), bin_counts[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with repeats\n",
    "data_2d = np.array([\n",
    "    [0.0, 0.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "    [1.0, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(0, 1, 2)\n",
    "second_dim  = np.linspace(0, 1, 2)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (2, 2), np.shape(bin_counts)\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,1], 0.0), bin_counts[0,1]\n",
    "assert np.isclose(bin_counts[1,0], 0.0), bin_counts[1,0]\n",
    "assert np.isclose(bin_counts[1,1], 3.0), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-1.0, -1.2],  \n",
    "    [0.5, 1.0],  \n",
    "])\n",
    "first_dim  = np.linspace(-1, 1, 3)\n",
    "second_dim  = np.linspace(-1, 1, 3)\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "print(bin_counts)\n",
    "\n",
    "assert np.shape(bin_counts) == (3, 3), np.shape(bin_counts)\n",
    "assert np.isclose(np.sum(bin_counts), 2.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[0,0], 1.0), bin_counts[0,0]\n",
    "assert np.isclose(bin_counts[1,2], 0.5), bin_counts[1,1]\n",
    "assert np.isclose(bin_counts[2,2], 0.5), bin_counts[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress test of CIC binning\n",
    "data_stress = np.random.rand(1000000, 5) # 5M rows of random data\n",
    "dim_stress = np.linspace(0, 1, 11)\n",
    "\n",
    "# Perform CIC binning\n",
    "bin_counts_stress = cic_binning(data_stress, [dim_stress, dim_stress, dim_stress, dim_stress, dim_stress])   \n",
    "\n",
    "# Assertions to verify the binning results\n",
    "assert np.shape(bin_counts_stress) == (11, 11, 11, 11, 11), np.shape(bin_counts_stress)\n",
    "assert np.isclose(np.sum(bin_counts_stress), len(data_stress)), np.sum(bin_counts_stress)\n",
    "\n",
    "with np.printoptions(precision=1, suppress=True, linewidth=100):\n",
    "    print(np.sum(np.sum(np.sum(bin_counts_stress, axis=0), axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CIC binning with negative dimensional ranges\n",
    "data_2d = np.array([\n",
    "    [-0.01, APP_MAG_BINS[3]],  \n",
    "    [0.01, APP_MAG_BINS[3]],  \n",
    "    [0.03, APP_MAG_BINS[3]],  \n",
    "    [0.12, APP_MAG_BINS[3]],  \n",
    "    [0.21, APP_MAG_BINS[3]],  \n",
    "    [0.40, APP_MAG_BINS[3]],  \n",
    "    [0.50, APP_MAG_BINS[5]],  \n",
    "])\n",
    "first_dim  = Z_BINS\n",
    "second_dim  = APP_MAG_BINS\n",
    "\n",
    "bin_counts = cic_binning(data_2d, [first_dim, second_dim])\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True, linewidth=200):\n",
    "    print(bin_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO not sure what this was\n",
    "\"\"\"\n",
    "with open('SimpleRedshiftGuesserMap.pkl', 'rb') as f:    \n",
    "    app_mag_bins, the_map = pickle.load(f)\n",
    "\n",
    "print(the_map.keys())\n",
    "\n",
    "indexes = [10,11,30,45]\n",
    "# histogram of the map at those indexes\n",
    "for i in indexes:\n",
    "    plt.hist(the_map[i], bins = 20)\n",
    "    plt.title(f'app mag ~ {app_mag_bins[i-1]}')\n",
    "    plt.show()\n",
    "\n",
    "test_mags = np.linspace(12.0, 20.0, 10000)\n",
    "test_z = np.linspace(0.0, 0.5, 10000) * np.random.rand(10000)\n",
    "app_mag_bins, the_map = build_app_mag_to_z_map_new(test_mags, test_z)\n",
    "\n",
    "print(the_map)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: which is faster, boolean indexing or integer indexing?\n",
    "arr = np.random.rand(20000000)\n",
    "bool_filter = arr < 0.1\n",
    "N = 20\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "test2 = np.zeros(len(arr))\n",
    "t1 = time.time()\n",
    "for n in range(N):\n",
    "    test += arr[bool_filter]\n",
    "    test2[bool_filter] += arr[bool_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for bool filter: {t2-t1}\")\n",
    "\n",
    "test = np.zeros(bool_filter.sum())\n",
    "t1 = time.time()\n",
    "idx_filter = np.flatnonzero(bool_filter)\n",
    "for n in range(N):\n",
    "    test += arr[idx_filter]\n",
    "    test2[idx_filter] += arr[idx_filter]\n",
    "t2 = time.time()\n",
    "print(f\"Time for idx filter: {t2-t1}\")\n",
    "\n",
    "# Answer: idx filter is faster. And order doesn't matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function signature is write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base, frac_area):\n",
    "\n",
    "# Generate some sample data to write\n",
    "NUM_ROWS = 500000\n",
    "ra = np.random.rand(NUM_ROWS)\n",
    "dec = np.random.rand(NUM_ROWS)\n",
    "z_eff = np.random.rand(NUM_ROWS)\n",
    "log_L_gal = np.random.rand(NUM_ROWS)\n",
    "V_max = np.random.rand(NUM_ROWS)\n",
    "colors = np.random.randint(0, 2, NUM_ROWS)\n",
    "chi = np.random.rand(NUM_ROWS)\n",
    "outname_base = OUTPUT_FOLDER + 'speed-write-test'\n",
    "outname_base2 = OUTPUT_FOLDER + 'speed-write-test2'\n",
    "\n",
    "# Write data using write_dat_files\n",
    "start_time = time.time()\n",
    "write_dat_files(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base)\n",
    "end_time = time.time()\n",
    "time_v1 = end_time - start_time\n",
    "\n",
    "# Write data using write_dat_files_v2\n",
    "start_time = time.time()\n",
    "write_dat_files_v2(ra, dec, z_eff, log_L_gal, V_max, colors, chi, outname_base2)\n",
    "end_time = time.time()\n",
    "time_v2 = end_time - start_time\n",
    "\n",
    "# Compare the contents of the two files\n",
    "with open(outname_base + '.dat', 'rb') as f1, open(outname_base2 + '.dat', 'rb') as f2:\n",
    "    data_v1 = f1.read()\n",
    "    data_v2 = f2.read()\n",
    "\n",
    "assert data_v1 == data_v2, \"The outputs of write_dat_files and write_dat_files_v2 are not the same\"\n",
    "\n",
    "# Print the time taken by each function\n",
    "print(f\"Time taken by write_dat_files: {time_v1} seconds\")\n",
    "print(f\"Time taken by write_dat_files_v2: {time_v2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat1 = np.random.rand(1000,1000)\n",
    "dataMat2 = np.random.rand(2,500000)\n",
    "dataMat3 = np.random.rand(500000,2)\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test1.txt','w') as f:\n",
    "    np.savetxt(f,dataMat1,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test2.txt','w') as f:\n",
    "    np.savetxt(f,dataMat2,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER +  'test3.txt','w') as f:\n",
    "    np.savetxt(f,dataMat3,fmt='%g',delimiter=' ')\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "start = time.perf_counter()\n",
    "with open(OUTPUT_FOLDER + 'test4.txt','w') as f:\n",
    "    fmt = ' '.join(['%g']*dataMat3.shape[1])\n",
    "    fmt = '\\n'.join([fmt]*dataMat3.shape[0])\n",
    "    data = fmt % tuple(dataMat3.ravel())        \n",
    "    f.write(data)\n",
    "end = time.perf_counter()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run once, unless you want to change the test data\n",
    "#catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.create_test_dat_files() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV3_test = BGSGroupCatalog(\"SV3 Test\", Mode.SIMPLE_v4, 19.5, 21.0, num_passes=10, drop_passes=3, data_cut='sv3', sdss_fill=False)\n",
    "SV3_test.GF_props = cat.GF_PROPS_VANILLA.copy()\n",
    "\n",
    "SV3_test.preprocess()\n",
    "\n",
    "# Read in BGS_SV3_ANY_FULL_FILE and ensure no precision is lost from there to SV3_test.preprocess_file and the like\n",
    "merged_table = Table.read(IAN_BGS_SV3_MERGED_FILE, format='fits')\n",
    "print(merged_table['RA'][0:10])\n",
    "\n",
    "# read in and print out the first few lines of SV3_test.preprocess_file\n",
    "with open(SV3_test.preprocess_file, 'r') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')\n",
    "\n",
    "#with open(SV3_test.preprocess_file + \"~\", 'r') as f:\n",
    "#    for i in range(10):\n",
    "#        print(f.readline(), end='')\n",
    "\n",
    "galprops_file = str.replace(SV3_test.GF_outfile, \".out\", \"_galprops.dat\")\n",
    "with open(galprops_file, 'r') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')\n",
    "\n",
    "#with open(galprops_file + \"~\", 'r') as f:\n",
    "#    for i in range(10):\n",
    "#        print(f.readline(), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C Group Finder Tests\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Baseline vanilla group finder test \n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "baseline_total_mass = df['M_halo'].sum()\n",
    "assert len(np.unique(df['igrp'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['quiescent'].sum() == 129\n",
    "assert np.isclose(df['weight'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "m1=df['M_halo'].to_numpy()\n",
    "\n",
    "# Test that when omega0 are 0, the others don't matter\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['omegaL_sf'] = 123\n",
    "catalog.GF_props['sigma_sf'] = 345\n",
    "catalog.GF_props['omegaL_q'] = 456\n",
    "catalog.GF_props['sigma_q'] = 678\n",
    "catalog.GF_props['omega0_sf'] = 0.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['igrp'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['quiescent'].sum() == 129\n",
    "assert np.isclose(df['weight'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "assert np.isclose(df['M_halo'].sum(), baseline_total_mass)\n",
    "m2=df['M_halo'].to_numpy()\n",
    "\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.GF_props['colors'] = 1\n",
    "catalog.GF_props['omegaL_sf'] = 10.0\n",
    "catalog.GF_props['sigma_sf'] = 3.0\n",
    "catalog.GF_props['omegaL_q'] = 0.0\n",
    "catalog.GF_props['sigma_q'] = 0.0\n",
    "catalog.GF_props['omega0_sf'] = 10.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['igrp'])) >= 200 # these parameters make assigned halos smaller\n",
    "assert len(df) == 246 \n",
    "assert df['quiescent'].sum() == 129\n",
    "assert df['weight'].sum() < 246 \n",
    "# TODO BUG I feel like this should be true, but it's not. Weighting doesn't preseve the halo mass function\n",
    "#assert np.isclose(df['M_halo'].sum(), baseline_total_mass) \n",
    "m3=df['M_halo'].to_numpy()\n",
    "\n",
    "plt.hist(np.stack([np.log10(m1), np.log10(m2), np.log10(m3)], axis=-1))\n",
    "\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting as pp\n",
    "pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df.Dec), np.max(df.Dec), df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC of photo-z-plus results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "import groupcatalog as gc\n",
    "import math\n",
    "#backend = emcee.backends.HDFBackend(\"mcmc17_1_4.h5\", read_only=True)\n",
    "#backend = emcee.backends.HDFBackend(\"mcmc17b_1_5.h5\", read_only=True)\n",
    "#backend = emcee.backends.HDFBackend(\"mcmc17_2_0.h5\", read_only=True)\n",
    "#backend = emcee.backends.HDFBackend(\"mcmc13_2_1.h5\", read_only=True)\n",
    "\n",
    "#backend = emcee.backends.HDFBackend(\"SelfCalGroupFinder/py/mcmc13_2_2.h5\", read_only=True)\n",
    "#backend = emcee.backends.HDFBackend(\"SelfCalGroupFinder/py/mcmc13_1_6.h5\", read_only=True)\n",
    "\n",
    "backend = emcee.backends.HDFBackend(\"SelfCalGroupFinder/py/mcmc13_2_3.h5\", read_only=True)\n",
    "print(backend.shape)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(backend.shape[0], backend.shape[1], gc.log_probability, backend=backend)\n",
    "samples = sampler.get_chain(flat=True)\n",
    "print(f\"Flat iterations run {len(samples)}\")\n",
    "\n",
    "# Get the log probabilities and sort them to find the top N parameter sets\n",
    "log_prob = sampler.get_log_prob(flat=True)\n",
    "top_N = 5  # Number of top parameter sets to display\n",
    "top_indices = np.argsort(log_prob)[::-1]  # Sort in descending order\n",
    "\n",
    "selected_indices = []\n",
    "for idx in top_indices:\n",
    "    params = samples[idx]\n",
    "    if all(not np.all(np.isclose(params, samples[prev_idx], rtol=0.5)) for prev_idx in selected_indices):\n",
    "        selected_indices.append(idx)\n",
    "        if len(selected_indices) >= top_N:\n",
    "            break\n",
    "\n",
    "with np.printoptions(precision=4, suppress=True, linewidth=200):\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        params = samples[idx]\n",
    "        print(f\"Rank {i+1}:\")\n",
    "        print(f\"Parameters: N={int(params[0])} {params[1:4]} {params[4:7]} {params[7:10]} {params[10:13]}\")\n",
    "        print(f\"SCORE: {log_prob[idx]:.4f}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "try:\n",
    "    tau = sampler.get_autocorr_time()\n",
    "    print(tau)\n",
    "except:\n",
    "    print(\"Not burnt in yet\")\n",
    "\n",
    "flatchain = sampler.get_chain(discard=1000, flat=True)\n",
    "print(np.shape(flatchain))\n",
    "fig = corner.corner(flatchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sampler.get_chain(discard=0)\n",
    "print(np.shape(c))\n",
    "\n",
    "for i in range(c.shape[2]):\n",
    "    plt.figure()\n",
    "    plt.plot(c[:,:,i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
