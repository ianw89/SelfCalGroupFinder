{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import fitsio\n",
    "from pycorr import TwoPointCorrelationFunction, TwoPointEstimator, project_to_multipoles, project_to_wp, utils, setup_logging\n",
    "from scipy.optimize import curve_fit\n",
    "from LSS.common_tools import mknz\n",
    "from astropy.table import Table\n",
    "import itertools\n",
    "\n",
    "from dataloc import *\n",
    "from desiclusteringtools import *\n",
    "\n",
    "# MAKE ALL PLOTS TEXT BIGGER\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "# But legend a bit smaller\n",
    "plt.rcParams.update({'legend.fontsize': 12})\n",
    "# Set DPI up a bit\n",
    "plt.rcParams.update({'figure.dpi': 150})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pycorr import TwoPointEstimator\n",
    "\n",
    "def load_allcounts_from_disk(base_dir):\n",
    "    \"\"\"\n",
    "    Recursively searches for and loads all 'allcounts*.npy' files from a base directory.\n",
    "\n",
    "    Parses metadata from the filenames and returns a list of dictionaries, \n",
    "    each containing the loaded data and its associated parameters.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The top-level directory to start the search from.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries. Each dictionary has two keys:\n",
    "              'params': A dictionary of metadata parsed from the filename.\n",
    "              'data': The loaded TwoPointEstimator object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regex to parse the complex filename structure.\n",
    "    # It captures named groups for each parameter.\n",
    "    filename_pattern = re.compile(\n",
    "        r\"allcounts_BGS_BRIGHT\"\n",
    "        r\"(?:_R-(?P<mag_range>\\d{2}-\\d{2}))?\"  # Optional magnitude range\n",
    "        r\"(?:_SERSIC-(?P<sersic>[\\d\\.-]+))?\"  # Optional SERSIC cut\n",
    "        r\"_(?P<sample_type>SF|Q|ALL)\"         # Sample type (SF, Q, or ALL)\n",
    "        r\"_(?P<region>GCcomb)\"                # Region\n",
    "        r\"_(?P<zmin>[\\d\\.]+)\"                 # zmin\n",
    "        r\"_(?P<zmax>[\\d\\.]+)\"                 # zmax\n",
    "        r\"_(?P<weights>[\\w_]+)\"               # Weights\n",
    "        r\"_(?P<bin_type>\\w+)\"                 # Binning type\n",
    "        r\"_njack(?P<njack>\\d+)\"               # njack\n",
    "        r\"_nran(?P<nran>\\d+)\"                 # nran\n",
    "        r\"_split(?P<split>\\d+)\"               # split\n",
    "        r\"\\.npy\"\n",
    "    )\n",
    "\n",
    "    loaded_results = []\n",
    "    print(f\"Searching for allcounts files in: {base_dir}\")\n",
    "\n",
    "    if not os.path.isdir(base_dir):\n",
    "        print(f\"Error: Base directory not found: {base_dir}\")\n",
    "        return []\n",
    "\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            match = filename_pattern.match(file)\n",
    "            if match:\n",
    "                full_path = os.path.join(root, file)\n",
    "                params = match.groupdict()\n",
    "                \n",
    "                print(f\"Found and loading: {file}\")\n",
    "                try:\n",
    "                    # Load the TwoPointEstimator object\n",
    "                    estimator = TwoPointEstimator.load(full_path)\n",
    "                    loaded_results.append({\n",
    "                        'params': params,\n",
    "                        'data': estimator\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"  -> Failed to load {full_path}: {e}\")\n",
    "\n",
    "    print(f\"\\nFinished search. Loaded {len(loaded_results)} files.\")\n",
    "    return loaded_results\n",
    "\n",
    "# Example usage:\n",
    "# Define the base directory where your clustering results are stored.\n",
    "clustering_base_dir = '/global/cfs/cdirs/desi/users/ianw89/newclustering/DA2/LSS/loa-v1/LSScats/v1.1/'\n",
    "all_results = load_allcounts_from_disk(clustering_base_dir)\n",
    "\n",
    "# You can now access the data and parameters like this:\n",
    "if all_results:\n",
    "    print(\"\\nExample of first loaded result:\")\n",
    "    first_result = all_results[0]\n",
    "    print(\"Parameters:\", first_result['params'])\n",
    "    print(\"Data object:\", first_result['data'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wp_results(loaded_results, weight_type):\n",
    "    \"\"\"\n",
    "    Plots wp(rp) for a list of loaded clustering results for a specific weight type.\n",
    "\n",
    "    Creates a figure for each unique magnitude range, with two subplots:\n",
    "    one for Star-Forming (SF) samples and one for Quiescent (Q) samples.\n",
    "    Different SERSIC cuts are shown in shades of blue and red respectively.\n",
    "\n",
    "    Args:\n",
    "        loaded_results (list): The list of dictionaries produced by\n",
    "                               load_allcounts_from_disk.\n",
    "        weight_type (str): The specific weight type to plot (e.g., 'WEIGHT_FKP_V1').\n",
    "    \"\"\"\n",
    "    # Filter results by the specified weight type\n",
    "    filtered_results = [res for res in loaded_results if res['params']['weights'] == weight_type]\n",
    "\n",
    "    if not filtered_results:\n",
    "        print(f\"No results found for weight_type='{weight_type}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Plotting results for weight_type='{weight_type}'\")\n",
    "\n",
    "    # Group results by magnitude range\n",
    "    results_by_mag = {}\n",
    "    for result in filtered_results:\n",
    "        # Filter out 'ALL' sample types as requested\n",
    "        if result['params']['sample_type'] == 'ALL':\n",
    "            continue\n",
    "        mag_range = result['params'].get('mag_range', 'all_magnitudes')\n",
    "        if mag_range not in results_by_mag:\n",
    "            results_by_mag[mag_range] = []\n",
    "        results_by_mag[mag_range].append(result)\n",
    "\n",
    "    # Create one plot for each magnitude range\n",
    "    for mag_range, results in results_by_mag.items():\n",
    "        fig, (ax_sf, ax_q) = plt.subplots(1, 2, figsize=(16, 8), sharey=True, sharex=True)\n",
    "        fig.suptitle(f'Projected Correlation Function (Weights: {weight_type})\\nMagnitude Range: {mag_range}', fontsize=18)\n",
    "\n",
    "        # Separate results into SF and Q\n",
    "        sf_results = sorted([r for r in results if r['params']['sample_type'] == 'SF'],\n",
    "                            key=lambda x: x['params']['sersic'] or '')\n",
    "        q_results = sorted([r for r in results if r['params']['sample_type'] == 'Q'],\n",
    "                           key=lambda x: x['params']['sersic'] or '')\n",
    "\n",
    "        # --- Plot SF (Blue) results ---\n",
    "        if sf_results:\n",
    "            # Create a colormap for different SERSIC values\n",
    "            n_sersic_sf = len(sf_results)\n",
    "            blue_shades = plt.cm.Blues(np.linspace(0.4, 1, n_sersic_sf))\n",
    "\n",
    "            for i, item in enumerate(sf_results):\n",
    "                params = item['params']\n",
    "                estimator = item['data']\n",
    "                color = blue_shades[i]\n",
    "\n",
    "                if int(params['njack']) > 0:\n",
    "                    rp, wp, cov = estimator.get_corr(return_sep=True, return_cov=True, mode='wp')\n",
    "                    wp_err = np.sqrt(np.diag(cov))\n",
    "                else:\n",
    "                    rp, wp = estimator.get_corr(return_sep=True, mode='wp')\n",
    "                    wp_err = None\n",
    "\n",
    "                label = f\"Sersic: {params['sersic'] or 'None'}\"\n",
    "                ax_sf.errorbar(rp, wp, yerr=wp_err, label=label, fmt='o', color=color, capsize=3, alpha=0.8)\n",
    "\n",
    "        ax_sf.set_title('Star-Forming (SF)')\n",
    "        ax_sf.set_xscale('log')\n",
    "        ax_sf.set_yscale('log')\n",
    "        ax_sf.set_xlabel(r'$r_p$ [Mpc/h]')\n",
    "        ax_sf.set_ylabel(r'$w_p(r_p)$')\n",
    "        ax_sf.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "        ax_sf.legend()\n",
    "\n",
    "        # --- Plot Q (Red) results ---\n",
    "        if q_results:\n",
    "            # Create a colormap for different SERSIC values\n",
    "            n_sersic_q = len(q_results)\n",
    "            red_shades = plt.cm.Reds(np.linspace(0.4, 1, n_sersic_q))\n",
    "\n",
    "            for i, item in enumerate(q_results):\n",
    "                params = item['params']\n",
    "                estimator = item['data']\n",
    "                color = red_shades[i]\n",
    "\n",
    "                if int(params['njack']) > 0:\n",
    "                    rp, wp, cov = estimator.get_corr(return_sep=True, return_cov=True, mode='wp')\n",
    "                    wp_err = np.sqrt(np.diag(cov))\n",
    "                else:\n",
    "                    rp, wp = estimator.get_corr(return_sep=True, mode='wp')\n",
    "                    wp_err = None\n",
    "\n",
    "                label = f\"Sersic: {params['sersic'] or 'None'}\"\n",
    "                ax_q.errorbar(rp, wp, yerr=wp_err, label=label, fmt='s', color=color, capsize=3, alpha=0.8)\n",
    "\n",
    "        ax_q.set_title('Quiescent (Q)')\n",
    "        ax_q.set_xscale('log')\n",
    "        ax_q.set_xlabel(r'$r_p$ [Mpc/h]')\n",
    "        ax_q.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "        ax_q.legend()\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle\n",
    "        plt.show()\n",
    "\n",
    "# Now, call the function with the loaded results and a specific weight type\n",
    "# You can change 'WEIGHT_FKP_V1' to any other weight type you have measured.\n",
    "plot_wp_results(all_results, 'pip_bitwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118605ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_comparison(loaded_results):\n",
    "    \"\"\"\n",
    "    Compares wp(rp) for different weight types, holding all other parameters constant.\n",
    "\n",
    "    Generates a plot for each combination of parameters (e.g., mag_range, sersic cut,\n",
    "    sample type) that has been measured with more than one weight type.\n",
    "\n",
    "    Args:\n",
    "        loaded_results (list): The list of dictionaries produced by\n",
    "                               load_allcounts_from_disk.\n",
    "    \"\"\"\n",
    "    # Group results by all parameters except for 'weights'\n",
    "    results_by_params = {}\n",
    "    for res in loaded_results:\n",
    "        p = res['params'].copy()\n",
    "        # The weight type will be used for labeling, not for grouping\n",
    "        p.pop('weights', None)\n",
    "        # Create a stable key from the remaining parameters\n",
    "        key = tuple(sorted(p.items()))\n",
    "\n",
    "        if key not in results_by_params:\n",
    "            results_by_params[key] = []\n",
    "        results_by_params[key].append(res)\n",
    "\n",
    "    print(f\"Found {len(results_by_params)} unique parameter combinations.\")\n",
    "    plots_made = 0\n",
    "\n",
    "    # Iterate through the grouped results and plot comparisons\n",
    "    for param_key, results_list in results_by_params.items():\n",
    "        # Only make a plot if there's more than one weight type to compare\n",
    "        if len(results_list) > 1:\n",
    "            plots_made += 1\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "            # Sort by weight name for consistent plotting\n",
    "            results_list.sort(key=lambda x: x['params']['weights'])\n",
    "\n",
    "            for i, item in enumerate(results_list):\n",
    "                params = item['params']\n",
    "                estimator = item['data']\n",
    "                weight_type = params['weights']\n",
    "\n",
    "                if int(params['njack']) > 0:\n",
    "                    rp, wp, cov = estimator.get_corr(return_sep=True, return_cov=True, mode='wp')\n",
    "                    wp_err = np.sqrt(np.diag(cov))\n",
    "                else:\n",
    "                    rp, wp = estimator.get_corr(return_sep=True, mode='wp')\n",
    "                    wp_err = None\n",
    "\n",
    "                ax.errorbar(rp, wp, yerr=wp_err, label=weight_type, fmt='-o', capsize=3, alpha=0.8)\n",
    "\n",
    "            # Create a descriptive title from the parameters\n",
    "            param_dict = dict(param_key)\n",
    "            title_parts = [\n",
    "                f\"Mag: {param_dict.get('mag_range', 'N/A')}\",\n",
    "                f\"Sersic: {param_dict.get('sersic', 'N/A')}\",\n",
    "                f\"Type: {param_dict.get('sample_type', 'N/A')}\",\n",
    "                f\"z: {param_dict.get('zmin', '?')}-{param_dict.get('zmax', '?')}\"\n",
    "            ]\n",
    "            ax.set_title(\"Weight Comparison: \" + \", \".join(title_parts))\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_xlabel(r'$r_p$ [Mpc/h]')\n",
    "            ax.set_ylabel(r'$w_p(r_p)$')\n",
    "            ax.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "            ax.legend(title=\"Weight Type\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    if plots_made == 0:\n",
    "        print(\"\\nNo parameter sets found with more than one weight type. No comparison plots generated.\")\n",
    "    else:\n",
    "        print(f\"\\nGenerated {plots_made} comparison plots.\")\n",
    "\n",
    "# Call the new function to generate the comparison plots\n",
    "plot_weight_comparison(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20417137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5d73a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
