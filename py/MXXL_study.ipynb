{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as c\n",
    "import h5py\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "import numpy.ma as ma\n",
    "from random import randint\n",
    "from ctypes import c_uint64\n",
    "import pickle\n",
    "from astropy.table import Table\n",
    "import sys\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from pyutils import *\n",
    "from plotting import *\n",
    "from dataloc import *\n",
    "import k_correction as kcorr\n",
    "import kcorr.k_corrections as desikc\n",
    "#import k_corr_new.k_corrections as desikc2\n",
    "from nnanalysis import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXXL Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITWORD = 'bitweight0'\n",
    "BIT_CHOICE = 0\n",
    "FIBER_ASSIGNED_SELECTOR = 2**BIT_CHOICE\n",
    "\n",
    "infile = h5py.File(MXXL_DATA_DIR + 'weights_3pass.hdf5', 'r')\n",
    "\n",
    "dec = infile['Data/dec'][:]\n",
    "ra = infile['Data/ra'][:]\n",
    "z_obs = infile['Data/z_obs'][:]\n",
    "app_mag = infile['Data/app_mag'][:]\n",
    "g_r = infile['Data/g_r'][:]\n",
    "abs_mag = infile['Data/abs_mag'][:] # We aren't using these; computing ourselves. \n",
    "galaxy_type = infile['Data/galaxy_type'][:]\n",
    "mxxl_halo_mass = infile['Data/halo_mass'][:]\n",
    "mxxl_halo_id = infile['Data/mxxl_id'][:]\n",
    "observed = (infile['Weight/'+BITWORD][:] & FIBER_ASSIGNED_SELECTOR ).astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    'dec': dec, \n",
    "    'ra': ra,\n",
    "    'z_obs': z_obs,\n",
    "    'app_mag': app_mag,\n",
    "    'g_r': g_r,\n",
    "    'abs_mag': abs_mag,\n",
    "    'galaxy_type': galaxy_type,\n",
    "    'mxxl_halo_mass': mxxl_halo_mass,\n",
    "    'mxxl_halo_id': mxxl_halo_id,\n",
    "    'observed': observed\n",
    "    })\n",
    "\n",
    "bright_df = df[df.app_mag < 19.5]\n",
    "df20 = df[df.app_mag < 20.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Simple Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_by_app_mag_bins(df):\n",
    "    # Makes bins of app_mag\n",
    "    mag_bins = np.linspace(16, 19.5, 6)\n",
    "    df['mag_bin'] = pd.cut(df.app_mag, mag_bins, labels=False)\n",
    "\n",
    "    color_bins = np.linspace(0.0, 2.0, 200)\n",
    "    z_bins = np.linspace(0, 0.5, 50)\n",
    "\n",
    "    # Make histogram of g_r by the app mag bins\n",
    "    plt.figure()\n",
    "    for bin_num in range(len(mag_bins)-1):\n",
    "        bin_mask = df.mag_bin == bin_num\n",
    "        g_r_bin = df.g_r[bin_mask]\n",
    "        plt.hist(g_r_bin, bins=color_bins, histtype='step', label=f'{mag_bins[bin_num]:.1f} < mag < {mag_bins[bin_num+1]:.1f}', density=True)\n",
    "    plt.xlabel('g-r')\n",
    "    plt.legend()\n",
    "    plt.xlim(0.5, 1.0)\n",
    "\n",
    "    # Make quiescent cut in df\n",
    "    df['quiescent'] = is_quiescent_BGS_gmr(None, df.g_r)\n",
    "\n",
    "    # Make histogram of z_obs by the app mag bins only for quiescent and then not quiescent galaxies\n",
    "    plt.figure()\n",
    "    for bin_num in range(len(mag_bins)-1):\n",
    "        bin_mask = df.mag_bin == bin_num\n",
    "        z_bin = df.z_obs[bin_mask]\n",
    "        plt.hist(z_bin[df.quiescent[bin_mask]], bins=z_bins, histtype='step', label=f'{mag_bins[bin_num]:.1f} < mag < {mag_bins[bin_num+1]:.1f} quiescent', density=True)\n",
    "    plt.xlabel('z_obs')\n",
    "    plt.legend()\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.title('Red galaxies')\n",
    "\n",
    "    plt.figure()\n",
    "    for bin_num in range(len(mag_bins)-1):\n",
    "        bin_mask = df.mag_bin == bin_num\n",
    "        z_bin = df.z_obs[bin_mask]\n",
    "        plt.hist(z_bin[~df.quiescent[bin_mask]], bins=z_bins, histtype='step', label=f'{mag_bins[bin_num]:.1f} < mag < {mag_bins[bin_num+1]:.1f} star-forming', density=True)\n",
    "    plt.xlabel('z_obs')\n",
    "    plt.legend()\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.title('Blue galaxies')\n",
    "\n",
    "    # Make histogram of z_obs by the app mag bins\n",
    "    plt.figure()\n",
    "    for bin_num in range(len(mag_bins)-1):\n",
    "        bin_mask = df.mag_bin == bin_num\n",
    "        z_bin = df.z_obs[bin_mask]\n",
    "        plt.hist(z_bin[df.observed[bin_mask]], bins=z_bins, histtype='step', label=f'{mag_bins[bin_num]:.1f} < mag < {mag_bins[bin_num+1]:.1f}', density=True)\n",
    "    plt.xlabel('z_obs')\n",
    "    plt.legend()\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.title('Observed galaxies')\n",
    "\n",
    "    # Make histogram of the lost galaxies by the app mag bins\n",
    "    plt.figure()\n",
    "    for bin_num in range(len(mag_bins)-1):\n",
    "        bin_mask = df.mag_bin == bin_num\n",
    "        z_bin = df.z_obs[bin_mask]\n",
    "        plt.hist(z_bin[~df.observed[bin_mask]], bins=z_bins, histtype='step', label=f'{mag_bins[bin_num]:.1f} < mag < {mag_bins[bin_num+1]:.1f} lost', density=True)\n",
    "    plt.xlabel('z_obs')\n",
    "    plt.legend()\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.title('Lost galaxies')\n",
    "\n",
    "    # Bin the observed galaxies and the lost ones seperately and then subtract them to see the difference\n",
    "    plt.figure()\n",
    "    for bin_num in range(len(mag_bins)-1):\n",
    "        bin_mask = df.mag_bin == bin_num\n",
    "        z_bin = df.z_obs[bin_mask]\n",
    "        obs_density = np.histogram(z_bin[df.observed[bin_mask]], bins=z_bins, density=True)\n",
    "        lost_density = np.histogram(z_bin[~df.observed[bin_mask]], bins=z_bins, density=True)\n",
    "        plt.plot(z_bins[0:49], lost_density[0]-obs_density[0], label=f'{mag_bins[bin_num]:.1f} < mag < {mag_bins[bin_num+1]:.1f}')\n",
    "    plt.xlabel('z_obs')\n",
    "    plt.legend()\n",
    "    #plt.yscale('log')\n",
    "    plt.title(\"Compare Lost-Observed Distributions\")\n",
    "\n",
    "plots_by_app_mag_bins(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show abs_mag distribution for observed and unobserved galaxies\n",
    "bins = np.linspace(-24, -12, 50)\n",
    "plt.figure()\n",
    "plt.hist(bright_df.abs_mag[bright_df.observed], bins=bins, histtype='step', label='Observed', density=True)\n",
    "plt.hist(bright_df.abs_mag[~bright_df.observed], bins=bins, histtype='step', label='Unobserved', density=True)\n",
    "plt.xlabel('abs_mag')\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "# Show app_mag distribution for observed and unobserved galaxies\n",
    "bins = np.linspace(15, 19.5, 50)\n",
    "plt.figure()\n",
    "plt.hist(bright_df.app_mag[bright_df.observed], bins=bins, histtype='step', label='Observed', density=True)\n",
    "plt.hist(bright_df.app_mag[~bright_df.observed], bins=bins, histtype='step', label='Unobserved', density=True)\n",
    "plt.xlabel('app_mag')\n",
    "#plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = df.app_mag < 19.5\n",
    "df = df[keep].reset_index(drop=True)\n",
    "indexes_assigned = np.argwhere(df.observed)\n",
    "assert np.max(indexes_assigned) <= len(df), \"Indexes not assigned are out of range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks a lot like BGS, 0.76 is fine for color cut\n",
    "junk=plt.hist(df.g_r, bins=100)\n",
    "plt.xlim(0.5, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CUT_INDEX = 1000000 #21201544 #3000000 \n",
    "\n",
    "weights = h5py.File(MXXL_DATA_DIR + 'weights_3pass.hdf5', 'r')\n",
    "print(list(weights))\n",
    "print(list(weights['Data']))\n",
    "print(list(weights['Weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_z_obs = weights['Data/z_obs'][0:DATA_CUT_INDEX]\n",
    "angular_bins = plt.hist(small_z_obs, bins=50)\n",
    "plt.xlabel(\"$z_{obs}$\")\n",
    "plt.title(\"Histogram of Observed Redshifts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxxl_ra = weights['Data/ra'][0:DATA_CUT_INDEX]\n",
    "mxxl_dec = weights['Data/dec'][0:DATA_CUT_INDEX]\n",
    "mxxl_app_mag = weights['Data/app_mag'][0:DATA_CUT_INDEX]\n",
    "bright_filter = mxxl_app_mag < 19.5 \n",
    "mxxl_ra_bright = mxxl_ra[bright_filter]\n",
    "mxxl_dec_bright = mxxl_dec[bright_filter]  \n",
    "mxxl_app_mag_bright = mxxl_app_mag[bright_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimate_frac_area(mxxl_ra, mxxl_dec))\n",
    "print(estimate_frac_area(mxxl_ra_bright, mxxl_dec_bright))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_indices = np.random.choice(len(mxxl_ra), len(mxxl_ra)//50, replace=False)\n",
    "fig = make_map(mxxl_ra[rnd_indices], mxxl_dec[rnd_indices]), # This looks like Alex' paper, good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mxxl_halo_id = weights['Data/mxxl_id'][0:DATA_CUT_INDEX]\n",
    "np.sum(mxxl_halo_id == 0) / len(mxxl_halo_id)\n",
    "# 2.5% of galaxies have 0 for the MXXL Halo ID because that are in halos that were added by hand post-simulation\n",
    "# This was done because the small halos were not resolved in the simulation\n",
    "# Gal type 2 and 3 are central and satellite galaxies that were unresolved\n",
    "\n",
    "small_gal_type = weights['Data/galaxy_type'][0:DATA_CUT_INDEX]\n",
    "\n",
    "weird_indexes = np.argwhere(np.invert(mxxl_halo_id.astype(bool)))\n",
    "weird_types = small_gal_type[weird_indexes]\n",
    "trash = plt.hist(weird_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_mag = df.app_mag.to_numpy()\n",
    "angular_bins = plt.hist(app_mag, bins=50)\n",
    "plt.xlabel(\"Apparent Mag\")\n",
    "plt.title(\"Histogram of Apparent Mags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density of galaxies per sq degree\n",
    "print(f\"There are ~{np.sum(df.app_mag < 19.5) / 14000:.0f} galaxies/deg^2 < 19.5 mag\")\n",
    "print(f\"There are ~{np.sum(np.all([df.app_mag > 19.5, df.app_mag < 20.0], axis=0)) / 14000:.0f} galaxies/deg^2 between 19.5 and 20.0 mag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abs Mag, K correction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_obs = df.z_obs.to_numpy()\n",
    "g_r = df.g_r.to_numpy()\n",
    "\n",
    "R = app_mag_to_abs_mag(df.app_mag.to_numpy(), z_obs)\n",
    "\n",
    "kcorr_r_gama = kcorr.GAMA_KCorrection(band='R')\n",
    "R_k_GAMA = R - kcorr_r_gama.k(z_obs, g_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcorr_r_bgs  = desikc.DESI_KCorrection(band='R', file='jmext', photsys='N')\n",
    "R_k_BGS = R - kcorr_r_bgs.k(z_obs, g_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcorr_r_bgs2  = desikc.DESI_KCorrection(band='R', file='jmext', photsys='S')\n",
    "R_k_BGS2 = R - kcorr_r_bgs.k(z_obs, g_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N vs S doesn't matter\n",
    "np.sum(np.isclose(R_k_BGS, R_k_BGS2, rtol=10E-6)) / len(R_k_BGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare my_abs_mag to abs_mag. \n",
    "bins = np.linspace(-25, -10, 100)\n",
    "#my_counts, my_bins, my_p = plt.hist(R, label=\"my abs_mag\", bins=bins, alpha=0.5)\n",
    "#alex_counts, alex_bins, alex_p = plt.hist(df.abs_mag.to_numpy(), label=\"alex abs_mag\", bins=bins, alpha=0.5)\n",
    "my_k_counts, my_k_bins, my_k_p = plt.hist(R_k_GAMA, label=\"my GAMA k abs_mag\", bins=bins, alpha=0.5)\n",
    "my_k_counts, my_k_bins, my_k_p = plt.hist(R_k_BGS, label=\"my BGS k abs_mag N\", bins=bins, alpha=0.5)\n",
    "#my_k_counts, my_k_bins, my_k_p = plt.hist(R_k_BGS2, label=\"my BGS k abs_mag S\", bins=bins, alpha=0.5)\n",
    "#z = plt.hist(my_abs_mag_k, label=\"my k abs_mag\", bins=50)\n",
    "plt.xlabel(\"Absolute Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Compare Absolute Mags\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "#print(f\"The peaks are Alex: {alex_bins[np.argmax(alex_counts)]:.1f}, My {my_bins[np.argmax(my_counts)]:.1f}, My K {my_k_bins[np.argmax(my_k_counts)]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a reasonable z fudge factor for 'close enough' redshifts given galaxies $v_{\\mathrm{pec}}$?\n",
    "\n",
    "Galaxies move at hundreds of km/s usually, or thousands in a rich cluster.\n",
    "\n",
    "Two galaxies moving at 750 km/s towards each other along LOS but at same cosmological redshift would have a total redshift difference of 0.005.\n",
    "\n",
    "Adopting z +/- 0.005 is a generous definition then that works for somewhat extremal cases in richer areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a reasonable z +/- fudge factor for 'close enough' redshifts? \n",
    "# Consider peculiar velocities.\n",
    "z_test = [0.001, 0.002, 0.003, 0.005, 0.01] * u.dimensionless_unscaled\n",
    "v_pec = z_test.to(u.km / u.s, u.equivalencies.doppler_redshift())\n",
    "for i in range(len(z_test)):\n",
    "    print(f\"z={z_test[i]:.3f} is {v_pec[i]:.0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Truth Abs Mag for Correcting\n",
    "\n",
    "This is for the 'fancy' approach that we don't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_mag = weights['Data/app_mag'][:]\n",
    "z_obs = weights['Data/z_obs'][:]\n",
    "APP_MAG_CUT = 19.5\n",
    "bright_filter = app_mag < APP_MAG_CUT \n",
    "redshift_filter = z_obs > 0 \n",
    "keep = np.all([bright_filter, redshift_filter], axis=0)\n",
    "\n",
    "app_mag = app_mag[keep]\n",
    "z_obs = z_obs[keep]\n",
    "\n",
    "my_abs_mag = app_mag_to_abs_mag(app_mag, z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_bins = np.linspace(min(my_abs_mag), max(my_abs_mag), 100)\n",
    "densities, angular_bins  = np.histogram(my_abs_mag, bins=angular_bins, density=True)\n",
    "t = plt.hist(my_abs_mag, angular_bins, density=True)\n",
    "\n",
    "with open('bin/abs_mag_weight.npy', 'wb') as f:\n",
    "    np.save(f, densities, allow_pickle=False)\n",
    "    np.save(f, angular_bins, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bin/abs_mag_weight.npy', 'rb') as f:\n",
    "    densities = np.load(f)\n",
    "    angular_bins = np.load(f)\n",
    "\n",
    "plt.plot(angular_bins[0:99], densities)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build map of apparent mag to z distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all galaxies\n",
    "app_mag_bins, the_map = build_app_mag_to_z_map(df20.app_mag, df20.z_obs)\n",
    "\n",
    "# Now use only lost galaxies\n",
    "lost_df = df20[~df20.observed]\n",
    "app_mag_bins2, the_map2 = build_app_mag_to_z_map(lost_df.app_mag, lost_df.z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "trash=plt.hist(the_map[10],bins=30, color='blue', density=True, histtype='step')\n",
    "trash=plt.hist(the_map[50],bins=30, color='red', density=True, histtype='step')\n",
    "trash=plt.hist(the_map[90],bins=30, color='green',  density=True, histtype='step')\n",
    "trash=plt.hist(the_map2[10],bins=30, color='cyan', density=True, histtype='step')\n",
    "trash=plt.hist(the_map2[50],bins=30, color='orange', density=True, histtype='step')\n",
    "trash=plt.hist(the_map2[90],bins=30, color='lightgreen', density=True, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lost_df))\n",
    "print(len(df20))\n",
    "\n",
    "with open(IAN_MXXL_LOST_APP_TO_Z_FILE, 'wb') as f:\n",
    "    pickle.dump((app_mag_bins2, the_map2), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(IAN_MXXL_LOST_APP_TO_Z_FILE, 'rb') as f:\n",
    "    app_mag_bins_read, the_map_read = pickle.load(f)\n",
    "\n",
    "assert len(the_map_read[5]) == len(the_map2[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Angular Separation and Same-Halo Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_MAG_CUT = 20.0\n",
    "bright_filter = app_mag < APP_MAG_CUT # makes a filter array (True/False values)\n",
    "redshift_filter = z_obs > 0 # makes a filter array (True/False values)\n",
    "keep = np.all([bright_filter, redshift_filter], axis=0)\n",
    "\n",
    "dec = dec[keep]\n",
    "ra = ra[keep]\n",
    "z_obs = z_obs[keep]\n",
    "app_mag = app_mag[keep]\n",
    "mxxl_halo_id = mxxl_halo_id[keep]\n",
    "g_r = g_r[keep]\n",
    "quiescent = is_quiescent_BGS_gmr(None, g_r)\n",
    "observed = observed[keep]\n",
    "unobserved = np.invert(observed)\n",
    "\n",
    "with open(MXXL_PROB_OBS_FILE, 'rb') as f:\n",
    "    prob_obs = np.load(f)\n",
    "prob_obs_cut = prob_obs[keep]\n",
    "\n",
    "try:\n",
    "    with open(MXXL_ABS_MAG_R_FILE, 'rb') as f:\n",
    "        abs_mag = pickle.load(f)\n",
    "except:\n",
    "    print(\"Error getting abs mag\")\n",
    "    abs_mag = app_mag_to_abs_mag_k(app_mag, z_obs, g_r, band='r')\n",
    "    with open(MXXL_ABS_MAG_R_FILE, 'wb') as f:\n",
    "        pickle.dump(abs_mag, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = NNAnalyzer(dec, ra, z_obs, app_mag, abs_mag, mxxl_halo_id, g_r, quiescent, observed, prob_obs_cut)\n",
    "obj.set_row_locator( app_mag < 19.5 ) # BRIGHT only\n",
    "obj.find_nn_properties(LOST_GALAXIES_ONLY=True)\n",
    "obj.make_bins()\n",
    "\n",
    "print(np.sum(obj.all_ang_bincounts))\n",
    "print(np.sum(obj.all_same_halo_bincounts))\n",
    "print(np.sum(obj.all_sim_z_bincounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newobj = NNAnalyzer_cic.from_data(dec, ra, z_obs, app_mag, abs_mag, g_r, quiescent, observed, prob_obs_cut)\n",
    "#newobj.set_row_locator(app_mag < 19.5) # BRIGHT only\n",
    "newobj.find_nn_properties(LOST_GALAXIES_ONLY=True) \n",
    "newobj.make_bins()\n",
    "newobj.save(NEIGHBOR_ANALYSIS_MXXL_BINS_FILE)\n",
    "\n",
    "print(np.sum(obj.all_ang_bincounts))\n",
    "print(np.sum(obj.all_sim_z_bincounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows that there is little information in NN ABS MAG\n",
    "obj.plot_angdist_absmag_per_zbin_cc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is good information in Lost app r-mag because it is, statistically a distance proxy!\n",
    "obj.plot_angdist_appmag_per_zbin_cc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.plot_angdist_pobs_per_zbin_cc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newobj.plot_angdist_pobs_per_zbin_cc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.plot_angdist_pobs_per_zbin_cc(simz=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'pobs_bin', 'nn_quiescent', 'quiescent', 'nn1_z_bin', 'app_mag_bin', 'nn_ang_dist_bin']\n",
    "def value_to_key(pobs, nn_q, q, z, mag, dist, nn_abs_mag):\n",
    "    return (np.digitize(pobs, POBS_BINS), nn_q, q, np.digitize(z, Z_BINS), np.digitize(mag, APP_MAG_BINS), np.digitize(dist, ANGULAR_BINS), np.digitize(nn_abs_mag, ABS_MAG_BINS))\n",
    "\n",
    "#print(obj.pt[( 1, True, True, 7.0, 1, 11)])\n",
    "print(obj.pt[value_to_key(0.9, True, True, 0.2, 19.0, 25.0, -20.0)])\n",
    "print(obj.pt[value_to_key(0.9, False, False, 0.2, 19.0, 25.0, -20.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate P_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsum(bitstring):\n",
    "    return bin(c_uint64(bitstring).value).count(\"1\")\n",
    "v_bitsum = np.vectorize(bitsum)\n",
    "\n",
    "def summate(a):\n",
    "    return np.sum(v_bitsum(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this if iips were loaded OK. Takes ~8 minutes.\n",
    "\n",
    "# Read all 32 64-bitstrings into memory from the file\n",
    "num_bitstrings = 32\n",
    "galaxy_count = len(input['Weight/bitweight0'])\n",
    "bitweights = np.empty((num_bitstrings, galaxy_count), dtype='i8')\n",
    "\n",
    "for i in range(num_bitstrings):\n",
    "    bitweights[i] = input['Weight/bitweight{0}'.format(i)][:]\n",
    "    \n",
    "prob_obs = np.apply_along_axis(summate, 0, bitweights) / 2048\n",
    "\n",
    "with open('bin/prob_obs.npy', 'wb') as f:\n",
    "    np.save(f, prob_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specimen = 123\n",
    "bit_selector = c_uint64(2).value\n",
    "print('{:064b}'.format(bit_selector))\n",
    "print('')\n",
    "for i in range(num_bitstrings):\n",
    "    value = bitweights[(i,specimen)]\n",
    "    converted = c_uint64(value).value\n",
    "    print('{:064b}'.format(converted), '{:2.0f}'.format(bitsum(value)), bool(converted & bit_selector))\n",
    "\n",
    "print(\"Averaged Probability of being targetted: \", prob_obs[specimen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_obs_cut = prob_obs[keep]\n",
    "\n",
    "pobs_bins_temp = np.linspace(0,1)\n",
    "trash=plt.hist(prob_obs, bins=pobs_bins_temp, label=\"All galaxies\")\n",
    "trash2=plt.hist(prob_obs_cut, bins=pobs_bins_temp, label=f\"Galaxies below {APP_MAG_CUT} mag\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_obs_dim = prob_obs[np.invert(keep)]\n",
    "trash=plt.hist(prob_obs_dim, bins=pobs_bins_temp, alpha=0.5, label=f\"Galaxies above {APP_MAG_CUT} mag\")\n",
    "trash2=plt.hist(prob_obs_cut, bins=pobs_bins_temp, alpha=0.5, label=f\"Galaxies below {APP_MAG_CUT} mag\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$P_{obs}$')\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to fit the 40% NN success curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_nn_same_halo(ang_dist, nn_z, my_app_mag, my_pobs):\n",
    "    my_ang_bin = np.digitize(ang_dist, obj.angular_bins)\n",
    "    nn_z_bin = np.digitize(nn_z, z_bins)\n",
    "    my_app_mag_bin = np.digitize(my_app_mag, obj.app_mag_bins)\n",
    "    my_pobs_bin = np.digitize(my_pobs, obj.POBS_bins)\n",
    "    \n",
    "    #print(f\"There are {all_ang_bincounts_2[my_pobs_bin,0,nn_z_bin,my_app_mag_bin,my_ang_bin]} galaxies in this bin\")\n",
    "    return obj.frac_same_halo_full[my_pobs_bin,0,nn_z_bin,my_app_mag_bin, my_ang_bin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob_nn_same_halo(13, 0.13, 16.7, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_nn_same_halo_index(my_ang_bin, nn_z_bin, my_app_mag_bin, my_pobs_bin):\n",
    "    return obj.frac_same_halo_full[my_pobs_bin,0,nn_z_bin,my_app_mag_bin, my_ang_bin]\n",
    "\n",
    "#all_ang_bincounts_2 = np.ones((POBS_BIN_COUNT, len(nn_bins), len(z_bins), APP_MAG_BIN_COUNT, BIN_COUNT))\n",
    "#all_same_halo_bincounts_2 = np.zeros((POBS_BIN_COUNT, len(nn_bins), len(z_bins), APP_MAG_BIN_COUNT, BIN_COUNT))\n",
    "#all_sim_z_bincounts_2 = np.zeros((POBS_BIN_COUNT, len(nn_bins), len(z_bins), APP_MAG_BIN_COUNT, BIN_COUNT))\n",
    "\n",
    "from scipy.interpolate import interpn\n",
    "\n",
    "points = (range(len(angular_bins)), range(len(z_bins)), range(len(app_mag_bins)), range(len(obj.POBS_bins)))\n",
    "values = get_prob_nn_same_halo_index(*np.meshgrid(*points, indexing='ij'))\n",
    "\n",
    "point = np.array([25, 0.13, 16.7, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "xdata = np.linspace(0, 4, 50)\n",
    "y = func(xdata, 2.5, 1.3, 0.5)\n",
    "rng = np.random.default_rng()\n",
    "y_noise = 0.2 * rng.normal(size=xdata.size)\n",
    "ydata = y + y_noise\n",
    "plt.plot(xdata, ydata, 'b-', label='data')\n",
    "\n",
    "popt, pcov = curve_fit(func, xdata, ydata)\n",
    "print(popt)\n",
    "print(pcov)\n",
    "np.array([2.56274217, 1.37268521, 0.47427475])\n",
    "plt.plot(xdata, func(xdata, *popt), 'r-', label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
    "\n",
    "#popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))\n",
    "#np.array([2.43736712, 1.        , 0.34463856])\n",
    "#plt.plot(xdata, func(xdata, *popt), 'g--', label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NEIGHBORS = 20\n",
    "fancy_to_match = coord.SkyCoord(ra=ra[unobserved]*u.degree, dec=dec[unobserved]*u.degree, frame='icrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_indexes = np.zeros(shape=(NUM_NEIGHBORS, len(fancy_to_match)), dtype=np.int32) # indexes point to CATALOG locations\n",
    "ang_distances = np.zeros(shape=(NUM_NEIGHBORS, len(fancy_to_match)))\n",
    "\n",
    "print(f\"Finding nearest {NUM_NEIGHBORS} neighbors... \", end='\\r')   \n",
    "for n in range(0, NUM_NEIGHBORS):\n",
    "    idx, d2d, d3d = coord.match_coordinates_sky(fancy_to_match, catalog, nthneighbor=n+1, storekdtree=treename)\n",
    "    neighbor_indexes[n] = idx # TODO is that right?\n",
    "    ang_distances[n] = d2d.to(u.arcsec).value\n",
    "print(f\"Finding nearest {NUM_NEIGHBORS} neighbors... done!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with FancyRedshiftGuesser(NUM_NEIGHBORS, debug=False) as scorer:\n",
    "    halo_matches = 0\n",
    "    z_matches = 0\n",
    "\n",
    "    print(f\"Assinging missing redshifts... \")   \n",
    "    # TODO don't loop?\n",
    "    j = 0 # index of the fancy_to_match sized arrays\n",
    "    \n",
    "    #for i in special_id:\n",
    "    for i in indexes_not_assigned: # index of the master arrays\n",
    "\n",
    "        #if i not in [7793057, 11425052]:\n",
    "        #    j+=1\n",
    "        #    continue\n",
    "\n",
    "        if j%10000==0:\n",
    "            print(f\"{j}/{len(fancy_to_match)} complete\", end='\\r')\n",
    "\n",
    "        neighbors = neighbor_indexes[:,j]\n",
    "        neighbors_z = z_obs_catalog[neighbors]\n",
    "        neighbors_ang_dist = ang_distances[:,j]\n",
    "        my_prob_obs = prob_obs_cut[i]\n",
    "        my_app_mag = app_mag[i]\n",
    "\n",
    "        winning_num = scorer.choose_winner(neighbors_z, neighbors_ang_dist, my_prob_obs, my_app_mag, z_obs[i])\n",
    "        winner_index = neighbors[winning_num]\n",
    "\n",
    "        # Track total correct\n",
    "        z_chosen = z_obs_catalog[winner_index] \n",
    "        if np.isclose(z_chosen, z_obs[i], rtol=0, atol=SIM_Z_THRESH):\n",
    "            z_matches += 1\n",
    "        halo_chosen = mxxl_halo_id_catalog[winner_index]\n",
    "        if halo_chosen == mxxl_halo_id[i]:\n",
    "            halo_matches += 1\n",
    "\n",
    "        j += 1 \n",
    "\n",
    "    print(f\"{j}/{len(fancy_to_match)} complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Halo matches: {halo_matches / len(fancy_to_match)}\")\n",
    "print(f\"z matches: {z_matches / len(fancy_to_match)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results from a run of the FancyRedshiftGuesser. Must put in the right filename (number)\n",
    "filename = 'bin/redshift_guesser_1691466513.171286.npy'\n",
    "with open(filename, 'rb') as f:\n",
    "    quick_nn = np.load(f)\n",
    "    quick_correct = np.load(f)\n",
    "    nn_used = np.load(f)\n",
    "    nn_correct = np.load(f)\n",
    "\n",
    "print(f\"Quick NN uses: {quick_nn}. Success: {quick_correct / (quick_nn+1)}\")\n",
    "print(f\"NN bin uses: {nn_used}. Success: {nn_correct / (nn_used+1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS N^2 CALCULATION do not run on full sky.\n",
    "total_bincounts = np.ones((len(z_bins), BIN_COUNT))\n",
    "total_same_halo_bincounts = np.zeros((len(z_bins), BIN_COUNT))\n",
    "\n",
    "# Examine each galaxy in the sample pair once\n",
    "for i in range(len(ra)-1):\n",
    "    ang_distance = coord.angular_separation(ra[i]*u.degree, dec[i]*u.degree, ra[i+1:len(ra)]*u.degree, dec[i+1:len(ra)]*u.degree).to(u.arcsec)\n",
    "        \n",
    "    same_halo = mxxl_halo_id[i] == mxxl_halo_id[i+1:len(ra)]\n",
    "    #print(\"Same halo fraction for {0}:\".format(i), np.sum(same_halo) / len(same_halo))\n",
    "\n",
    "    angdist_bin_ind = np.digitize(ang_distance.value, angular_bins)\n",
    "    #print(bin_ind)\n",
    "    bincounts = np.bincount(angdist_bin_ind)[0:BIN_COUNT]\n",
    "    same_halo_bincounts = np.bincount(angdist_bin_ind, weights= same_halo.astype(int)) [0:BIN_COUNT]\n",
    "\n",
    "    z_bin = np.digitize(z_obs[i], z_bins)\n",
    "    total_bincounts[z_bin] = total_bincounts[z_bin] + bincounts\n",
    "    total_same_halo_bincounts[z_bin] = total_same_halo_bincounts[z_bin] + same_halo_bincounts\n",
    "    #print(total_same_halo_bincounts)\n",
    "\n",
    "#print(\"Total counts in each bin:\", total_bincounts)\n",
    "\n",
    "fraction_same_halo = total_same_halo_bincounts / total_bincounts\n",
    "#print(fraction_same_halo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for galaxy pairs\n",
    "plt.figure()\n",
    "for i in range(len(z_bins)):\n",
    "    if i==0:\n",
    "        label = \"< {0}\".format(z_bins[i])\n",
    "    else:\n",
    "        label = \"{0} - {1}\".format(z_bins[i-1], z_bins[i])\n",
    "    plt.plot(angular_bins, total_bincounts[i], label=label)\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Angular Separation (arcsec)')\n",
    "plt.ylabel('Count of Galaxies Pairs')\n",
    "plt.title(\"Galaxy Pair Counts (by ang separation and z)\")\n",
    "plt.draw()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(z_bins)):\n",
    "    if i==0:\n",
    "        label = \"< {0}\".format(z_bins[i])\n",
    "    else:\n",
    "        label = \"{0} - {1}\".format(z_bins[i-1], z_bins[i])\n",
    "    plt.plot(angular_bins, fraction_same_halo[i], label=label)\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Angular Separation (arcsec)')\n",
    "plt.ylabel('Fraction Pair in Same Halo')\n",
    "plt.ylim(-0.01, 1.0)\n",
    "plt.title(\"Fraction Pair in Same Halo (by ang separation and z)\")\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCHUU Experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[('R_MAG_APP', '>f4'), ('R_MAG_ABS', '>f4'), ('G_R_REST', '>f4'), ('G_R_OBS', '>f4'), ('DEC', '>f8'), ('HALO_MASS', '>f4'), ('CEN', '>i4'), ('RES', '>i4'), ('RA', '>f8'), ('Z_COSMO', '>f4'), ('Z', '>f4'), ('STATUS', '>i4'), ('FIRST_ACC_SCALE', '>f4'), ('M_ACC', '>f4'), ('M_VIR_ALL', '>f4'), ('R_VIR', '>f4'), ('V_PEAK', '>f4'), ('R_S', '>f4'), ('V_RMS', '>f4'), ('NGC', '>f4'), ('SGC', '>f4'), ('HALO_ID', '>i8'), ('PID', '>i8')]))\n",
    "filename='/export/sirocco2/tinker/DESI/UCHUU_MOCKS/BGS_LC_Uchuu.fits'\n",
    "u_table = Table.read(filename, format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_MAG_CUT = 19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table.columns\n",
    "#G_R_OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = u_table['DEC']\n",
    "ra = u_table['RA']\n",
    "z_obs = u_table['Z']\n",
    "app_mag = u_table['R_MAG_APP']\n",
    "abs_mag = u_table['R_MAG_ABS']\n",
    "g_r = u_table['G_R_REST'] # TODO before using ensure it should be rest and not observed\n",
    "g_r_obs = u_table['G_R_OBS']\n",
    "central = u_table['CEN']\n",
    "uchuu_halo_mass = u_table['HALO_MASS']\n",
    "uchuu_halo_id = u_table['HALO_ID']\n",
    "\n",
    "bright_filter = app_mag < APP_MAG_CUT \n",
    "redshift_filter = z_obs > 0 \n",
    "keep = np.all([mass_filter, bright_filter, redshift_filter], axis=0)\n",
    "\n",
    "dec = dec[keep]\n",
    "ra = ra[keep]\n",
    "z_obs = z_obs[keep]\n",
    "app_mag = app_mag[keep]\n",
    "abs_mag = abs_mag[keep]\n",
    "g_r = g_r[keep]\n",
    "g_r_obs = g_r_obs[keep]\n",
    "central = central[keep]\n",
    "uchuu_halo_mass = uchuu_halo_mass[keep]\n",
    "uchuu_halo_id = uchuu_halo_id[keep]\n",
    "\n",
    "abs_mag_me = app_mag_to_abs_mag(app_mag, z_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_mag_me_k = k_correct(app_mag, z_obs, g_r)\n",
    "# using true g-r instead of the observed g-r gives the reported distribution as shown by plot below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare my_abs_mag to abs_mag. \n",
    "angular_bins = np.linspace(-25, -10, 100)\n",
    "#my_counts, my_bins, my_p = plt.hist(abs_mag_me, label=\"my abs_mag\", bins=bins, alpha=0.5)\n",
    "alex_counts, alex_bins, alex_p = plt.hist(abs_mag, label=\"UCHUU abs_mag\", bins=angular_bins, alpha=0.5)\n",
    "my_k_counts, my_k_bins, my_k_p = plt.hist(abs_mag_me_k, label=\"my k abs_mag\", bins=angular_bins, alpha=0.5)\n",
    "#z = plt.hist(my_abs_mag_k, label=\"my k abs_mag\", bins=50)\n",
    "plt.xlabel(\"Absolute Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Compare Absolute Mags\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "#print(f\"The peaks are UCHUU: {alex_bins[np.argmax(alex_counts)]:.1f}, My {my_bins[np.argmax(my_counts)]:.1f}, My K {my_k_bins[np.argmax(my_k_counts)]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCHUU\n",
    "print(len(ra))\n",
    "estimate_frac_area(ra, dec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_indices = np.random.choice(len(ra), len(ra)//100, replace=False)\n",
    "fig = make_map(ra[rnd_indices], dec[rnd_indices]), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO only centrals...\n",
    "plt.hist(np.log10(uchuu_halo_mass*10**10), bins=30, alpha=0.5, density=True, label=\"UCHUU\")\n",
    "plt.hist(np.log10(all.all_data['mxxl_halo_mass']*10**10), bins=30, alpha=0.5, density=True, label=\"MXXL\")\n",
    "#plt.yscale('log')\n",
    "plt.title(\"MXXL vs UCHUU Truth Halo Masses\")\n",
    "plt.xlabel('log(M_halo)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test estimate_frac_area for a completely filled sky\n",
    "_ra = np.linspace(0.01, 359.9, 1000)\n",
    "_dec = np.linspace(0.01, 179.9, 1000)\n",
    "_ra, _dec = np.meshgrid(_ra, _dec)\n",
    "_ra = _ra.flatten()\n",
    "_dec = _dec.flatten()\n",
    "\n",
    "estimate_frac_area(_ra, _dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out smooth redshift comparison function works as desired for the relevant redshift differences\n",
    "x=np.arange(-0.01, 0.0105, 0.0005)\n",
    "plt.plot(x, sim_z_score(0.2, 0.2+x))\n",
    "plt.tight_layout()\n",
    "\n",
    "assert np.isclose(sim_z_score(0.2, 0.3), 0.0)\n",
    "assert np.isclose(sim_z_score(0.2, 0.25), 0.0)\n",
    "assert sim_z_score(0.2, 0.210) < 0.1, sim_z_score(0.2, 0.210)\n",
    "assert sim_z_score(0.2, 0.207) < 0.3, sim_z_score(0.2, 0.207)\n",
    "assert sim_z_score(0.2, 0.205) > 0.8, sim_z_score(0.2, 0.205)\n",
    "assert sim_z_score(0.2, 0.203) > 0.99, sim_z_score(0.2, 0.203)\n",
    "assert np.isclose(sim_z_score(0.2, 0.2001), 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
