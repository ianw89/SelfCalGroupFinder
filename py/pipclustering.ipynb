{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import astropy.constants as const\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "from bgs_helpers import *\n",
    "from plotting import *\n",
    "import wp\n",
    "import catalog_definitions as cat\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustering_catalog(filename, year):\n",
    "    table = Table.read(filename, format='fits')\n",
    "    print(table.colnames)\n",
    "    \n",
    "    table.keep_columns(['TARGETID', 'DEC', 'RA', 'Z','NTILE', 'WEIGHT', 'WEIGHT_ZFAIL'])\n",
    "    \n",
    "    \n",
    "    add_NTILE_MINE_to_table(table, year)\n",
    "    table['NTID'] = table['NEAREST_TILEIDS'][:,0]\n",
    "    table.remove_columns(['NEAREST_TILEIDS'])\n",
    "    \n",
    "    sv3tiles = read_tiles_Y3_sv3()\n",
    "    galaxies_df = table_to_df(table)\n",
    "    ntiles_inside, nearest_tile_ids = find_tiles_for_galaxies(sv3tiles, galaxies_df, 10)\n",
    "    if 'NTILE_MINE_SV3' in table.columns:\n",
    "        table.remove_columns(['NTILE_MINE_SV3'])\n",
    "    #if 'NEAREST_TILEIDS_SV3' in table.columns:\n",
    "    #    table.remove_columns(['NEAREST_TILEIDS_SV3'])\n",
    "    table.add_column(ntiles_inside, name=\"NTILE_MINE_SV3\")\n",
    "    #table.add_column(nearest_tile_ids, name=\"NEAREST_TILEIDS_SV3\")\n",
    "    \n",
    "    return table.to_pandas()\n",
    "\n",
    "\n",
    "def prep_for_clustering(df: pd.DataFrame):\n",
    "        \n",
    "    # check for duplicate targetid\n",
    "    df = df.drop_duplicates(subset='TARGETID', keep='first')\n",
    "    print(len(df))\n",
    "\n",
    "    df.rename(columns={'DEC': 'Dec', 'Z': 'z'}, inplace=True)\n",
    "    df['REGION'] = tile_to_region(df['NTID'])\n",
    "\n",
    "    innerdf = df[df['NTILE_MINE_SV3'] >= 10]\n",
    "    print(len(innerdf))\n",
    "\n",
    "    # Drop the bad two regions for equal comparison\n",
    "    to_remove = np.isin(innerdf['REGION'], sv3_poor_y3overlap)\n",
    "    innerdf = innerdf.loc[~to_remove]\n",
    "\n",
    "    innerdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    group_catalog = deserialize(cat.bgs_sv3_fiberonly_10p)\n",
    "    group_catalog.all_data.rename(columns={'target_id': 'TARGETID'}, inplace=True)\n",
    "    innerdf = pd.merge(innerdf, group_catalog.all_data.loc[:, ['TARGETID', 'quiescent']], on='TARGETID', how='inner', validate='one_to_one')\n",
    "\n",
    "\n",
    "    return innerdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = pickle.load(open(MY_RANDOMS_SV3_CLUSTERING, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SV3 PIP Clustering Calculation\n",
    "\n",
    "#dfN = get_clustering_catalog(BGS_SV3_CLUSTERING_N_BRIGHT_FILE, 'sv3')\n",
    "#dfS = get_clustering_catalog(BGS_SV3_CLUSTERING_S_BRIGHT_FILE, 'sv3')\n",
    "#df = pd.concat([dfN, dfS])\n",
    "#print(len(df))\n",
    "#innerdf = prep_for_clustering(df)\n",
    "#results = wp.calculate_wp_from_df(innerdf, randoms, weights=innerdf['WEIGHT'])\n",
    "#pickle.dump(results, open('sv3_pip_clustering_proper.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y3 Cut to SV3 Clustering Calculation\n",
    "# Using SV3 randoms, not Y3 cut to SV3. Is that right? TODO BUG\n",
    "\n",
    "y3_likesv3_df = get_clustering_catalog(BGS_Y3_CLUSTERING_FILE, '3')\n",
    "y3_innerdf = prep_for_clustering(y3_likesv3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = wp.calculate_wp_from_df(y3_innerdf, randoms, weights=y3_innerdf['WEIGHT'])\n",
    "pickle.dump(results, open(OUTPUT_FOLDER + 'y3_likesv3_pip_clustering_proper.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open(OUTPUT_FOLDER + 'y3_likesv3_pip_clustering_proper.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbins, wp_all, wp_red, wp_blue = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_positions(y3_innerdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
