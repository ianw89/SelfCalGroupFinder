{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "#sys.path.append(os.path.join(os.getcwd(), '../desi/'))\n",
    "#import catalog_definitions as cat\n",
    "import numpy as np\n",
    "import emcee\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(x, mu, cov):\n",
    "    diff = x - mu\n",
    "    return -0.5 * np.dot(diff, np.linalg.solve(cov, diff))\n",
    "\n",
    "ndim = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    " # Fixed values, not parameters.\n",
    "means = np.random.rand(ndim) # Means are between 0 and 1\n",
    "# There are some covariancse between the 5 gaussians\n",
    "cov = 0.5 - np.random.rand(ndim**2).reshape((ndim, ndim)) \n",
    "cov = np.triu(cov)\n",
    "cov += cov.T - np.diag(cov.diagonal())\n",
    "cov = np.dot(cov, cov)\n",
    "\n",
    "nwalkers = 32\n",
    "niter = 10000\n",
    "nburnin = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.random.uniform(low=np.zeros(ndim), high=np.ones(ndim), size=(nwalkers, ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = emcee.backends.HDFBackend(\"test_backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- run emcee\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[means, cov], backend=backend)\n",
    "#state = sampler.run_mcmc(p0, nburnin)\n",
    "#sampler.reset()\n",
    "\n",
    "start = time.time()\n",
    "# If you run this multiple times, it will keep doing 10000 more steps (per walker)\n",
    "sampler.run_mcmc(p0, niter, progress=True)\n",
    "end = time.time()\n",
    "serial_time = end - start\n",
    "\n",
    "print(\"Serial took {0:.1f} seconds\".format(serial_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.get_chain()\n",
    "ndim = samples.shape[2]\n",
    "print(f'Number of steps: {samples.shape[0] * samples.shape[1]} (total); {samples.shape[0]} (per walker), ')\n",
    "print(f'Number of walkers: {samples.shape[1]}')\n",
    "print(f'Number of parameters: {ndim}')\n",
    "\n",
    "try:\n",
    "    tau = sampler.get_autocorr_time()\n",
    "    print(tau)\n",
    "except:\n",
    "    print(\"Not burnt in yet\")\n",
    "\n",
    "burn = int(np.max(tau) * 2)\n",
    "flatchain = sampler.get_chain(discard=burn, flat=True)\n",
    "\n",
    "fig = corner.corner(\n",
    "    flatchain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool() as pool:\n",
    "    sampler2 = emcee.EnsembleSampler(nwalkers, ndim, log_prob, pool=pool, args=[means, cov])\n",
    "    state2 = sampler2.run_mcmc(p0, nburnin)\n",
    "    sampler2.reset()\n",
    "\n",
    "    start = time.time()\n",
    "    sampler2.run_mcmc(p0, niter, progress=True)\n",
    "    end = time.time()\n",
    "    multi_time = end - start\n",
    "    \n",
    "    print(\"Multiprocessing took {0:.1f} seconds\".format(multi_time))\n",
    "    print(\"{0:.1f} times faster than serial\".format(serial_time / multi_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples = sampler.get_chain(flat=True) # length is walkers * steps run total\n",
    "PARAMETER_INDEX = 0\n",
    "\n",
    "# View distribution of values (not including burn in) of a single parameter\n",
    "plt.hist(samples[:, PARAMETER_INDEX], 100, color=\"k\", histtype=\"step\")\n",
    "plt.xlabel(r\"$\\theta_1$\")\n",
    "plt.ylabel(r\"$p(\\theta_1)$\")\n",
    "plt.title(f'Posterior Distribution for parameter {PARAMETER_INDEX}')\n",
    "plt.gca().set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "# View chain for a single parameter\n",
    "plt.plot(samples[:, PARAMETER_INDEX])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel(f'Parameter Value')\n",
    "plt.title(f'Parameter Chain for parameter {PARAMETER_INDEX}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean acceptance fraction: {0:.3f}\".format(\n",
    "        np.mean(sampler.acceptance_fraction)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Mean autocorrelation time: {0:.3f} steps\".format(\n",
    "        np.mean(sampler.get_autocorr_time())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corner Plots\n",
    "import corner\n",
    "\n",
    "fig = corner.corner(\n",
    "    flat_samples, labels=labels, truths=[m_true, b_true, np.log(f_true)]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
