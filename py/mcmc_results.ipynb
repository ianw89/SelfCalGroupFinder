{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../desi/'))\n",
    "import catalog_definitions as cat\n",
    "import numpy as np\n",
    "import emcee\n",
    "import corner\n",
    "from IPython.display import display, Latex, Math\n",
    "\n",
    "# 10 Parameters associated with galaxy colors\n",
    "# Multiple configurations could produce the same LHMR, fsat, etc.\n",
    "# The actual values of these parameters is not of central interest;\n",
    "# it's the implied LHMR, fsat, etc. that we really care about.\n",
    "# Thus any degeneracies in these parameters are not a concern.\n",
    "\n",
    "# A zeroth and first order polynomial in log L_gal for B_sat, which controls the satelite threshold\n",
    "# Bsat,r = β_0,r + β_L,r(log L_gal − 9.5)\n",
    "# Bsat,b = β_0,b + β_L,b(log L_gal − 9.5)\n",
    "# Constrained from projected two-point clustering comparison for r,b seperately\n",
    "\n",
    "# Weights for each galaxy luminosity, when abundance matching\n",
    "# log w_cen,r = (ω_0,r / 2) (1 + erf[(log L_gal - ω_L,r) / σω,r)] ) \n",
    "# log w_cen,b = (ω_0,b / 2) (1 + erf[(log L_gal - ω_L,b) / σω,b)] ) \n",
    "# Constrained from Lsat,r/Lsat,b ratio and projected two-point clustering.\n",
    "\n",
    "# A secondary, individual galaxy property can be introduced to affect the weight for abundance matching.\n",
    "#  2 Parameters (one for each red and blue)\n",
    "# w_χ,r = exp(χ/ω_χ,r)\n",
    "# w_χ,b = exp(χ/ω_χ,b)\n",
    "# Constrained from Lsat(χ|L_gal) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MCMC using emcee backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder number to look in\n",
    "run = 1\n",
    "run_file = run\n",
    "\n",
    "path = f'/mount/sirocco1/imw2293/GROUP_CAT/MCMC/mcmc_{run}/mcmc_{run_file}.dat'\n",
    "#path = f'./mcmc_{run}/mcmc_{run_file}.dat'\n",
    "\n",
    "reader = emcee.backends.HDFBackend(path, read_only=True)\n",
    "samples = reader.get_chain()\n",
    "ndim = reader.shape[1]\n",
    "print(f'Number of steps: {samples.shape[0] * samples.shape[1]} (total); {samples.shape[0]} (per walker), ')\n",
    "print(f'Number of walkers: {samples.shape[1]}')\n",
    "print(f'Number of parameters: {ndim}')\n",
    "\n",
    "try:\n",
    "    tau = reader.get_autocorr_time()\n",
    "    print(tau)\n",
    "except:\n",
    "    print(\"Not burnt in yet\")\n",
    "\n",
    "burn_number = 150 # TODO choose this by inspecting the chains above. wait for convergence in all parameters\n",
    "thin_number = 1\n",
    "flat_samples = reader.get_chain(discard=burn_number, thin=thin_number, flat=True)\n",
    "flat_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad = [15,23,29] # this walker went off the deep end...\n",
    "bad = []\n",
    "# remove the 15th walker \n",
    "#flat_samples = np.delete(samples, 15, 1)\n",
    "# and first burn_number steps from each walker and flatten\n",
    "#flat_samples = flat_samples[burn_number:, :].reshape((-1, ndim))\n",
    "#flat_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ndim, figsize=(10, 2.5*ndim), sharex=True)\n",
    "labels = ['$\\\\omega_{L,b}$', '$\\\\sigma_{\\\\omega,b}$', '$\\\\omega_{L,r}$', '$\\\\sigma_{\\\\omega,r}$', '$\\\\omega_{0,b}$', '$\\\\omega_{0,r}$', '$\\\\beta_{0,r}$', '$\\\\beta_{L,r}$', '$\\\\beta_{0,b}$', '$\\\\beta_{L,b}$']\n",
    "good_walkers = list(np.arange(samples.shape[1]))\n",
    "for b in bad:\n",
    "    good_walkers.remove(b)\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, good_walkers, i], alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    # label each walker number\n",
    "    #for j in good_walkers:\n",
    "    #    ax.text(10000, samples[10000, j, i], f'{j}', color='k', fontsize=6)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The corner plot shows all 1D and 2D projections of the posterior probabilities of your parameters.\n",
    "# This is useful because it quickly demonstrates all of the covariances between parameters. \n",
    "# Also, the way that you find the marginalized distribution for a parameter or set of parameters \n",
    "#   using the results of the MCMC chain is to project the samples into that plane and then make \n",
    "#   an N-dimensional histogram. \n",
    "# That means that the corner plot shows the marginalized distribution for each parameter independently \n",
    "#   in the histograms along the diagonal and then the marginalized two dimensional distributions \n",
    "#   in the other panels.\n",
    "\n",
    "#fig = corner.corner(flat_samples, labels=labels)\n",
    "\n",
    "ranges = [(10,20),(0,5),(-2,30),(-5,20),(0,35),(-10,15),(-6,6),(4,25),(8,25),(-25,5)]\n",
    "fig = corner.corner(flat_samples, labels=labels, range=ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best model (lowest chi squared)\n",
    "idx = np.argmax(reader.get_log_prob(flat=True))\n",
    "all_flat_samples = reader.get_chain(flat=True)\n",
    "best_fit = all_flat_samples[idx]\n",
    "# Print with labels, need latex formatting\n",
    "print(\"BEST MODEL\")\n",
    "for i in range(len(labels)):\n",
    "    display(Latex(f'{labels[i]} = {best_fit[i]:.3f}'))\n",
    "\n",
    "# Then print means of the posteriors\n",
    "print(\"MEAN MODEL\")\n",
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt = f\"{labels[i]} = ${mcmc[1]:.3f}_{{-{q[0]:.3f}}}^{{{q[1]:.3f}}}$\"\n",
    "    display(Latex(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MCMC using manual output file\n",
    "But this is problematic in that it resets the model count to 1 everytime we startup after a crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Chains and Distributions of Parameters from the out.i file\n",
    "# Can get parameter info from the output file as well\n",
    "\n",
    "folder_num = 1\n",
    "\n",
    "models = []\n",
    "chi = []\n",
    "contributions = []\n",
    "with open(f'../../MCMC/mcmc_{folder_num}/out.{folder_num}', 'r') as file:\n",
    "    model_num = -1\n",
    "    for line in file:\n",
    "        if line.startswith('MODEL'):\n",
    "            model_num = int(line.split(' ', 2)[-1].strip())\n",
    "        elif line.startswith('{\\'zmin\\':'):\n",
    "            parameter_dict = ast.literal_eval(line)\n",
    "            models.append(parameter_dict)\n",
    "        elif line.startswith('CHI'):\n",
    "            chi.append(float(line.split(' ', 2)[-1].strip()))\n",
    "        elif line.startswith('CONTRIBUTIONS'):\n",
    "            contributions.append(ast.literal_eval(line.split(' ', 1)[1].strip()))\n",
    "\n",
    "    assert len(models) == len(chi)\n",
    "\n",
    "def get_parameter_values(parameter_name):\n",
    "    return [model[parameter_name] for model in models]\n",
    "\n",
    "exclusions = ['zmin', 'zmax', 'frac_area', 'fluxlim', 'color']\n",
    "\n",
    "contributions = np.array(contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For low chi squared models, the mean contributions come from:\")\n",
    "for i in range(contributions.shape[1]):\n",
    "    filtered_contributions = np.where(np.array(chi) < 150, contributions[:,i], np.zeros(contributions.shape[0]))\n",
    "    print(f\"Mean={np.mean(filtered_contributions):.2f}, var={np.var(filtered_contributions):.2f}\")\n",
    "\n",
    "print(\"For high chi squared models, the mean contributions come from:\")\n",
    "for i in range(contributions.shape[1]):\n",
    "    filtered_contributions = np.where(np.array(chi) > 150, contributions[:,i], np.zeros(contributions.shape[0]))\n",
    "    print(f\"Mean={np.mean(filtered_contributions):.2f}, var={np.var(filtered_contributions):.2f}\")\n",
    "\n",
    "#indexes_sorted = np.argsort(chi)\n",
    "#junk=plt.hist(np.log10(chi), bins=50)\n",
    "#chi_sorted = np.sort(chi)\n",
    "#chi_sorted[len(chi_sorted)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My versions of chain plots and parameter distributions\n",
    "for pname in models[0]:\n",
    "    if pname in exclusions:\n",
    "        continue\n",
    "    values=get_parameter_values(pname)\n",
    "    plt.plot(values, color=\"k\")\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(f'Parameter Value')\n",
    "    plt.title(f'Parameter Chain for {pname}')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(values, 100, color=\"k\", histtype=\"step\")\n",
    "    plt.xlabel(f\"{pname}\")\n",
    "    plt.ylabel(f\"$p({pname})$\")\n",
    "    plt.gca().set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(chi)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Chi Squared')\n",
    "plt.title('Chi Squared Chain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best model\n",
    "best_model = models[chi.index(min(chi))]\n",
    "print(f'Best model is model {chi.index(min(chi))} with chi squared of {min(chi)}')\n",
    "\n",
    "#compare each property of best model to cat.sdss_colors.GF_props\n",
    "for key in best_model:\n",
    "    if key in exclusions:\n",
    "        continue\n",
    "    print(f'{key.ljust(12)}:  {best_model[key]:.4} vs {cat.sdss_colors.GF_props[key]:.4} ({100 * (best_model[key] - cat.sdss_colors.GF_props[key]) / cat.sdss_colors.GF_props[key]:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math\n",
    "\n",
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt = \"{3} = {0:.3f}_{{-{1:.3f}}}^{{{2:.3f}}}\"\n",
    "    txt = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "    display(Math(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
