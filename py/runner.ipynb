{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.coordinates as coord\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table,join\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from groupcatalog import *\n",
    "import catalog_definitions as cat\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "import plotting as pp\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Group Finder\n",
    "\n",
    "This notebook will call the functions to preprocess, run group finder, and run postprocessing code to build up a GroupCatalog object, which mostly wraps a pandas DataFrame containing the resulting group catalog data.\n",
    "\n",
    "After running this on a given GroupCatalog definition, a serialized (via pickle) version of the GroupCatalog object will exist which can be deserialized elsewhere for analysis. See post_plots.ipynb for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_run: list[GroupCatalog] = []\n",
    "#datasets_to_run.extend(cat.sdss_list)\n",
    "#datasets_to_run.extend(cat.uchuu_list)\n",
    "#datasets_to_run.extend(cat.mxxl_list)\n",
    "datasets_to_run.extend(cat.bgs_sv3_list)  \n",
    "#datasets_to_run.extend(bgs_y1_list)\n",
    "#datasets_to_run.extend(bgs_y3_list)\n",
    "\n",
    "\n",
    "# To just run postprocessing on GF output, comment out run_group_finder()\n",
    "for d in datasets_to_run:\n",
    "    #d = deserialize(d)\n",
    "    #d.preprocess()\n",
    "    d.run_group_finder(popmock=False)\n",
    "    d.postprocess()\n",
    "    #d.run_corrfunc()\n",
    "    serialize(d)\n",
    "    #del(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs_sv3_pz_2_4_7p = deserialize(cat.bgs_sv3_pz_2_4_7p)\n",
    "bgs_y3_like_sv3_pz_2_4 = deserialize(cat.bgs_y3_like_sv3_pz_2_4)\n",
    "bgs_sv3_pz_2_4_10p = deserialize(cat.bgs_sv3_pz_2_4_10p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting as pp\n",
    "import astropy.units as u\n",
    "fig=pp.make_map(bgs_sv3_pz_2_4_7p.all_data.RA.to_numpy(), bgs_sv3_pz_2_4_7p.all_data.Dec.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot_positions(bgs_sv3_pz_2_4_7p.all_data, bgs_y3_like_sv3_pz_2_4.all_data, DEG_LONG=4, split=True, ra_min=148, dec_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import match_coordinates_sky\n",
    "\n",
    "def find_unique_objects(cat1, cat2):\n",
    "    df1 = cat1.all_data.loc[z_flag_is_spectro_z(cat1.all_data['z_assigned_flag'])].reset_index()\n",
    "    df2 = cat2.all_data.loc[z_flag_is_spectro_z(cat2.all_data['z_assigned_flag'])].reset_index()\n",
    "                                                 \n",
    "    # Extract RA and Dec from the catalogs\n",
    "    ra1, dec1 = df1['RA'].to_numpy(), df1['Dec'].to_numpy()\n",
    "    ra2, dec2 = df2['RA'].to_numpy(), df2['Dec'].to_numpy()\n",
    "        \n",
    "    # Create SkyCoord objects\n",
    "    coords1 = SkyCoord(ra=ra1*u.degree, dec=dec1*u.degree)\n",
    "    coords2 = SkyCoord(ra=ra2*u.degree, dec=dec2*u.degree)\n",
    "    \n",
    "    # Match coordinates\n",
    "    idx, d2d, _ = match_coordinates_sky(coords1, coords2)\n",
    "\n",
    "    df1['FID'] = idx\n",
    "    df2['FID'] = df2.index\n",
    "    \n",
    "    # Find objects in df1 that are not in df2\n",
    "    unique_mask = d2d > 1*u.arcsec  # You can adjust the threshold as needed\n",
    "\n",
    "    # join with df2 for matched_objects on the FID\n",
    "    matched_objects = df1.join(df2.set_index('FID'), on='FID', rsuffix='_2')\n",
    "    matched_objects = matched_objects[~unique_mask]\n",
    "\n",
    "    print(f\"Total spectroscopic galaxies in cat1: {len(df1)}, cat2: {len(df2)}\")\n",
    "    print(f'Unique objects in cat1: {unique_mask.sum()}, Matched objects in cat1: {len(matched_objects)}')\n",
    "    \n",
    "    return unique_objects, matched_objects\n",
    "\n",
    "# Example usage\n",
    "unique_objects, matched_objects = find_unique_objects(bgs_sv3_pz_2_4_10p, bgs_y3_like_sv3_pz_2_4)\n",
    "\n",
    "np.isclose(matched_objects['z'], matched_objects['z_2'], atol=0.0001, rtol=0).sum() / len(matched_objects)\n",
    "#fig=pp.make_map(unique_objects.RA.to_numpy(), unique_objects.Dec.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(matched_objects['z'] - matched_objects['z_2'], bins=np.linspace(-0.005, 0.005, 100))\n",
    "plt.yscale('log')\n",
    "\n",
    "# Draw verticle line at 0.005\n",
    "plt.axvline(x=0.005, color='r', linestyle='--')\n",
    "plt.axvline(x=-0.005, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
