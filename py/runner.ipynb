{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.coordinates as coord\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table,join\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from groupcatalog import GroupCatalog, BGSGroupCatalog, TestGroupCatalog, serialize, deserialize, SDSSGroupCatalog\n",
    "import catalog_definitions as cat\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "import plotting as pp\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Group Finder\n",
    "\n",
    "This notebook will call the functions to preprocess, run group finder, and run postprocessing code to build up a GroupCatalog object, which mostly wraps a pandas DataFrame containing the resulting group catalog data.\n",
    "\n",
    "After running this on a given GroupCatalog definition, a serialized (via pickle) version of the GroupCatalog object will exist which can be deserialized elsewhere for analysis. See post_plots.ipynb for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_list : list[GroupCatalog] = [\n",
    "    cat.sdss_vanilla,\n",
    "    cat.sdss_colors,\n",
    "    cat.sdss_colors_chi,\n",
    "    cat.sdss_vanilla_v2,\n",
    "    cat.sdss_colors_v2,\n",
    "    cat.sdss_colors_chi_v2,\n",
    "    cat.sdss_bgscut,\n",
    "]\n",
    "uchuu_list : list[GroupCatalog] = [\n",
    "    cat.uchuu_all,\n",
    "]\n",
    "mxxl_list : list[GroupCatalog] = [\n",
    "    cat.mxxl_all,\n",
    "    #cat.mxxl_all_c,\n",
    "    cat.mxxl_fiberonly,\n",
    "    #cat.mxxl_fiberonly_c,\n",
    "    cat.mxxl_nn,\n",
    "    #cat.mxxl_nn_c,\n",
    "    cat.mxxl_simple_2,\n",
    "    #cat.mxxl_simple_2_c,\n",
    "    cat.mxxl_simple_4,\n",
    "    #cat.mxxl_simple_4_c,\n",
    "]\n",
    "bgs_sv3_list : list[GroupCatalog] = [\n",
    "    cat.bgs_sv3_nn_10p,\n",
    "    cat.bgs_sv3_nn_7p,\n",
    "    cat.bgs_sv3_nn_6p,\n",
    "    cat.bgs_sv3_fiberonly_10p,\n",
    "    cat.bgs_sv3_simple_4_10p,\n",
    "    cat.bgs_sv3_simple_4_9p,\n",
    "    cat.bgs_sv3_simple_4_8p,\n",
    "    cat.bgs_sv3_simple_4_7p,\n",
    "    cat.bgs_sv3_simple_4_6p,\n",
    "    cat.bgs_sv3_simple_4_5p,\n",
    "    cat.bgs_sv3_simple_4_4p,\n",
    "    cat.bgs_sv3_simple_4_3p,\n",
    "    cat.bgs_sv3_simple_4_2p,\n",
    "    cat.bgs_sv3_simple_4_1p,\n",
    "    cat.bgs_sv3_simple_5_10p,\n",
    "    cat.bgs_sv3_simple_5_9p,\n",
    "    cat.bgs_sv3_simple_5_8p,\n",
    "    cat.bgs_sv3_simple_5_7p,\n",
    "    cat.bgs_sv3_pz_1_10p,\n",
    "    cat.bgs_sv3_pz_1_0_7p,\n",
    "    cat.bgs_sv3_pz_1_1_7p,\n",
    "    cat.bgs_sv3_pz_1_2_7p,\n",
    "    cat.bgs_sv3_pz_1_3_7p,\n",
    "    cat.bgs_sv3_pz_2_0_7p\n",
    "]\n",
    "bgs_y1_list : list[GroupCatalog] = [\n",
    "    #cat.bgs_simple_4_old,\n",
    "    ##cat.bgs_simple_4,\n",
    "    #cat.bgs_simple_4_1pass,\n",
    "    #cat.bgs_simple_4_no_sdss,\n",
    "    #cat.bgs_simple_4_4p,\n",
    "    #cat.bgs_simple_4_c,\n",
    "    #cat.bgs_fiberonly,\n",
    "    #cat.bgs_fiberonly_1pass,\n",
    "    #cat.bgs_nn,\n",
    "    #cat.bgs_nn_sdsslike,\n",
    "    ##cat.bgs_simple_2,\n",
    "    #cat.bgs_simple_2_c,\n",
    "    ##cat.bgs_simple_5,\n",
    "]\n",
    "bgs_y3_list : list[GroupCatalog] = [\n",
    "    ##cat.bgs_y3_simple_4,\n",
    "    #cat.bgs_y3_simple_4_4p,\n",
    "    #cat.bgs_y3_fiberonly_1pass,\n",
    "    #cat.bgs_y3_fiberonly,\n",
    "    ##cat.bgs_y3_simple_5,\n",
    "    cat.bgs_y3_pzp_1\n",
    "]\n",
    "\n",
    "datasets_to_run: list[GroupCatalog] = []\n",
    "#datasets_to_run.extend(sdss_list)\n",
    "#datasets_to_run.extend(uchuu_list)\n",
    "#datasets_to_run.extend(mxxl_list)\n",
    "#datasets_to_run.extend(bgs_sv3_list)  \n",
    "#datasets_to_run.extend(bgs_y1_list)\n",
    "#datasets_to_run.extend(bgs_y3_list)\n",
    "\n",
    "# BUG unclear why this one is broken...\n",
    "datasets_to_run.extend([cat.bgs_sv3_pz_2_0_7p])\n",
    "\n",
    "#mcmc = BGSGroupCatalog(\"Photo-z Plus MCMC BGS sv3 7pass \", Mode.PHOTOZ_PLUS_v1, 19.5, 21.0, num_passes=10, drop_passes=3, data_cut='sv3', sdss_fill=False, extra_params=(np.nan, np.nan, 10, np.nan, np.nan))\n",
    "#mcmc.GF_props = cat.GF_PROPS_VANILLA.copy()\n",
    "#datasets_to_run.extend([mcmc])\n",
    "\n",
    "#datasets_to_run.extend([cat.bgs_sv3_pz_1_2_7p])\n",
    "\n",
    "# To just run postprocessing on GF output, comment out run_group_finder()\n",
    "for d in datasets_to_run:\n",
    "    #d = deserialize(d)\n",
    "    d.run_group_finder(popmock=False)\n",
    "    d.postprocess()\n",
    "    #d.run_corrfunc()\n",
    "    serialize(d)\n",
    "    #del(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python End to End Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV3_test = BGSGroupCatalog(\"SV3 Test\", Mode.SIMPLE_v4, 19.5, 21.0, num_passes=10, drop_passes=3, data_cut='sv3', sdss_fill=False)\n",
    "SV3_test.GF_props = cat.GF_PROPS_VANILLA.copy()\n",
    "\n",
    "SV3_test.preprocess()\n",
    "\n",
    "# Read in BGS_SV3_ANY_FULL_FILE and ensure no precision is lost from there to SV3_test.preprocess_file and the like\n",
    "merged_table = Table.read(IAN_BGS_SV3_MERGED_FILE, format='fits')\n",
    "print(merged_table['RA'][0:10])\n",
    "\n",
    "# read in and print out the first few lines of SV3_test.preprocess_file\n",
    "with open(SV3_test.preprocess_file, 'r') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')\n",
    "\n",
    "#with open(SV3_test.preprocess_file + \"~\", 'r') as f:\n",
    "#    for i in range(10):\n",
    "#        print(f.readline(), end='')\n",
    "\n",
    "galprops_file = str.replace(SV3_test.GF_outfile, \".out\", \"_galprops.dat\")\n",
    "with open(galprops_file, 'r') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')\n",
    "\n",
    "#with open(galprops_file + \"~\", 'r') as f:\n",
    "#    for i in range(10):\n",
    "#        print(f.readline(), end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C Group Finder Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run once, unless you want to change the test data\n",
    "#catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.create_test_dat_files() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Baseline vanilla group finder test \n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.run_group_finder(silent=True) \n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "baseline_total_mass = df['M_halo'].sum()\n",
    "assert len(np.unique(df['igrp'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['quiescent'].sum() == 129\n",
    "assert np.isclose(df['weight'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "m1=df['M_halo'].to_numpy()\n",
    "\n",
    "# Test that when omega0 are 0, the others don't matter\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "catalog.GF_props['omegaL_sf'] = 123\n",
    "catalog.GF_props['sigma_sf'] = 345\n",
    "catalog.GF_props['omegaL_q'] = 456\n",
    "catalog.GF_props['sigma_q'] = 678\n",
    "catalog.GF_props['omega0_sf'] = 0.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['igrp'])) == 200\n",
    "assert len(df) == 246 \n",
    "assert df['quiescent'].sum() == 129\n",
    "assert np.isclose(df['weight'].sum(), 246 * 1.0) # no weights, just 1 per gal\n",
    "assert np.isclose(df['M_halo'].sum(), baseline_total_mass)\n",
    "m2=df['M_halo'].to_numpy()\n",
    "\n",
    "catalog = TestGroupCatalog(\"Test\")\n",
    "#catalog.GF_props['colors'] = 1\n",
    "catalog.GF_props['omegaL_sf'] = 10.0\n",
    "catalog.GF_props['sigma_sf'] = 3.0\n",
    "catalog.GF_props['omegaL_q'] = 0.0\n",
    "catalog.GF_props['sigma_q'] = 0.0\n",
    "catalog.GF_props['omega0_sf'] = 10.0\n",
    "catalog.GF_props['omega0_q'] = 0.0\n",
    "catalog.run_group_finder(silent=True)\n",
    "catalog.postprocess()\n",
    "df=catalog.all_data\n",
    "assert len(np.unique(df['igrp'])) >= 200 # these parameters make assigned halos smaller\n",
    "assert len(df) == 246 \n",
    "assert df['quiescent'].sum() == 129\n",
    "assert df['weight'].sum() < 246 \n",
    "# TODO BUG I feel like this should be true, but it's not. Weighting doesn't preseve the halo mass function\n",
    "#assert np.isclose(df['M_halo'].sum(), baseline_total_mass) \n",
    "m3=df['M_halo'].to_numpy()\n",
    "\n",
    "plt.hist(np.stack([np.log10(m1), np.log10(m2), np.log10(m3)], axis=-1))\n",
    "\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.examine_area(np.min(df.RA), np.max(df.RA), np.min(df.Dec), np.max(df.Dec), df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
