{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Group Finder\n",
    "\n",
    "This notebook will call the functions to preprocess, run group finder, and run postprocessing code to build up a GroupCatalog object, which mostly wraps a pandas DataFrame containing the resulting group catalog data.\n",
    "\n",
    "After running this on a given GroupCatalog definition, a serialized (via pickle) version of the GroupCatalog object will exist which can be deserialized elsewhere for analysis. See post_plots.ipynb for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.coordinates as coord\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table,join\n",
    "import astropy.io.fits as fits\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from groupcatalog import *\n",
    "import catalog_definitions as cat\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "import plotting as pp\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_run: list[GroupCatalog] = []\n",
    "#datasets_to_run.extend(cat.sdss_list)\n",
    "#datasets_to_run.extend(cat.uchuu_list)\n",
    "#datasets_to_run.extend(cat.mxxl_list)\n",
    "#datasets_to_run.extend(cat.bgs_sv3_list)  \n",
    "#datasets_to_run.extend(cat.bgs_y1_list)  \n",
    "#datasets_to_run.extend(cat.bgs_y3_list)  \n",
    "#datasets_to_run.extend(cat.bgs_aux_list)\n",
    "\n",
    "# TODO LOA columns not same as KIBO I guess...\n",
    "\n",
    "datasets_to_run.extend([\n",
    "    cat.bgs_y3_pzp_2_4\n",
    "    #cat.bgs_sv3_pz_2_4_10p_c1\n",
    "    #cat.sdss_colors_chi,\n",
    "])\n",
    "\n",
    "\n",
    "# To just run postprocessing on GF output, comment out run_group_finder()\n",
    "for d in datasets_to_run:\n",
    "    #d = deserialize(d)\n",
    "    success = d.run_group_finder(popmock=True)\n",
    "    if not success:\n",
    "        print(f\"Group finder failed for {d.name}\")\n",
    "        continue\n",
    "    d.calc_wp_for_mock()\n",
    "    d.postprocess()\n",
    "    d.dump()\n",
    "\n",
    "    #d = deserialize(d)\n",
    "    #d.calculate_projected_clustering(with_extra_randoms=True) # 15m\n",
    "    #d.calculate_projected_clustering_in_magbins(with_extra_randoms=True) # 45m\n",
    "    #serialize(d)\n",
    "\n",
    "    #pp.proj_clustering_plot(d)\n",
    "    #pp.lsat_data_compare_plot(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=3, suppress=True, linewidth=300, threshold=sys.maxsize, formatter={'float_kind':'{:6.3f}'.format}):\n",
    "    for d in datasets_to_run:\n",
    "        print(d.hod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs_sv3_pz_2_4_10p = deserialize(cat.bgs_sv3_pz_2_4_10p)\n",
    "bgs_sv3_pz_2_4_10p.add_jackknife_err_to_proj_clustering(with_extra_randoms=True, for_mag_bins=False)\n",
    "serialize(bgs_sv3_pz_2_4_10p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = deserialize(cat.bgs_sv3_pz_2_4_10p)\n",
    "catalog.all_data['Z_ASSIGNED_FLAG'] = catalog.all_data['Z_ASSIGNED_FLAG'].astype('int32')\n",
    "columns_to_write = [\n",
    "            'TARGETID', \n",
    "            'RA',\n",
    "            'DEC',\n",
    "            'Z',\n",
    "            'L_GAL', \n",
    "            'VMAX',\n",
    "            'P_SAT', \n",
    "            'M_HALO',\n",
    "            'N_SAT', \n",
    "            'L_TOT', \n",
    "            'IGRP', \n",
    "            'WEIGHT', \n",
    "            'APP_MAG_R', \n",
    "            'Z_ASSIGNED_FLAG',\n",
    "            'G_R',\n",
    "            'IS_SAT', \n",
    "            'QUIESCENT', \n",
    "            'MSTAR' \n",
    "        ]\n",
    "\n",
    "table = Table.from_pandas(\n",
    "    catalog.all_data.loc[:, columns_to_write],\n",
    "    units={ \n",
    "        'RA': u.degree,\n",
    "        'DEC': u.degree,\n",
    "        'L_GAL': u.solLum,\n",
    "        'VMAX': u.Mpc**3,\n",
    "        'M_HALO': u.solMass,\n",
    "        'L_TOT': u.solLum,\n",
    "        'MSTAR': u.solMass\n",
    "    } # Others are dimensionless\n",
    "    )\n",
    "table.info.name = \"GALAXIES\"\n",
    "table.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frompath = catalog.write_sharable_output_file()\n",
    "\n",
    "read = Table.read(frompath)\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdul = fits.open(frompath, memmap=True)\n",
    "hdul.info()\n",
    "hdul[1].name = \"GALAXIES\"\n",
    "hdul.info()\n",
    "hdul.writeto(frompath, overwrite=True)\n",
    "hdul = fits.open(frompath, memmap=True)\n",
    "hdul.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
