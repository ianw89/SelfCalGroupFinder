{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57684ff2",
   "metadata": {},
   "source": [
    "# Spectroscopic Properties Lookup Table\n",
    "\n",
    "This notebook creates k-correction lookup tables for the BGS data. The lookup table uses KDTree for efficient nearest neighbor searching based on redshift and g-r color to provide k-corrections for absolute magnitude calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6b9c7",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f556713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "from astropy.table import Table\n",
    "import sys\n",
    "from pykdtree.kdtree import KDTree\n",
    "import pickle\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "if './SelfCalGroupFinder/py/' not in sys.path:\n",
    "    sys.path.append('./SelfCalGroupFinder/py/')\n",
    "from pyutils import *\n",
    "from dataloc import *\n",
    "from bgs_helpers import *\n",
    "from groupcatalog import BGS_Z_MAX, BGS_Z_MIN\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557244e",
   "metadata": {},
   "source": [
    "## Load BGS Data\n",
    "\n",
    "Load the merged BGS data file to use for creating the lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged table\n",
    "table = Table.read(IAN_BGS_Y1_MERGED_FILE, format='fits')\n",
    "df = table_to_df(table, 20.175, BGS_Z_MIN, BGS_Z_MAX, True, 1)\n",
    "print(f\"Loaded {len(df):,} galaxies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9de070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all but the columns we need\n",
    "df = df[['TARGETID', 'Z', 'ABS_MAG_R', 'ABS_MAG_G', 'ABSMAG01_SDSS_R', 'ABSMAG01_SDSS_G', 'DN4000_MODEL', 'G_R_BEST', 'LOG_L_GAL', 'LOGMSTAR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "magr_k_gama = k_correct_gama(df['ABS_MAG_R'], df['Z'], df['ABS_MAG_G'] - df['ABS_MAG_R'], band='r')\n",
    "magg_k_gama = k_correct_gama(df['ABS_MAG_G'], df['Z'], df['ABS_MAG_G'] - df['ABS_MAG_R'], band='g')\n",
    "badmatch = (np.abs(magr_k_gama - df['ABSMAG01_SDSS_R']) > 1.0) | (np.abs(magg_k_gama - df['ABSMAG01_SDSS_G']) > 1.0)\n",
    "goodidx = ~np.isnan(df['ABS_MAG_R']) & ~np.isnan(df['ABS_MAG_G']) & ~np.isnan(df['Z']) & ~np.isnan(df['ABSMAG01_SDSS_R']) & ~np.isnan(df['ABSMAG01_SDSS_G']) & ~badmatch\n",
    "gmr = df.loc[goodidx, 'ABS_MAG_G'] - df.loc[goodidx, 'ABS_MAG_R']\n",
    "print(f\"Number of galaxies with good data: {np.sum(goodidx):,}\")\n",
    "\n",
    "# Randomly split goodidx into a training and test set\n",
    "np.random.seed(6884)\n",
    "shuffled_indices = np.random.permutation(np.where(goodidx)[0])\n",
    "train_size = int(0.8 * len(shuffled_indices))\n",
    "train_indices = shuffled_indices[:train_size]\n",
    "test_indices = shuffled_indices[train_size:]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Prepare training and test data\n",
    "z_train = df.loc[train_indices, 'Z'].to_numpy()\n",
    "magr_train = df.loc[train_indices, 'ABS_MAG_R'].to_numpy() # These have no k-corr\n",
    "magg_train = df.loc[train_indices, 'ABS_MAG_G'].to_numpy() # These have no k-corr\n",
    "gmr_train = magg_train - magr_train\n",
    "\n",
    "kcorr_r_train = magr_train - df.loc[train_indices, 'ABSMAG01_SDSS_R'].to_numpy() # These have the fastspecfit k-corr in them\n",
    "kcorr_g_train = magg_train - df.loc[train_indices, 'ABSMAG01_SDSS_G'].to_numpy() # These have the fastspecfit k-corr in them\n",
    "\n",
    "z_test = df.loc[test_indices, 'Z'].to_numpy()\n",
    "magr_test = df.loc[test_indices, 'ABS_MAG_R'].to_numpy()\n",
    "magg_test = df.loc[test_indices, 'ABS_MAG_G'].to_numpy()\n",
    "gmr_test = magg_test - magr_test\n",
    "\n",
    "kcorr_r_test = magr_test - df.loc[test_indices, 'ABSMAG01_SDSS_R'].to_numpy() # These have the fastspecfit k-corr in them\n",
    "kcorr_g_test = magg_test - df.loc[test_indices, 'ABSMAG01_SDSS_G'].to_numpy() # These have the fastspecfit k-corr in them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[test_indices, 'ABSMAG01_SDSS_R'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[test_indices, 'ABS_MAG_R'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98079c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[test_indices, 'APP_MAG_R'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f59f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "distmod( df.loc[test_indices, 'Z'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50181b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcorr_r_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "18.35078 - 39.31299 - 0.046359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c91103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of redshift and g-r\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(gmr_train, z_train, s=5, alpha=0.05, label='Training Set')\n",
    "plt.xlabel('g - r')\n",
    "plt.ylabel('Redshift')\n",
    "plt.title('Redshift vs. g-r Color')\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc796c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution of k-corrections in r and g bands\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(kcorr_r_train, bins=1250, alpha=0.7, color='r', label='r-band')\n",
    "plt.hist(kcorr_g_train, bins=1250, alpha=0.7, color='g', label='g-band')\n",
    "plt.xlabel('K-correction (mag)')\n",
    "plt.ylabel('Number of galaxies')\n",
    "plt.title('Distribution of K-corrections (Training Set)')\n",
    "plt.legend()\n",
    "plt.xlim(-0.4, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e168ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First rusults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5cf43",
   "metadata": {},
   "source": [
    "## Look at kcorr MCMC Samples and save best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sampler\n",
    "backend = emcee.backends.HDFBackend(\"kcorr_lookup_optimization.h5\")\n",
    "chains = backend.get_log_prob(flat=True)\n",
    "argmax = np.argmax(chains)\n",
    "samples = backend.get_chain(flat=True)\n",
    "chisqr = - backend.get_log_prob(flat=True)\n",
    "\n",
    "print(f\"Total Samples: {len(samples)}\")\n",
    "print(f\"Best-fit parameters: {samples[argmax]}\")\n",
    "print(f\"Best-fit chi-squared: {chisqr[argmax]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2503f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of chisqr values, chi sqr is color and 2d map is the two parameters \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(samples[:, 0], samples[:, 1], c=chisqr, cmap='viridis', s=10)\n",
    "plt.colorbar(label='Chi-squared')\n",
    "plt.xlabel('METRIC_Z')\n",
    "plt.ylabel('METRIC_GMR')\n",
    "plt.title('MCMC Samples Colored by Chi-squared')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot corner plot\n",
    "fig = corner.corner(samples, labels=[\"METRIC_Z\", \"METRIC_GMR\"], show_titles=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the best fit metric, build the tree and lookup to save off (using the full data now)\n",
    "\n",
    "# MCMC says it doesn't matter much\n",
    "optimal_metric_z = 20.0\n",
    "optimal_metric_gmr = 4.0\n",
    "\n",
    "print(f\"Building final lookup table with metric:\")\n",
    "print(f\"  METRIC_Z: {optimal_metric_z}\")\n",
    "print(f\"  METRIC_GMR: {optimal_metric_gmr}\")\n",
    "\n",
    "# Prepare full dataset (all good galaxies)\n",
    "z_full = df.loc[goodidx, 'Z'].to_numpy()\n",
    "magr_full = df.loc[goodidx, 'ABS_MAG_R'].to_numpy()\n",
    "magg_full = df.loc[goodidx, 'ABS_MAG_G'].to_numpy()\n",
    "gmr_full = magg_full - magr_full\n",
    "\n",
    "# Calculate k-corrections for the full dataset\n",
    "kcorr_r_full = magr_full - df.loc[goodidx, 'ABSMAG01_SDSS_R'].to_numpy()\n",
    "kcorr_g_full = magg_full - df.loc[goodidx, 'ABSMAG01_SDSS_G'].to_numpy()\n",
    "\n",
    "# Scale the features with optimal metrics\n",
    "z_scaled = z_full * optimal_metric_z\n",
    "gmr_scaled = gmr_full * optimal_metric_gmr\n",
    "magr_scaled = magr_full  # metric_absmag_r = 1.0\n",
    "\n",
    "# Build the KDTree\n",
    "lookup_points = np.vstack((z_scaled, gmr_scaled, magr_scaled)).T\n",
    "kdtree = KDTree(lookup_points)\n",
    "\n",
    "# Store the k-corrections as lookup tables\n",
    "kcorr_r_lookup = kcorr_r_full\n",
    "kcorr_g_lookup = kcorr_g_full\n",
    "\n",
    "print(f\"Built KDTree with {len(lookup_points):,} galaxies\")\n",
    "print(f\"K-correction lookup table shape: {kcorr_r_lookup.shape}\")\n",
    "\n",
    "# Save the lookup table and optimal metrics\n",
    "lookup_data = (kdtree, kcorr_r_lookup, kcorr_g_lookup, optimal_metric_z, optimal_metric_gmr, 1.0)\n",
    "\n",
    "with open(BGS_Y3_KCORR_LOOKUP_FILE, 'wb') as f:\n",
    "    pickle.dump(lookup_data, f)\n",
    "\n",
    "print(f\"\\nSaved lookup table to {BGS_Y3_KCORR_LOOKUP_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52504a7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cddc064d",
   "metadata": {},
   "source": [
    "## Validation of the Final kcorrlook metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46705f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's validate by reading in and using the first 100000 from the Y3 data\n",
    "\n",
    "print(\"Loading Y3 validation data...\")\n",
    "table_y3 = Table.read(IAN_BGS_Y3_MERGED_FILE_LOA, format='fits')\n",
    "df_y3 = table_to_df(table_y3, 20.175, BGS_Z_MIN, BGS_Z_MAX, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random subset of Y3 for validation (up to 100k)\n",
    "n_validate = min(100000, len(df_y3))\n",
    "validation_idx = np.random.choice(len(df_y3), size=n_validate, replace=False)\n",
    "df_y3_subset = df_y3.iloc[validation_idx].copy()\n",
    "print(f\"Loaded {n_validate:,} Y3 galaxies for validation\")\n",
    "\n",
    "# Remove data points that were in Y1 (use TARGETID)\n",
    "y1_targetids = set(df['TARGETID'].values)\n",
    "not_in_y1 = ~df_y3_subset['TARGETID'].isin(y1_targetids)\n",
    "df_y3_subset = df_y3_subset[not_in_y1].copy()\n",
    "print(f\"After removing Y1 galaxies: {len(df_y3_subset):,} Y3 galaxies remaining\")\n",
    "\n",
    "# Filter to galaxies with all required data\n",
    "has_kcorr = ~np.isnan(df_y3_subset['ABSMAG01_SDSS_R']) & ~np.isnan(df_y3_subset['ABSMAG01_SDSS_G'])\n",
    "has_mags = ~np.isnan(df_y3_subset['ABS_MAG_R']) & ~np.isnan(df_y3_subset['ABS_MAG_G'])\n",
    "has_z = ~np.isnan(df_y3_subset['Z'])\n",
    "valid_y3 = has_kcorr & has_mags & has_z\n",
    "\n",
    "df_y3_valid = df_y3_subset[valid_y3].copy()\n",
    "print(f\"Number of Y3 galaxies with complete data: {len(df_y3_valid):,}\")\n",
    "\n",
    "# Load the saved lookup table\n",
    "print(f\"\\nLoading lookup table from {BGS_Y3_KCORR_LOOKUP_FILE}...\")\n",
    "lookup = kcorrlookup()\n",
    "\n",
    "# Query the lookup table for Y3 galaxies\n",
    "z_y3 = df_y3_valid['Z'].to_numpy()\n",
    "magr_y3 = df_y3_valid['ABS_MAG_R'].to_numpy()\n",
    "magg_y3 = df_y3_valid['ABS_MAG_G'].to_numpy()\n",
    "gmr_y3 = magg_y3 - magr_y3\n",
    "\n",
    "# Get predicted k-corrections\n",
    "pred_kcorr_r_y3, pred_kcorr_g_y3  = lookup.query(gmr_y3, z_y3, magr_y3)\n",
    "\n",
    "# True k-corrections from Y3\n",
    "true_kcorr_r_y3 = magr_y3 - df_y3_valid['ABSMAG01_SDSS_R'].to_numpy()\n",
    "true_kcorr_g_y3 = magg_y3 - df_y3_valid['ABSMAG01_SDSS_G'].to_numpy()\n",
    "\n",
    "# Calculate errors\n",
    "kcorr_r_error = pred_kcorr_r_y3 - true_kcorr_r_y3\n",
    "kcorr_g_error = pred_kcorr_g_y3 - true_kcorr_g_y3\n",
    "\n",
    "# Calculate predicted k-corrected magnitudes\n",
    "pred_abs_mag_r_kcorr = magr_y3 - pred_kcorr_r_y3\n",
    "pred_abs_mag_g_kcorr = magg_y3 - pred_kcorr_g_y3\n",
    "pred_gmr_kcorr = pred_abs_mag_g_kcorr - pred_abs_mag_r_kcorr\n",
    "\n",
    "# True k-corrected magnitudes\n",
    "true_abs_mag_r_kcorr = df_y3_valid['ABSMAG01_SDSS_R'].to_numpy()\n",
    "true_abs_mag_g_kcorr = df_y3_valid['ABSMAG01_SDSS_G'].to_numpy()\n",
    "true_gmr_kcorr = true_abs_mag_g_kcorr - true_abs_mag_r_kcorr\n",
    "\n",
    "# Calculate magnitude errors\n",
    "abs_mag_r_error = pred_abs_mag_r_kcorr - true_abs_mag_r_kcorr\n",
    "gmr_error = pred_gmr_kcorr - true_gmr_kcorr\n",
    "\n",
    "# Print validation statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nK-correction errors:\")\n",
    "print(f\"  r-band k-corr MAE: {np.mean(np.abs(kcorr_r_error)):.4f} mag\")\n",
    "print(f\"  g-band k-corr MAE: {np.mean(np.abs(kcorr_g_error)):.4f} mag\")\n",
    "print(f\"  r-band k-corr RMS: {np.sqrt(np.mean(kcorr_r_error**2)):.4f} mag\")\n",
    "print(f\"  g-band k-corr RMS: {np.sqrt(np.mean(kcorr_g_error**2)):.4f} mag\")\n",
    "\n",
    "print(\"\\nK-corrected magnitude errors:\")\n",
    "print(f\"  r-band abs mag MAE: {np.mean(np.abs(abs_mag_r_error)):.4f} mag\")\n",
    "print(f\"  g-r color MAE: {np.mean(np.abs(gmr_error)):.4f} mag\")\n",
    "print(f\"  r-band abs mag RMS: {np.sqrt(np.mean(abs_mag_r_error**2)):.4f} mag\")\n",
    "print(f\"  g-r color RMS: {np.sqrt(np.mean(gmr_error**2)):.4f} mag\")\n",
    "\n",
    "\n",
    "# Plot validation results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: K-correction comparison for r-band\n",
    "ax = axes[0, 0]\n",
    "# TODO plot the color some some other property to see if I should add it to the lookup\n",
    "ax.scatter(true_kcorr_r_y3, pred_kcorr_r_y3, alpha=0.1, s=1)\n",
    "ax.plot([-1, 1], [-1, 1], 'r--', lw=2)\n",
    "ax.set_xlim(-0.5, 1)\n",
    "ax.set_ylim(-0.5, 1)\n",
    "ax.set_xlabel('True r-band k-correction')\n",
    "ax.set_ylabel('Predicted r-band k-correction')\n",
    "ax.set_title(f'r-band k-correction\\nMAE={np.mean(np.abs(kcorr_r_error)):.4f}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: K-correction comparison for g-band\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(true_kcorr_g_y3, pred_kcorr_g_y3, alpha=0.1, s=1)\n",
    "ax.plot([-1, 1], [-1, 1], 'r--', lw=2)\n",
    "ax.set_xlim(-0.5, 2)\n",
    "ax.set_ylim(-0.5, 2)\n",
    "ax.set_xlabel('True g-band k-correction')\n",
    "ax.set_ylabel('Predicted g-band k-correction')\n",
    "ax.set_title(f'g-band k-correction\\nMAE={np.mean(np.abs(kcorr_g_error)):.4f}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: K-correction error histogram\n",
    "ax = axes[0, 2]\n",
    "ax.hist(kcorr_r_error, bins=50, alpha=0.5, label='r-band', density=True)\n",
    "ax.hist(kcorr_g_error, bins=50, alpha=0.5, label='g-band', density=True)\n",
    "ax.axvline(0, color='k', linestyle='--', lw=2)\n",
    "ax.set_xlim(-1.0, 1.0)\n",
    "ax.set_xlabel('K-correction error (mag)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('K-correction error distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Absolute magnitude comparison\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(true_abs_mag_r_kcorr, pred_abs_mag_r_kcorr, alpha=0.1, s=1)\n",
    "ax.plot([-24, -16], [-24, -16], 'r--', lw=2)\n",
    "ax.set_xlabel('True k-corrected r-band abs mag')\n",
    "ax.set_ylabel('Predicted k-corrected r-band abs mag')\n",
    "ax.set_title(f'Absolute magnitude\\nMAE={np.mean(np.abs(abs_mag_r_error)):.4f}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: g-r color comparison\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(true_gmr_kcorr, pred_gmr_kcorr, alpha=0.1, s=1)\n",
    "ax.plot([0, 1.5], [0, 1.5], 'r--', lw=2)\n",
    "ax.set_xlabel('True k-corrected g-r color')\n",
    "ax.set_ylabel('Predicted k-corrected g-r color')\n",
    "ax.set_title(f'g-r color\\nMAE={np.mean(np.abs(gmr_error)):.4f}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Error vs redshift\n",
    "ax = axes[1, 2]\n",
    "ax.scatter(z_y3, abs_mag_r_error, alpha=0.1, s=1)\n",
    "ax.axhline(0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Redshift')\n",
    "ax.set_ylabel('Abs mag error (mag)')\n",
    "ax.set_title('Error vs redshift')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12cafcc",
   "metadata": {},
   "source": [
    "## Valdiation of the Final dn4000lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of Dn4000 lookup on Y3 data\n",
    "print(\"Loading Y3 validation data for Dn4000...\")\n",
    "\n",
    "# Use the same Y3 subset we already loaded\n",
    "# Filter to galaxies with all required Dn4000 data\n",
    "has_dn4000 = ~np.isnan(df_y3_subset['DN4000_MODEL'])\n",
    "has_logmstar = ~np.isnan(df_y3_subset['LOGMSTAR'])\n",
    "has_mags = ~np.isnan(df_y3_subset['ABS_MAG_R']) & ~np.isnan(df_y3_subset['ABS_MAG_G'])\n",
    "valid_dn4000_y3 = has_dn4000 & has_logmstar & has_mags & not_in_y1\n",
    "\n",
    "df_y3_dn4000 = df_y3_subset[valid_dn4000_y3].copy()\n",
    "print(f\"Number of Y3 galaxies with complete Dn4000 data: {len(df_y3_dn4000):,}\")\n",
    "\n",
    "# Load the saved Dn4000 lookup table\n",
    "print(f\"\\nLoading Dn4000 lookup table from {BGS_Y3_DN4000_LOOKUP_FILE}...\")\n",
    "dn4000_lookup = dn4000lookup()\n",
    "\n",
    "# Query the lookup table for Y3 galaxies\n",
    "magr_y3_dn = df_y3_dn4000['ABS_MAG_R'].to_numpy()\n",
    "magg_y3_dn = df_y3_dn4000['ABS_MAG_G'].to_numpy()\n",
    "gmr_y3_dn = magg_y3_dn - magr_y3_dn\n",
    "\n",
    "# Get predicted values\n",
    "pred_dn4000_y3, pred_logmstar_y3 = dn4000_lookup.query(gmr_y3_dn, magr_y3_dn)\n",
    "\n",
    "# True values from Y3\n",
    "true_dn4000_y3 = df_y3_dn4000['DN4000_MODEL'].to_numpy()\n",
    "true_logmstar_y3 = df_y3_dn4000['LOGMSTAR'].to_numpy()\n",
    "\n",
    "# Calculate errors\n",
    "dn4000_error = pred_dn4000_y3 - true_dn4000_y3\n",
    "logmstar_error = pred_logmstar_y3 - true_logmstar_y3\n",
    "\n",
    "# Print validation statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DN4000 VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDn4000 errors:\")\n",
    "print(f\"  Dn4000 MAE: {np.mean(np.abs(dn4000_error)):.4f}\")\n",
    "print(f\"  Dn4000 RMS: {np.sqrt(np.mean(dn4000_error**2)):.4f}\")\n",
    "print(f\"  Dn4000 median error: {np.median(dn4000_error):.4f}\")\n",
    "print(f\"  Dn4000 std: {np.std(dn4000_error):.4f}\")\n",
    "\n",
    "print(\"\\nLogMstar errors:\")\n",
    "print(f\"  LogMstar MAE: {np.mean(np.abs(logmstar_error)):.4f}\")\n",
    "print(f\"  LogMstar RMS: {np.sqrt(np.mean(logmstar_error**2)):.4f}\")\n",
    "print(f\"  LogMstar median error: {np.median(logmstar_error):.4f}\")\n",
    "print(f\"  LogMstar std: {np.std(logmstar_error):.4f}\")\n",
    "\n",
    "# Plot validation results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Dn4000 comparison\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(true_dn4000_y3, pred_dn4000_y3, alpha=0.1, s=1)\n",
    "ax.plot([1.0, 2.5], [1.0, 2.5], 'r--', lw=2)\n",
    "ax.set_xlim(1.0, 2.5)\n",
    "ax.set_ylim(1.0, 2.5)\n",
    "ax.set_xlabel('True Dn4000')\n",
    "ax.set_ylabel('Predicted Dn4000')\n",
    "ax.set_title(f'Dn4000\\nMAE={np.mean(np.abs(dn4000_error)):.4f}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: LogMstar comparison\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(true_logmstar_y3, pred_logmstar_y3, alpha=0.1, s=1)\n",
    "ax.plot([8, 12], [8, 12], 'r--', lw=2)\n",
    "ax.set_xlim(8, 12)\n",
    "ax.set_ylim(8, 12)\n",
    "ax.set_xlabel('True log(M*/M_sun)')\n",
    "ax.set_ylabel('Predicted log(M*/M_sun)')\n",
    "ax.set_title(f'Stellar Mass\\nMAE={np.mean(np.abs(logmstar_error)):.4f}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Error histograms\n",
    "ax = axes[0, 2]\n",
    "ax.hist(dn4000_error, bins=50, alpha=0.7, label='Dn4000', density=True)\n",
    "ax.axvline(0, color='k', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Dn4000 error')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Dn4000 error distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Error vs g-r color\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(gmr_y3_dn, dn4000_error, alpha=0.1, s=1)\n",
    "ax.axhline(0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('g-r color')\n",
    "ax.set_ylabel('Dn4000 error')\n",
    "ax.set_title('Error vs color')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Error vs absolute magnitude\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(magr_y3_dn, dn4000_error, alpha=0.1, s=1)\n",
    "ax.axhline(0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('M_r (abs mag)')\n",
    "ax.set_ylabel('Dn4000 error')\n",
    "ax.set_title('Error vs magnitude')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: LogMstar error histogram\n",
    "ax = axes[1, 2]\n",
    "ax.hist(logmstar_error, bins=50, alpha=0.7, label='LogMstar', density=True)\n",
    "ax.axvline(0, color='k', linestyle='--', lw=2)\n",
    "ax.set_xlabel('log(M*) error')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Stellar mass error distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbe5e5",
   "metadata": {},
   "source": [
    "## Spot Check Final Lookup Tables\n",
    "For lost galaxies we want a Dn4000 value and stellar mass. But they have no spectra. So, using their k-corrected g-r color and their absolute magnitude (once a z is assigned to them), we can assigned a random Dn4000 based on similar observed galaxies. This approach helps keep whatever systematics are associated with out quiesence determination similar between lost and observed galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f329c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "lookup = dn4000lookup()\n",
    "# Pick 10 random index from df2\n",
    "n = np.min([len(df_y3), 1000])\n",
    "idx_test = np.random.choice(len(df_y3), size=n, replace=False)\n",
    "example_z = df_y3['Z'].values[idx_test]\n",
    "example_abs_mag = app_mag_to_abs_mag(df_y3['APP_MAG_R'].values[idx_test], example_z)\n",
    "dn4000_truth = df_y3['DN4000_MODEL'].values[idx_test]\n",
    "example_gmr = df_y3['APP_MAG_G'].values[idx_test] - df2['APP_MAG_R'].values[idx_test]\n",
    "quiescent_truth = df2['QUIESCENT'].values[idx_test]\n",
    "\n",
    "#example_abs_mag = np.random.uniform(-25, -14, size=100000) \n",
    "#example_gmr = np.random.uniform(-0.1, 2.5, size=100000) \n",
    "nearest_dn4000, near_logmstar = lookup.query(example_abs_mag, example_gmr)\n",
    "example_q = is_quiescent_BGS_dn4000(abs_mag_r_to_log_solar_L(example_abs_mag), nearest_dn4000, example_gmr)\n",
    "# TODO gmr_kcorr = \n",
    "example_q2 = is_quiescent_BGS_gmr(abs_mag_r_to_log_solar_L(example_abs_mag), example_gmr)\n",
    "\n",
    "# Print % classification that agrees\n",
    "agreement = np.sum(quiescent_truth == example_q) / len(example_q) * 100\n",
    "print(f\"\\nQuiescent classification agreement (dn4000 method): {agreement:.2f}%\\n\") # 76%\n",
    "agreement2 = np.sum(quiescent_truth == example_q2) / len(example_q2) * 100\n",
    "print(f\"Quiescent classification agreement (g-r method): {agreement2:.2f}%\\n\") # 81%\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Test {i}: M_r={example_abs_mag[i]:.2f}, g-r={example_gmr[i]:.2f}, T DN4000={dn4000_truth[i]:.3f}, lookup DN4000={nearest_dn4000[i]:.3f}, T Q={quiescent_truth[i].astype(int)}, lookup Q={example_q[i].astype(int)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef163f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "klookup = kcorrlookup()\n",
    "# Pick 10 random index from df_y3\n",
    "n = np.min([len(df_y3), 1000])\n",
    "idx_test = np.random.choice(len(df_y3), size=n, replace=False)\n",
    "example_z = df_y3['Z'].values[idx_test]\n",
    "example_abs_mag_r = app_mag_to_abs_mag(df_y3['APP_MAG_R'].values[idx_test], example_z)\n",
    "example_abs_mag_g = app_mag_to_abs_mag(df_y3['APP_MAG_G'].values[idx_test], example_z)\n",
    "true_abs_mag_r = df_y3['ABSMAG01_SDSS_R'].values[idx_test]\n",
    "true_abs_mag_g = df_y3['ABSMAG01_SDSS_G'].values[idx_test]\n",
    "\n",
    "#example_z = np.random.uniform(0.001, 0.5, size=1000)  # Replace with your actual data\n",
    "#example_abs_mag_r = np.random.uniform(-25, -15, size=1000)  # Replace with your actual data\n",
    "#example_abs_mag_g = np.random.uniform(-25, -15, size=1000)   # Replace with your actual data\n",
    "nearest_kcorr_r, nearest_kcorr_g = klookup.query(example_abs_mag_r, example_abs_mag_g, example_z)\n",
    "calculated_abs_mag_r, calculated_abs_mag_g = k_correct_fromlookup(example_abs_mag_r, example_abs_mag_g, example_z)\n",
    "\n",
    "# What % have a k-corrected g-r within 0.1 of the true value?\n",
    "true_gmr = true_abs_mag_g - true_abs_mag_r\n",
    "calc_gmr = calculated_abs_mag_g - calculated_abs_mag_r\n",
    "agreement = np.sum(np.abs(true_gmr - calc_gmr) < 0.1) / len(true_gmr) * 100\n",
    "print(f\"\\nK-correction g-r agreement within 0.1 mag: {agreement:.2f}%\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Test {i}: z={example_z[i]:.3f}, M_r={example_abs_mag_r[i]:.2f}, M_g={example_abs_mag_g[i]:.2f}, True M_r^0.1={true_abs_mag_r[i]:.2f}, Calc M_r^0.1={calculated_abs_mag_r[i]:.2f}, True M_g={true_abs_mag_g[i]:.2f}, Calc M_g={calculated_abs_mag_g[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51d1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
