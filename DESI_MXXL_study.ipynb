{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as c\n",
    "from scipy import special\n",
    "import h5py\n",
    "from astropy.wcs import WCS\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from pyutils import *\n",
    "import types\n",
    "import numpy.ma as ma\n",
    "import sys\n",
    "from random import randint\n",
    "from matplotlib.patches import Circle\n",
    "from astropy.modeling import models\n",
    "import pyarrow.feather as feather\n",
    "from ctypes import c_uint64\n",
    "\n",
    "ROOT_FOLDER = \"/Volumes/Seagate Backup Plus Drive/galaxy-groups-data/\"\n",
    "#ROOT_FOLDER = \"/mnt/f/galaxy-groups-data/\"\n",
    "#ROOT_FOLDER = \"bin/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic read-in of HDF5 data from MXXL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CUT_INDEX = 300000 #21201544 #3000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = h5py.File(ROOT_FOLDER + 'weights_3pass.hdf5', 'r')\n",
    "print(list(weights))\n",
    "print(list(weights['Data']))\n",
    "print(list(weights['Weight']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIT_CHOICE = 0\n",
    "SELECTOR = 2**BIT_CHOICE\n",
    "assigned = np.array(weights['Weight/bitweight0'][0:DATA_CUT_INDEX] & SELECTOR).astype(bool) # choose 1 of the 2048 fiber assignment realizations with this bitstring\n",
    "unassigned_count = np.sum(np.invert(assigned))\n",
    "print(np.sum(assigned), \"galaxies were assigned a fiber\", np.sum(assigned) / len(assigned))\n",
    "print(unassigned_count, \"galaxies were NOT assigned a fiber\", unassigned_count / len(assigned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common PLT helpers\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "def get_color(i):\n",
    "    co = colors[i%len(colors)]\n",
    "    return co"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of nearest neighbors implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = weights\n",
    "dec = input['Data/dec'][0:DATA_CUT_INDEX]\n",
    "ra = input['Data/ra'][0:DATA_CUT_INDEX]\n",
    "z_obs = input['Data/z_obs'][0:DATA_CUT_INDEX]\n",
    "app_mag = input['Data/app_mag'][0:DATA_CUT_INDEX]\n",
    "sim_halo_mass = input['Data/halo_mass'][0:DATA_CUT_INDEX]\n",
    "sim_halo_id = input['Data/mxxl_id'][0:DATA_CUT_INDEX]\n",
    "\n",
    "bright_filter = app_mag < 19.5 # makes a filter array (True/False values)\n",
    "redshift_filter = z_obs > 0 # makes a filter array (True/False values)\n",
    "keep = np.all([bright_filter, redshift_filter], axis=0)\n",
    "dec = dec[keep]\n",
    "ra = ra[keep]\n",
    "z_obs = z_obs[keep]\n",
    "sim_halo_mass = sim_halo_mass[keep]\n",
    "sim_halo_id = sim_halo_id[keep]\n",
    "\n",
    "count = len(dec)\n",
    "print(count, \"galaxies in HDF5 file\")\n",
    "\n",
    "# choose 1 of the 2048 fiber assignment realizations with this bitstring\n",
    "fiber_assigned_0 = assigned.astype(bool)\n",
    "fiber_assigned_0 = fiber_assigned_0[keep]\n",
    "fiber_not_assigned_0 = np.invert(fiber_assigned_0)\n",
    "indexes_not_assigned = np.argwhere(fiber_not_assigned_0)\n",
    "print(np.sum(fiber_assigned_0), \"galaxies were assigned a fiber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astropy NN Search with kdtrees\n",
    "catalog = coord.SkyCoord(ra=ra[fiber_assigned_0]*u.degree, dec=dec[fiber_assigned_0]*u.degree, frame='icrs')\n",
    "z_cat = z_obs[fiber_assigned_0]\n",
    "halo_mass_cat = sim_halo_mass[fiber_assigned_0]\n",
    "to_match = coord.SkyCoord(ra=ra[fiber_not_assigned_0]*u.degree, dec=dec[fiber_not_assigned_0]*u.degree, frame='icrs')\n",
    "\n",
    "idx, d2d, d3d = coord.match_coordinates_sky(to_match, catalog, storekdtree=False)\n",
    "\n",
    "z_eff_a = np.copy(z_obs)\n",
    "z_err_a = np.zeros(len(z_obs))\n",
    "\n",
    "# i is the index of the full sized array that needed a NN z value\n",
    "# j is the index along the to_match list corresponding to that\n",
    "# idx are the indexes of the NN from the catalog\n",
    "\n",
    "# Mhalo - (Mhalo of the NN galaxy)\n",
    "halo_delta = np.zeros(len(idx))\n",
    "\n",
    "j = 0\n",
    "for i in indexes_not_assigned:\n",
    "    assert np.isclose(ra[i], to_match[j].ra.value)\n",
    "    new_z = z_cat[idx[j]]\n",
    "    halo_delta[j] = sim_halo_mass[i] - halo_mass_cat[idx[j]]\n",
    "    z_err_a[i] = abs(z_eff_a[i] - new_z) / z_eff_a[i]\n",
    "    z_eff_a[i] = new_z\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine fractional error in assigned redshifts \n",
    "plt.hist(np.log10(z_err_a[fiber_not_assigned_0]), bins=50)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('log(fractional error) from known simulation value')\n",
    "plt.ylabel('Count')\n",
    "print(np.sum(z_err_a))\n",
    "print(np.count_nonzero(z_err_a))\n",
    "\n",
    "# convert to km/s and think about velocity dispersions of galaxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_assigned_error = z_err_a[fiber_not_assigned_0] * u.dimensionless_unscaled\n",
    "velocity_error = z_assigned_error.to(u.km / u.s, u.equivalencies.doppler_redshift())\n",
    "\n",
    "plt.hist(np.log10(velocity_error.value), bins=50)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('log(fractional error as km/s) from known simulation value')\n",
    "plt.ylabel('Count')\n",
    "print(np.sum(z_err_a))\n",
    "print(np.count_nonzero(z_err_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on MXXL Data Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple plots of basic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_gal_type = weights['Data/galaxy_type'][0:DATA_CUT_INDEX] # 0 1 2 3 possible\n",
    "bins = plt.hist(small_gal_type, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_z_obs = weights['Data/z_obs'][0:DATA_CUT_INDEX]\n",
    "bins = plt.hist(small_z_obs, bins=50)\n",
    "plt.xlabel(\"$z_{obs}$\")\n",
    "plt.title(\"Histogram of Observed Redshifts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = weights['Data/ra'][0:DATA_CUT_INDEX]\n",
    "dec = weights['Data/dec'][0:DATA_CUT_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a map of the galaxies\n",
    "\n",
    "ra_angles = coord.Angle(ra*u.degree)\n",
    "ra_angles = ra_angles.wrap_at(180*u.degree)\n",
    "dec_angles = coord.Angle(dec*u.degree)\n",
    "\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = fig.add_subplot(111, projection=\"mollweide\")\n",
    "ax.scatter(ra_angles.radian, dec_angles.radian, alpha=0.002)\n",
    "# This looks like Alex' paper, good\n",
    "# TODO how to get frac_area from this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxxl_halo_id = weights['Data/mxxl_id'][0:DATA_CUT_INDEX]\n",
    "np.sum(mxxl_halo_id == 0) / len(mxxl_halo_id)\n",
    "# TODO why do 2.5% of galaxies have 0 for the MXXL Halo ID? This may be messing us up\n",
    "\n",
    "weird_indexes = np.argwhere(np.invert(mxxl_halo_id.astype(bool)))\n",
    "weird_types = small_gal_type[weird_indexes]\n",
    "trash = plt.hist(weird_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_app_mag = weights['Data/app_mag'][0:DATA_CUT_INDEX]\n",
    "bins = plt.hist(small_app_mag, bins=50)\n",
    "plt.xlabel(\"Apparent Mag\")\n",
    "plt.title(\"Histogram of Apparent Mags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_abs_mag = weights['Data/abs_mag'][0:DATA_CUT_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating luminosity distances from the cosmology is a bit slow\n",
    "my_abs_mag = app_mag_to_abs_mag(small_app_mag, small_z_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare my_abs_mag to abs_mag. \n",
    "x = plt.hist(my_abs_mag, label=\"my abs_mag\", bins=50)\n",
    "y = plt.hist(small_abs_mag, label=\"alex abs_mag\", bins=50)\n",
    "plt.xlabel(\"Absolute Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Compare Absolute Mags\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At what distance (luminosity distance) would the objects appear to be 19.5 mag?\n",
    "v_max = get_max_observable_volume(my_abs_mag, small_z_obs, 19.5)\n",
    "v_max2 = get_max_observable_volume(small_abs_mag, small_z_obs, 19.5)\n",
    "\n",
    "bins = plt.hist(np.log10(v_max), label=\"my abs_mag\", bins=50)\n",
    "bins = plt.hist(np.log10(v_max2), label=\"alex abs_mag\", bins=50)\n",
    "plt.title(\"Compare V_max\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"log(V_max) [Mpc]\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a reasonable z fudge factor for 'close enough' redshifts given galaxies $v_{\\mathrm{pec}}$?\n",
    "\n",
    "Galaxies move at hundreds of km/s usually, or thousands in a rich cluster.\n",
    "\n",
    "Two galaxies moving at 600 km/s towards each other along LOS but at same cosmological redshift would have a total redshift difference of 0.004. This suggests a z +/- 0.002 is totally reasonable. In richer areas this could be as high as z +/- 0.010. \n",
    "\n",
    "Adopting z +/- 0.003 for now seems fine. Can refine later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a reasonable z +/- fudge factor for 'close enough' redshifts? \n",
    "# Consider peculiar velocities.\n",
    "z_test = [0.001, 0.002, 0.003, 0.005, 0.01] * u.dimensionless_unscaled\n",
    "v_pec = z_test.to(u.km / u.s, u.equivalencies.doppler_redshift())\n",
    "for i in range(len(z_test)):\n",
    "    print(f\"z={z_test[i]:.3f} is {v_pec[i]:.0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Truth Abs Mag for Correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_mag = weights['Data/app_mag'][:]\n",
    "z_obs = weights['Data/z_obs'][:]\n",
    "APP_MAG_CUT = 19.5\n",
    "bright_filter = app_mag < APP_MAG_CUT \n",
    "redshift_filter = z_obs > 0 \n",
    "keep = np.all([bright_filter, redshift_filter], axis=0)\n",
    "\n",
    "app_mag = app_mag[keep]\n",
    "z_obs = z_obs[keep]\n",
    "\n",
    "my_abs_mag = app_mag_to_abs_mag(app_mag, z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(my_abs_mag), max(my_abs_mag), 100)\n",
    "densities, bins  = np.histogram(my_abs_mag, bins=bins, density=True)\n",
    "t = plt.hist(my_abs_mag, bins, density=True)\n",
    "\n",
    "with open('bin/abs_mag_weight.npy', 'wb') as f:\n",
    "    np.save(f, densities, allow_pickle=False)\n",
    "    np.save(f, bins, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bin/abs_mag_weight.npy', 'rb') as f:\n",
    "    densities = np.load(f)\n",
    "    bins = np.load(f)\n",
    "\n",
    "plt.plot(bins[0:99], densities)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Angular Separation and Same-Halo Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = weights\n",
    "dec = input['Data/dec'][:]\n",
    "ra = input['Data/ra'][:]\n",
    "z_obs = input['Data/z_obs'][:]\n",
    "app_mag = input['Data/app_mag'][:]\n",
    "\n",
    "APP_MAG_CUT = 19.5\n",
    "bright_filter = app_mag < APP_MAG_CUT # makes a filter array (True/False values)\n",
    "redshift_filter = z_obs > 0 # makes a filter array (True/False values)\n",
    "#location_filter_1 = ra < 270.0\n",
    "#location_filter_2 = ra > 120.0\n",
    "#location_filter_3 = dec > 0.0\n",
    "#location_filter_4 = dec < 45.0\n",
    "keep = np.all([bright_filter, redshift_filter], axis=0)\n",
    "#keep = np.all([bright_filter, redshift_filter, location_filter_1, location_filter_2, location_filter_3, location_filter_4], axis=0)\n",
    "\n",
    "dec = dec[keep]\n",
    "ra = ra[keep]\n",
    "z_obs = z_obs[keep]\n",
    "app_mag = app_mag[keep]\n",
    "sim_halo_id = input['Data/mxxl_id'][:]\n",
    "sim_halo_id = sim_halo_id[keep]\n",
    "\n",
    "\n",
    "len(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIT_CHOICE = 0\n",
    "FIBER_ASSIGNED_SELECTOR = 2**BIT_CHOICE\n",
    "fassigned = (input['Weight/bitweight0'][:] & FIBER_ASSIGNED_SELECTOR).astype(bool) # choose 1 of the 2048 fiber assignment realizations with this bitstring\n",
    "fnotassigned = np.invert(fassigned)\n",
    "\n",
    "fassigned = fassigned[keep]\n",
    "fnotassigned = fnotassigned[keep]\n",
    "indexes_not_assigned = np.argwhere(fnotassigned)\n",
    "\n",
    "print(np.sum(fassigned) / len(dec))\n",
    "\n",
    "with open('bin/prob_obs.npy', 'rb') as f:\n",
    "    prob_obs = np.load(f)\n",
    "prob_obs_cut = prob_obs[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate IIP Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitsum(bitstring):\n",
    "    return bin(c_uint64(bitstring).value).count(\"1\")\n",
    "v_bitsum = np.vectorize(bitsum)\n",
    "\n",
    "def summate(a):\n",
    "    return np.sum(v_bitsum(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this if iips were loaded OK. Takes ~8 minutes.\n",
    "\n",
    "# Read all 32 64-bitstrings into memory from the file\n",
    "num_bitstrings = 32\n",
    "galaxy_count = len(input['Weight/bitweight0'])\n",
    "bitweights = np.empty((num_bitstrings, galaxy_count), dtype='i8')\n",
    "\n",
    "for i in range(num_bitstrings):\n",
    "    bitweights[i] = input['Weight/bitweight{0}'.format(i)][:]\n",
    "    \n",
    "prob_obs = np.apply_along_axis(summate, 0, bitweights) / 2048\n",
    "\n",
    "with open('bin/prob_obs.npy', 'wb') as f:\n",
    "    np.save(f, prob_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specimen = 123\n",
    "bit_selector = c_uint64(2).value\n",
    "print('{:064b}'.format(bit_selector))\n",
    "print('')\n",
    "for i in range(num_bitstrings):\n",
    "    value = bitweights[(i,specimen)]\n",
    "    converted = c_uint64(value).value\n",
    "    print('{:064b}'.format(converted), '{:2.0f}'.format(bitsum(value)), bool(converted & bit_selector))\n",
    "\n",
    "print(\"Averaged Probability of being targetted: \", prob_obs[specimen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_obs_cut = prob_obs[keep]\n",
    "\n",
    "pobs_bins_temp = np.linspace(0,1)\n",
    "trash=plt.hist(prob_obs, bins=pobs_bins_temp, label=\"All galaxies\")\n",
    "trash2=plt.hist(prob_obs_cut, bins=pobs_bins_temp, label=f\"Galaxies below {APP_MAG_CUT} mag\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_obs_dim = prob_obs[np.invert(keep)]\n",
    "trash=plt.hist(prob_obs_dim, bins=pobs_bins_temp, alpha=0.5, label=f\"Galaxies above {APP_MAG_CUT} mag\")\n",
    "trash2=plt.hist(prob_obs_cut, bins=pobs_bins_temp, alpha=0.5, label=f\"Galaxies below {APP_MAG_CUT} mag\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$P_{obs}$')\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Halo / Similar z Analysis\n",
    "\n",
    "What fraction of time nearest neighbors in same halo? \n",
    "\n",
    "What is the distribution of Angular distances?\n",
    "\n",
    "What fraction of time is nearest neighbors at a similar enough redshift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now bin so that things with ang distances higher than the max we care about are thrown out\n",
    "BIN_COUNT = 25\n",
    "bins = np.logspace(np.log10(3), np.log10(60*60), BIN_COUNT)\n",
    "print(\"Angular Distance Bin Markers\", bins)\n",
    "\n",
    "z_bins = [0.1, 0.2, 0.3, 1.0] # nothing can be higher than rightmost bin value\n",
    "z_bins = [0.08, 0.12, 0.16, 0.2, 0.24, 0.28, 0.36, 1.0] # nothing can be higher than rightmost bin value\n",
    "print(\"Redshift Bin Markers\", z_bins)\n",
    "\n",
    "POBS_BIN_COUNT = 25\n",
    "POBS_bins = np.linspace(0.01, 1.0, POBS_BIN_COUNT)\n",
    "print(\"Pobs Bin Markers\", POBS_bins)\n",
    "\n",
    "LOST_GALAXIES_ONLY = True\n",
    "\n",
    "if LOST_GALAXIES_ONLY:\n",
    "    treename = 'mxxl_same_halo_analysis_fiberassigned_b' + str(BIT_CHOICE)\n",
    "    catalog = coord.SkyCoord(ra=ra[fassigned]*u.degree, dec=dec[fassigned]*u.degree, frame='icrs')\n",
    "    sim_halo_id_catalog = sim_halo_id[fassigned]\n",
    "    z_obs_catalog = z_obs[fassigned]\n",
    "else:\n",
    "    treename = 'mxxl_same_halo_analysis_all'\n",
    "    catalog = coord.SkyCoord(ra=ra*u.degree, dec=dec*u.degree, frame='icrs')\n",
    "    sim_halo_id_catalog = sim_halo_id\n",
    "    z_obs_catalog = z_obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NN's angular distance distribution and same halo truth from MXXL\n",
    "\n",
    "# Though this is binned by z of the target and not the NN, it shouldn't be able to affect results\n",
    "# by recipricality of NN\n",
    "z_bin = np.digitize(z_obs, z_bins)\n",
    "\n",
    "if LOST_GALAXIES_ONLY:\n",
    "    nn_bins = np.arange(5)+1\n",
    "else:\n",
    "    nn_bins = [2]#[2,3,4] # this means closest 3. '1' will find the same object.\n",
    "\n",
    "all_ang_bincounts = np.ones((len(z_bins), len(nn_bins), len(bins)))\n",
    "all_same_halo_bincounts = np.zeros((len(z_bins), len(nn_bins), len(bins)))\n",
    "all_same_z_bincounts = np.zeros((len(z_bins), len(nn_bins), len(bins)))\n",
    "all_sim_z_bincounts = np.zeros((len(z_bins), len(nn_bins), len(bins)))\n",
    "\n",
    "for i in range(len(z_bins)):\n",
    "    for j in range(len(nn_bins)):\n",
    "        if LOST_GALAXIES_ONLY:\n",
    "            filter = np.all([z_bin == i, fnotassigned], axis=0)\n",
    "        else:\n",
    "            filter = z_bin == i\n",
    "        to_match = coord.SkyCoord(ra=ra[filter]*u.degree, dec=dec[filter]*u.degree, frame='icrs')\n",
    "        idx, d2d, d3d = coord.match_coordinates_sky(to_match, catalog, nthneighbor=nn_bins[j], storekdtree=treename)\n",
    "\n",
    "        same_halo = sim_halo_id[filter] == sim_halo_id_catalog[idx]\n",
    "        same_z = np.isclose(z_obs[filter], z_obs_catalog[idx], rtol=0, atol=0.000001)\n",
    "        sim_z = np.isclose(z_obs[filter], z_obs_catalog[idx], rtol=0, atol=SIM_Z_THRESH)\n",
    "        \n",
    "        angdist_bin_ind = np.digitize(d2d.to(u.arcsec).value, bins)\n",
    "        \n",
    "        bincounts = np.bincount(angdist_bin_ind, minlength=len(bins)) + 1 # avoids divide by 0, won't hurt statistics\n",
    "        all_ang_bincounts[i][j] = bincounts\n",
    "\n",
    "        bincounts2 = np.bincount(angdist_bin_ind, minlength=len(bins), weights=same_halo.astype(int))\n",
    "        all_same_halo_bincounts[i][j] = bincounts2\n",
    "\n",
    "        bincount3 = np.bincount(angdist_bin_ind, minlength=len(bins), weights=same_z.astype(int))\n",
    "        all_same_z_bincounts[i][j] = bincount3\n",
    "\n",
    "        bincount4 = np.bincount(angdist_bin_ind, minlength=len(bins), weights=sim_z.astype(int))\n",
    "        all_sim_z_bincounts[i][j] = bincount4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Galaxies studied: {0}. Same halo: {1}. Similar z: {2}\".format(np.sum(all_ang_bincounts), np.sum(all_same_halo_bincounts), np.sum(all_sim_z_bincounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "#for b in range(len(all_same_halo_bincounts)):\n",
    "#    print(all_same_halo_bincounts[b], all_same_z_bincounts[b], len(all_same_z_bincounts))\n",
    "\n",
    "np.all(np.isclose(all_same_halo_bincounts, all_same_z_bincounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlabel(index, z_bins):\n",
    "    if index==0:\n",
    "        label = \"< {0}\".format(z_bins[index])\n",
    "    else:\n",
    "        label = \"{0} - {1}\".format(z_bins[index-1], z_bins[index])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for nearest-neighbor angular distances and same-halo analysis\n",
    "\n",
    "for j in range(len(nn_bins)):\n",
    "    if j < 5:\n",
    "        plt.figure()\n",
    "        for i in range(len(z_bins)):\n",
    "            label = getlabel(i, z_bins)\n",
    "        plt.plot(bins, all_ang_bincounts[i][j], label=label, color=get_color(i))\n",
    "\n",
    "        plt.title(f\"Nearest Neighbor {j} Ang. Distance Distribution\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xlabel(\"Angular Distance (arcsec)\")\n",
    "        plt.yscale('log')\n",
    "        plt.xscale('log')\n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(len(z_bins)):\n",
    "            label = getlabel(i, z_bins)\n",
    "            plt.plot(bins, all_same_halo_bincounts[i][j]/all_ang_bincounts[i][j], label=label, color=get_color(i))\n",
    "            print(\"Total fraction of nearest neighbors in same halo (z {0}, NN-{1}): {2:.3f}\".format(label, j+1, np.sum(all_same_halo_bincounts[i][j]) / np.sum(all_ang_bincounts[i][j])))\n",
    "\n",
    "        plt.title(f\"Nearest Neighbor {j} Same Halo Fraction\")\n",
    "        plt.ylabel(\"NN Same Halo Fraction\")\n",
    "        plt.xlabel(\"Angular Distance (arcsec)\")\n",
    "        plt.xscale('log')\n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(len(z_bins)):\n",
    "            label = getlabel(i, z_bins)\n",
    "            plt.plot(bins, all_sim_z_bincounts[i][j]/all_ang_bincounts[i][j], label=label, color=get_color(i))\n",
    "            \n",
    "            print(\"Total fraction of nearest neighbors at sim z (z {0}, NN-{1}): {2:.3f}\".format(label, j+1, np.sum(all_sim_z_bincounts[i][j]) / np.sum(all_ang_bincounts[i][j])))\n",
    "\n",
    "        plt.title(f\"Nearest Neighbor {j} Sim z Fraction\")\n",
    "        plt.ylabel(\"NN Sim z Fraction\")\n",
    "        plt.xlabel(\"Angular Distance (arcsec)\")\n",
    "        plt.xscale('log')\n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "\n",
    "#print(\"What fraction of the time is the NN >19.5 mag?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POBS_bin = np.digitize(prob_obs_cut, POBS_bins)\n",
    "\n",
    "if LOST_GALAXIES_ONLY: \n",
    "    nn_bins = [1]\n",
    "else:\n",
    "    nn_bins = [2] # since catalog includes the targets in this case\n",
    "\n",
    "all_ang_bincounts_2 = np.ones((POBS_BIN_COUNT, len(nn_bins), len(z_bins), BIN_COUNT))\n",
    "all_same_halo_bincounts_2 = np.zeros((POBS_BIN_COUNT, len(nn_bins), len(z_bins), BIN_COUNT))\n",
    "all_sim_z_bincounts_2 = np.zeros((POBS_BIN_COUNT, len(nn_bins), len(z_bins), BIN_COUNT))\n",
    "\n",
    "for i in range(len(POBS_bins)):\n",
    "    for j in range(len(nn_bins)):\n",
    "        if LOST_GALAXIES_ONLY:\n",
    "            filter = np.all([POBS_bin == i, fnotassigned], axis=0)\n",
    "        else:\n",
    "            filter = POBS_bin == i\n",
    "        to_match = coord.SkyCoord(ra=ra[filter]*u.degree, dec=dec[filter]*u.degree, frame='icrs')\n",
    "        idx, d2d, d3d = coord.match_coordinates_sky(to_match, catalog, nthneighbor=nn_bins[j], storekdtree=treename)\n",
    "        same_halo = sim_halo_id[filter] == sim_halo_id_catalog[idx]\n",
    "        sim_z = np.isclose(z_obs[filter], z_obs_catalog[idx], rtol=0, atol=SIM_Z_THRESH)\n",
    "\n",
    "        nn_z_bin_ind = np.digitize(z_obs_catalog[idx], z_bins)\n",
    "        angdist_bin_ind = np.digitize(d2d.to(u.arcsec).value, bins)\n",
    "        \n",
    "        for zb in range(len(z_bins)):\n",
    "            right_z_bin = nn_z_bin_ind == zb\n",
    "            bincounts = np.bincount(angdist_bin_ind, minlength=len(bins), weights=right_z_bin.astype(int)) + 1 # avoids divide by 0, won't hurt statistics\n",
    "            all_ang_bincounts_2[i][j][zb] = bincounts\n",
    "\n",
    "            bincounts2 = np.bincount(angdist_bin_ind, minlength=len(bins), weights=np.all([same_halo, right_z_bin], axis=0).astype(int))\n",
    "            all_same_halo_bincounts_2[i][j][zb] = bincounts2\n",
    "\n",
    "            bincounts3 = np.bincount(angdist_bin_ind, minlength=len(bins), weights=np.all([sim_z, right_z_bin], axis=0).astype(int))\n",
    "            all_sim_z_bincounts_2[i][j][zb] = bincounts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_same = all_same_halo_bincounts_2 / all_ang_bincounts_2\n",
    "frac_sim_z = all_sim_z_bincounts_2 / all_ang_bincounts_2\n",
    "success_bins = [0,0.25,0.5,1.0]\n",
    "frac_same_binned = np.digitize(frac_same, bins=success_bins)\n",
    "#for i in range(len(frac_same_binned)):\n",
    "#    frac_same_binned[i] = success_bins[frac_same_binned[i-1]]\n",
    "frac_same_over50 = (frac_same > 0.5).astype(int)\n",
    "frac_at50 = close_enough(frac_same, 0.5, threshold=0.05).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_NN_50_line(z, t_Pobs):\n",
    "    FIT_SHIFT_RIGHT = [15,20,20,20,25,25,35,40]\n",
    "    FIT_SCALE = [10,10,10,10,10,10,10,10]\n",
    "    FIT_SHIFT_UP = [0.8,0.8,0.8,0.8,0.8,0.8,0.6,0.5]\n",
    "    FIT_SQUEEZE = [1.3,1.3,1.3,1.3,1.4,1.4,1.5,1.5]\n",
    "    #z_bins = [0.1,0.2,0.3,1.0]\n",
    "    base = [1.16,1.16,1.16,1.16,1.12,1.12,1.08,1.08]\n",
    "    zb = np.digitize(z, z_bins)\n",
    "\n",
    "    # for higher and lower z bit just use simple cut\n",
    "    if zb in [6,7]:\n",
    "        return np.full(t_Pobs.shape, 10)\n",
    "    #if zb == 7:\n",
    "    #    return np.full(t_Pobs.shape, 10)\n",
    "\n",
    "    erf_in = FIT_SQUEEZE[zb]*(t_Pobs - FIT_SHIFT_UP[zb])\n",
    "\n",
    "    # for middle ones use exponentiated inverse erf to get the curve \n",
    "    exponent = FIT_SHIFT_RIGHT[zb] - FIT_SCALE[zb]*special.erfinv(erf_in)\n",
    "    fit = base[zb]**exponent\n",
    "    return fit\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(z_bins), ncols=4, figsize=(24, 4*len(z_bins)))\n",
    "\n",
    "\n",
    "for zb in range(len(z_bins)):\n",
    "    density = all_ang_bincounts_2[:,0,zb,:] #/ np.sum(all_ang_bincounts_2[:,0,zb,:])\n",
    "    print(f\"Galaxies in this z-bin: {np.sum(density)}\")\n",
    "\n",
    "    cplot = axes[zb][0].pcolor(bins, POBS_bins, frac_same_binned[:,0,zb,:], shading='auto', cmap='RdYlGn')\n",
    "    #cplot = axes[zb][0].pcolor(bins, POBS_bins, frac_same_over50[:,0,zb,:], shading='auto', cmap='RdYlGn', norm=c.Normalize(vmin=0, vmax=0.8))\n",
    "    fig.colorbar(cplot, ax=axes[zb][0])\n",
    "    axes[zb][0].set_title(f\"Nearest Neighbor Same Halo Over 50% (NN z {getlabel(zb, z_bins)})\")\n",
    "    axes[zb][0].set_ylabel(\"Lost Galaxy $P_{obs}$\")\n",
    "    axes[zb][0].set_xlabel(\"Angular Distance (arcsec) to NN\")\n",
    "    axes[zb][0].set_xscale('log')\n",
    "    axes[zb][0].set_xlim(3,250)\n",
    "\n",
    "    cplot = axes[zb][1].pcolor(bins, POBS_bins, frac_same[:,0,zb,:], shading='auto', cmap='RdYlGn', norm=c.Normalize(vmin=0, vmax=0.8))\n",
    "    fig.colorbar(cplot, ax=axes[zb][1])\n",
    "    axes[zb][1].set_title(f\"Nearest Neighbor Same Halo (NN z {getlabel(zb, z_bins)})\")\n",
    "    axes[zb][1].set_ylabel(\"Lost Galaxy $P_{obs}$\")\n",
    "    axes[zb][1].set_xlabel(\"Angular Distance (arcsec) to NN\")\n",
    "    axes[zb][1].set_xscale('log')\n",
    "\n",
    "    cplot = axes[zb][2].pcolor(bins, POBS_bins, frac_sim_z[:,0,zb,:], shading='auto', cmap='RdYlGn', norm=c.Normalize(vmin=0, vmax=0.8))\n",
    "    fig.colorbar(cplot, ax=axes[zb][2])\n",
    "    axes[zb][2].set_title(f\"Nearest Neighbor Sim z Fraction (NN z {getlabel(zb, z_bins)})\")\n",
    "    axes[zb][2].set_ylabel(\"Lost Galaxy $P_{obs}$\")\n",
    "    axes[zb][2].set_xlabel(\"Angular Distance (arcsec) to NN\")\n",
    "    axes[zb][2].set_xscale('log')\n",
    "\n",
    "    #cplot = axes[zb][3].pcolor(bins, POBS_bins, density, shading='auto', cmap='YlGn', norm=c.LogNorm(vmin=0.0001, vmax=0.1))\n",
    "    cplot = axes[zb][3].pcolor(bins, POBS_bins, density, shading='auto', cmap='YlGn', norm=c.LogNorm(vmin=10, vmax=5000))\n",
    "    fig.colorbar(cplot, ax=axes[zb][3])\n",
    "    axes[zb][3].set_title(f\"Counts (NN z {getlabel(zb, z_bins)})\")\n",
    "    axes[zb][3].set_ylabel(\"Lost Galaxy $P_{obs}$\")\n",
    "    axes[zb][3].set_xlabel(\"Angular Distance (arcsec) to NN\")\n",
    "    axes[zb][3].set_xscale('log')\n",
    "\n",
    "    axes[zb][0].scatter(get_NN_50_line(z_bins[zb]-0.01, POBS_bins), POBS_bins)\n",
    "    axes[zb][1].scatter(get_NN_50_line(z_bins[zb]-0.01, POBS_bins), POBS_bins)\n",
    "    axes[zb][2].scatter(get_NN_50_line(z_bins[zb]-0.01, POBS_bins), POBS_bins)\n",
    "    \n",
    "fig.tight_layout() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using z +/- {0} values as a success metric:\\n \".format(SIM_Z_THRESH))\n",
    "for i in range(BIN_COUNT):\n",
    "    arcsec = bins[i]\n",
    "    tot = np.sum(all_ang_bincounts[:,0,0:i])\n",
    "    frac = np.sum(all_sim_z_bincounts[:,0,0:i]) / np.sum(all_ang_bincounts[:,0,0:i])\n",
    "    frac_assigned = np.sum(all_ang_bincounts[:,0,0:i]) / np.sum(all_ang_bincounts[:,0,:])\n",
    "    print(\"  Up to {0:.1f}\\\": Success frac: {1:.3f}. Assigned frac: {2:.3f}\".format(arcsec, frac, frac_assigned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine velocities between neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NEIGHBORS = 20\n",
    "fancy_to_match = coord.SkyCoord(ra=ra[fnotassigned]*u.degree, dec=dec[fnotassigned]*u.degree, frame='icrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_indexes = np.zeros(shape=(NUM_NEIGHBORS, len(fancy_to_match)), dtype=np.int32) # indexes point to CATALOG locations\n",
    "ang_distances = np.zeros(shape=(NUM_NEIGHBORS, len(fancy_to_match)))\n",
    "\n",
    "print(f\"Finding nearest {NUM_NEIGHBORS} neighbors... \", end='\\r')   \n",
    "for n in range(0, NUM_NEIGHBORS):\n",
    "    idx, d2d, d3d = coord.match_coordinates_sky(fancy_to_match, catalog, nthneighbor=n+1, storekdtree=treename)\n",
    "    neighbor_indexes[n] = idx # TODO is that right?\n",
    "    ang_distances[n] = d2d.to(u.arcsec).value\n",
    "print(f\"Finding nearest {NUM_NEIGHBORS} neighbors... done!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with RedshiftGuesser(NUM_NEIGHBORS, debug=False) as scorer:\n",
    "    halo_matches = 0\n",
    "    z_matches = 0\n",
    "\n",
    "    print(f\"Assinging missing redshifts... \")   \n",
    "    # TODO don't loop?\n",
    "    j = 0 # index of the fancy_to_match sized arrays\n",
    "    \n",
    "    #for i in special_id:\n",
    "    for i in indexes_not_assigned: # index of the master arrays\n",
    "\n",
    "        #if i not in [7793057, 11425052]:\n",
    "        #    j+=1\n",
    "        #    continue\n",
    "\n",
    "        if j%10000==0:\n",
    "            print(f\"{j}/{len(fancy_to_match)} complete\", end='\\r')\n",
    "\n",
    "        neighbors = neighbor_indexes[:,j]\n",
    "        neighbors_z = z_obs_catalog[neighbors]\n",
    "        neighbors_ang_dist = ang_distances[:,j]\n",
    "        my_prob_obs = prob_obs_cut[i]\n",
    "        my_app_mag = app_mag[i]\n",
    "\n",
    "        winning_num = scorer.choose_winner(neighbors_z, neighbors_ang_dist, my_prob_obs, my_app_mag, z_obs[i])\n",
    "        winner_index = neighbors[winning_num]\n",
    "\n",
    "        # Track total correct\n",
    "        z_chosen = z_obs_catalog[winner_index] \n",
    "        if np.isclose(z_chosen, z_obs[i], rtol=0, atol=SIM_Z_THRESH):\n",
    "            z_matches += 1\n",
    "        halo_chosen = sim_halo_id_catalog[winner_index]\n",
    "        if halo_chosen == sim_halo_id[i]:\n",
    "            halo_matches += 1\n",
    "\n",
    "        j += 1 \n",
    "\n",
    "    print(f\"{j}/{len(fancy_to_match)} complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Halo matches: {halo_matches / len(fancy_to_match)}\")\n",
    "print(f\"z matches: {z_matches / len(fancy_to_match)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results from a run of the RedshiftGuesser. Must put in the right filename (number)\n",
    "filename = 'bin/redshift_guesser_1691466513.171286.npy'\n",
    "with open(filename, 'rb') as f:\n",
    "    quick_nn = np.load(f)\n",
    "    quick_correct = np.load(f)\n",
    "    nn_used = np.load(f)\n",
    "    nn_correct = np.load(f)\n",
    "\n",
    "print(f\"Quick NN uses: {quick_nn}. Success: {quick_correct / (quick_nn+1)}\")\n",
    "print(f\"NN bin uses: {nn_used}. Success: {nn_correct / (nn_used+1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Galaxy Pairs Angular Separation and Same-Halo Analysis\n",
    "Continuation of the above.\n",
    "\n",
    "THIS IS N^2 CALCULATION do not run on full sky. Adjust data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS N^2 CALCULATION do not run on full sky.\n",
    "total_bincounts = np.ones((len(z_bins), BIN_COUNT))\n",
    "total_same_halo_bincounts = np.zeros((len(z_bins), BIN_COUNT))\n",
    "\n",
    "# Examine each galaxy in the sample pair once\n",
    "for i in range(len(ra)-1):\n",
    "    ang_distance = coord.angular_separation(ra[i]*u.degree, dec[i]*u.degree, ra[i+1:len(ra)]*u.degree, dec[i+1:len(ra)]*u.degree).to(u.arcsec)\n",
    "        \n",
    "    same_halo = sim_halo_id[i] == sim_halo_id[i+1:len(ra)]\n",
    "    #print(\"Same halo fraction for {0}:\".format(i), np.sum(same_halo) / len(same_halo))\n",
    "\n",
    "    angdist_bin_ind = np.digitize(ang_distance.value, bins)\n",
    "    #print(bin_ind)\n",
    "    bincounts = np.bincount(angdist_bin_ind)[0:BIN_COUNT]\n",
    "    same_halo_bincounts = np.bincount(angdist_bin_ind, weights= same_halo.astype(int)) [0:BIN_COUNT]\n",
    "\n",
    "    z_bin = np.digitize(z_obs[i], z_bins)\n",
    "    total_bincounts[z_bin] = total_bincounts[z_bin] + bincounts\n",
    "    total_same_halo_bincounts[z_bin] = total_same_halo_bincounts[z_bin] + same_halo_bincounts\n",
    "    #print(total_same_halo_bincounts)\n",
    "\n",
    "#print(\"Total counts in each bin:\", total_bincounts)\n",
    "\n",
    "fraction_same_halo = total_same_halo_bincounts / total_bincounts\n",
    "#print(fraction_same_halo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for galaxy pairs\n",
    "plt.figure()\n",
    "for i in range(len(z_bins)):\n",
    "    if i==0:\n",
    "        label = \"< {0}\".format(z_bins[i])\n",
    "    else:\n",
    "        label = \"{0} - {1}\".format(z_bins[i-1], z_bins[i])\n",
    "    plt.plot(bins, total_bincounts[i], label=label)\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Angular Separation (arcsec)')\n",
    "plt.ylabel('Count of Galaxies Pairs')\n",
    "plt.title(\"Galaxy Pair Counts (by ang separation and z)\")\n",
    "plt.draw()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(z_bins)):\n",
    "    if i==0:\n",
    "        label = \"< {0}\".format(z_bins[i])\n",
    "    else:\n",
    "        label = \"{0} - {1}\".format(z_bins[i-1], z_bins[i])\n",
    "    plt.plot(bins, fraction_same_halo[i], label=label)\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Angular Separation (arcsec)')\n",
    "plt.ylabel('Fraction Pair in Same Halo')\n",
    "plt.ylim(-0.01, 1.0)\n",
    "plt.title(\"Fraction Pair in Same Halo (by ang separation and z)\")\n",
    "plt.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Group Founder Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(filename):\n",
    "\n",
    "    filename_props = str.replace(filename, \".out\", \"_galprops.dat\")\n",
    "\n",
    "    df = pd.read_csv(filename, delimiter=' ', names=('RA', 'Dec', 'z', 'L_gal', 'V_max', 'P_sat', 'M_halo', 'N_sat', 'L_tot', 'igrp', 'unknown'))\n",
    "    galprops = pd.read_csv(filename_props, delimiter=' ', names=('app_mag', 'g_r', 'galaxy_type', 'mxxl_halo_mass', 'fiber_assigned_0', 'assigned_halo_mass', 'z_obs', 'mxxl_halo_id', 'assigned_halo_id'), dtype={'mxxl_halo_id': np.int32, 'assigned_halo_id': np.int32})\n",
    "    all_data = pd.merge(df, galprops, left_index=True, right_index=True)\n",
    "\n",
    "    # Drop bad data, should have been cleaned up earlier though!\n",
    "    orig_count = len(all_data)\n",
    "    all_data = all_data[all_data.M_halo != 0]\n",
    "    new_count = len(all_data)\n",
    "    if (orig_count != new_count):\n",
    "        print(\"Dropped {0} bad galaxies\".format(orig_count - new_count))\n",
    "\n",
    "    all_data['is_sat'] = (all_data.index != all_data.igrp).astype(int)\n",
    "    all_data['is_sat_truth'] = np.logical_or(all_data.galaxy_type == 1, all_data.galaxy_type == 3).astype(int)\n",
    "    all_data['logLgal'] = np.log10(all_data.L_gal)\n",
    "\n",
    "    bins = np.logspace(np.log10(min(all_data.M_halo)), np.log10(max(all_data.M_halo)), 30)\n",
    "    labels = bins[0:len(bins)-1] # using bottom (or top?) value, not middle\n",
    "    all_data['Mh_bin'] = pd.cut(x = all_data['M_halo'], bins = bins, labels = labels, include_lowest = True)\n",
    "    \n",
    "    centrals = all_data[all_data.index == all_data.igrp]\n",
    "    #logmstar_means = centrals.groupby('Mh_bin').log_M_star.mean()\n",
    "    #logmstar_scatter = centrals.groupby('Mh_bin').log_M_star.std()\n",
    "    loglcen_means = centrals.groupby('Mh_bin').logLgal.mean()\n",
    "    loglcen_scatter = centrals.groupby('Mh_bin').logLgal.std()\n",
    "\n",
    "    # Compute f_sat(Lgal)\n",
    "    bins_Lgal = np.logspace(np.log10(min(all_data.L_gal)), np.log10(max(all_data.L_gal)), 30)\n",
    "    labels_Lgal = bins_Lgal[0:len(bins_Lgal)-1] # using bottom (or top?) value, not middle\n",
    "    all_data['Lgal_bin'] = pd.cut(x = all_data['L_gal'], bins = bins_Lgal, labels = labels_Lgal, include_lowest = True)\n",
    "    \n",
    "    f_sat = all_data.groupby('Lgal_bin').is_sat.mean()\n",
    "    Lgal_counts = all_data.groupby('Lgal_bin').RA.count()\n",
    "\n",
    "    dataset = types.SimpleNamespace()\n",
    "    dataset.filename = filename[filename.rfind('/')+1 : len(filename)-4]\n",
    "    dataset.all_data = all_data\n",
    "    dataset.bins = bins\n",
    "    dataset.labels = labels\n",
    "    dataset.centrals = centrals\n",
    "    #dataset.logmstar_means = logmstar_means\n",
    "    #dataset.logmstar_scatter = logmstar_scatter\n",
    "    dataset.loglcen_means = loglcen_means\n",
    "    dataset.loglcen_scatter = loglcen_scatter\n",
    "    dataset.bins_Lgal = bins_Lgal\n",
    "    dataset.labels_Lgal = labels_Lgal\n",
    "    dataset.f_sat = f_sat\n",
    "    dataset.Lgal_counts = Lgal_counts\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def plots(*frames):\n",
    "    \n",
    "    plt.figure()\n",
    "    for f in frames:\n",
    "        if ('20' not in f.name):\n",
    "            plt.errorbar(f.labels, f.loglcen_means, yerr=f.loglcen_scatter, label=f.name, color=f.color)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('$M_{halo}$')\n",
    "    plt.ylabel('$log(L_{cen})$')\n",
    "    plt.title(\"Central Luminosity vs. Halo Mass\")\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "\n",
    "    plt.figure()\n",
    "    for f in frames:\n",
    "        if ('20' in f.name):\n",
    "            plt.errorbar(f.labels, f.loglcen_means, yerr=f.loglcen_scatter, label=f.name, color=f.color)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('$M_{halo}$')\n",
    "    plt.ylabel('$log(L_{cen})$')\n",
    "    plt.title(\"Central Luminosity vs. Halo Mass\")\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "\n",
    "    plt.figure()    \n",
    "    for f in frames:\n",
    "        if ('20' not in f.name):\n",
    "            plt.plot(f.labels, f.loglcen_scatter, f.marker, color=f.color, label=f.name)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('$M_{halo}$')\n",
    "    plt.ylabel('$\\\\sigma(\\\\log(L_{cen})$')\n",
    "    plt.title(\"Central Luminosity Scatter vs. Halo Mass\")\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "\n",
    "    plt.figure()    \n",
    "    for f in frames:\n",
    "        if ('20' in f.name):\n",
    "            plt.plot(f.labels, f.loglcen_scatter, f.marker, color=f.color, label=f.name)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('$M_{halo}$')\n",
    "    plt.ylabel('$\\\\sigma(\\\\log(L_{cen})$')\n",
    "    plt.title(\"Central Luminosity Scatter vs. Halo Mass\")\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "\n",
    "    \"\"\"     \n",
    "    plt.figure()\n",
    "    for f in frames:\n",
    "        plt.scatter(f.centrals.M_halo, f.centrals.L_gal, alpha=0.002)\n",
    "    plt.loglog()\n",
    "    plt.xlabel('M_halo / h')\n",
    "    plt.ylabel('L_gal / $h^2$)')\n",
    "    plt.draw() \n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    for f in frames:\n",
    "        Nsat_means = f.all_data.groupby('Mh_bin').N_sat.mean()\n",
    "        plt.plot(f.labels, Nsat_means, f.marker, label=f.name, color=f.color)\n",
    "        #plt.hist(f.centrals.N_sat, np.arange(0,50,1), alpha=0.5)\n",
    "    plt.loglog()    \n",
    "    plt.ylabel(\"$<N_{sat}>$\")    \n",
    "    plt.xlabel('$M_{halo}$')\n",
    "    plt.title(\"Mean Number of Satellites by Halo Mass\")\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "\n",
    "    plt.figure()\n",
    "    for f in frames:\n",
    "        plt.plot(f.labels_Lgal, f.f_sat, f.marker, label=f.name, color=f.color)\n",
    "    truth_f_sat = frames[0].all_data.groupby('Lgal_bin').is_sat_truth.mean()\n",
    "    plt.plot(frames[0].labels_Lgal, truth_f_sat, 'k')\n",
    "    #centrals = frames[0].all_data['galaxy_type' == 0 or 'galaxy_type' == 2].groupby('Lgal_bin').count()\n",
    "    #sats = frames[0].all_data['galaxy_type' == 1 or 'galaxy_type' == 3].groupby('Lgal_bin').count()\n",
    "    #truth_f_sat = sats / (centrals + sats)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(\"$L_{gal}$\")\n",
    "    plt.ylabel(\"$f_{sat}$\")\n",
    "    plt.title(\"Satellite fraction vs Galaxy Luminosity\")\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "    \n",
    "    plt.figure()\n",
    "    for f in frames:\n",
    "        plt.plot(f.labels_Lgal, f.Lgal_counts, f.marker, label=f.name, color=f.color)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"$L_{gal}$\")\n",
    "    plt.ylabel(\"Count of Galaxies\")\n",
    "    plt.title(\"Galaxy Luminosity Counts\")\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "\n",
    "    print(\"TOTAL f_sat: \")\n",
    "    for f in frames:\n",
    "        print(f.filename, f.all_data['is_sat'].sum() / f.all_data['is_sat'].count())\n",
    "\n",
    "    print(\"MXXL Truth\", frames[0].all_data['is_sat_truth'].sum() / f.all_data['is_sat_truth'].count())\n",
    "\n",
    "    plt.figure()\n",
    "    for f in frames:\n",
    "        bin_ind = np.digitize(f.all_data.M_halo, f.bins)\n",
    "        bincounts = np.bincount(bin_ind)[0:len(f.bins)]\n",
    "        plt.plot(f.bins, bincounts / np.sum(bincounts), f.marker, label=f.name, color=f.color) \n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('$M_{halo}$')\n",
    "    plt.ylabel('Density of Halo Mass')\n",
    "    plt.title(\"Fiber Loss on Group Finder Halo Masses\")\n",
    "    plt.legend()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vir_radius(halo_mass):\n",
    "    # TODO redshift?\n",
    "    # TODO concentration?\n",
    "    m = models.NFW(mass=halo_mass, concentration=5.0, massfactor='200m') # 200m according to https://arxiv.org/pdf/1701.06581.pdf\n",
    "    return m.r_virial.to(u.kpc).value\n",
    "\n",
    "def post_process(frame):\n",
    "    df: pd.DataFrame = frame.all_data\n",
    "    \n",
    "    # Calculate additional halo properties\n",
    "    masses = df.loc[:, 'mxxl_halo_mass'].to_numpy() * 1E10 * u.solMass\n",
    "    df.loc[:, 'mxxl_halo_vir_radius_guess'] = get_vir_radius(masses)\n",
    "\n",
    "    _cosmo = FlatLambdaCDM(H0=73, Om0=0.25, Ob0=0.045, Tcmb0=2.725, Neff=3.04) \n",
    "    # TODO comoving or proper?\n",
    "    as_per_kpc = _cosmo.arcsec_per_kpc_proper(df.loc[:, 'z'].to_numpy())\n",
    "    df.loc[:, 'mxxl_halo_vir_radius_guess_arcsec'] =  df.loc[:, 'mxxl_halo_vir_radius_guess'] * as_per_kpc.to(u.arcsec / u.kpc).value\n",
    "\n",
    "    # Luminosity distance to z_obs\n",
    "    df.loc[:, 'ldist_true'] = z_to_ldist(df.z_obs.to_numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = process(ROOT_FOLDER + \"mxxl_3pass_all.out\")\n",
    "all.name = \"All\"\n",
    "all.color = get_color(0)\n",
    "all.marker = '-'\n",
    "#post_process(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all20 = process(ROOT_FOLDER + \"mxxl_3pass_all20.out\")\n",
    "all20.name = \"All <20\"\n",
    "all20.color = get_color(0)\n",
    "all20.marker = '--'\n",
    "post_process(all20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiberonly = process(ROOT_FOLDER + \"mxxl_3pass_fiberonly.out\")\n",
    "fiberonly.name = \"Fiber Assigned Only\"\n",
    "fiberonly.color = get_color(1)\n",
    "fiberonly.marker = '-'\n",
    "#post_process(fiberonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiberonly20 = process(ROOT_FOLDER + \"mxxl_3pass_fiberonly20.out\")\n",
    "fiberonly20.name = \"Fiber Assigned Only <20\"\n",
    "fiberonly20.color = get_color(1)\n",
    "fiberonly20.marker = '--'\n",
    "post_process(fiberonly20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_kd = process(ROOT_FOLDER + \"mxxl_3pass_nn_kd.out\")\n",
    "#post_process(nn_kd)\n",
    "nn_kd.name = \"Nearest Neighbor\"\n",
    "nn_kd.color = get_color(2)\n",
    "nn_kd.marker = '-'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_kd20 = process(ROOT_FOLDER + \"mxxl_3pass_nn_kd20.out\")\n",
    "post_process(nn_kd20)\n",
    "nn_kd20.name = \"Nearest Neighbor <20\"\n",
    "nn_kd20.color = get_color(2)\n",
    "nn_kd20.marker = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_1 = process(ROOT_FOLDER + \"mxxl_3pass_fancy_1.out\")\n",
    "post_process(fancy_1)\n",
    "fancy_1.name = \"Fancy v1\"\n",
    "fancy_1.color = get_color(3)\n",
    "fancy_1.marker = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_6 = process(ROOT_FOLDER + \"mxxl_3pass_fancy_6.out\")\n",
    "post_process(fancy_6)\n",
    "fancy_6.name = \"Fancy v6\"\n",
    "fancy_6.color = get_color(4)\n",
    "fancy_6.marker = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out\n",
    "#def save_processed_data(frame):\n",
    "#    frame.all_data.to_feather(ROOT_FOLDER + frame.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots(all, fiberonly, nn_kd, all20, fiberonly20, nn_kd20)\n",
    "plots(all, fiberonly, nn_kd, fancy_1, fancy_6)\n",
    "# BLUE: ALL     ORANGE: FIBER ASSIGNED ONLY     GREEN: NEAREST NEIGHBOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plots, the NN ones have some galaxies at higher $L_{gal}$ than the 'all' sample. This is because some of the assigned redshifts imply a larger luminosity than any galaxy seen in MXXL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What effect does Fiber Assignment have on group finder properties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Halo Masses (in group finder abundance matching)\n",
    "all_to_use = all\n",
    "fiberonly_to_use = fiberonly\n",
    "\n",
    "all_centrals = all_to_use.all_data[all_to_use.all_data.index == all_to_use.all_data.igrp]\n",
    "#loglcen_means = centrals.groupby('Mh_bin').logLgal.mean()\n",
    "angdist_bin_ind = np.digitize(all_centrals.M_halo, all_to_use.bins)\n",
    "all_bincounts = np.bincount(angdist_bin_ind)[0:len(all_to_use.bins)]\n",
    "all_density = all_bincounts / np.sum(all_bincounts)\n",
    "\n",
    "\n",
    "fo_centrals = fiberonly_to_use.all_data[fiberonly_to_use.all_data.index == fiberonly_to_use.all_data.igrp]\n",
    "#loglcen_means = centrals.groupby('Mh_bin').logLgal.mean()\n",
    "angdist_bin_ind = np.digitize(fo_centrals.M_halo, all.bins)\n",
    "fo_bincounts = np.bincount(angdist_bin_ind)[0:len(all.bins)]\n",
    "fo_density = fo_bincounts / np.sum(fo_bincounts)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_to_use.bins, np.log10(fo_density / all_density)) \n",
    "plt.xscale('log')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.xlabel('$M_{halo}$')\n",
    "plt.ylabel('Normalized log(Fiberonly / All)')\n",
    "plt.title(\"Effects of Fiber Loss on Group Finder Halo Masses\")\n",
    "plt.draw()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_to_use.bins, all_density, label=\"All Galaxies\") \n",
    "plt.plot(all_to_use.bins, fo_density, label=\"Fiber-Assigned Only\") \n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$M_{halo}$')\n",
    "plt.ylabel('Density of Galaxies')\n",
    "plt.title(\"Effects of Fiber Loss on Group Finder Halo Masses\")\n",
    "plt.legend()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up the centrals from all in fiberonly\n",
    "catalog = coord.SkyCoord(ra=all_centrals.RA.to_numpy()*u.degree, dec=all_centrals.Dec.to_numpy()*u.degree, frame='icrs')\n",
    "to_match = coord.SkyCoord(ra=fo_centrals.RA.to_numpy()*u.degree, dec=fo_centrals.Dec.to_numpy()*u.degree, frame='icrs')\n",
    "idx, d2d, d3d = coord.match_coordinates_sky(to_match, catalog, nthneighbor=1, storekdtree='all_fo_matching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_match = np.isclose(d2d.to(u.arcsec).value, 0, rtol=0.0, atol=0.0001) \n",
    "# 0.0001 arcsec precision on matching doesn't hit floating point noise. You get same with 0.001\n",
    "print(\"What fraction of centrals in \\'fiberonly\\' are centrals in \\'all\\'?\", np.sum(perfect_match) / len(d2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare assigned implied abs mags to truth from MXXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_to_check = fancy_6\n",
    "\n",
    "not_assigned = np.invert(run_to_check.all_data.fiber_assigned_0.astype(bool))\n",
    "app_mags = run_to_check.all_data.app_mag[not_assigned].to_numpy()\n",
    "my_assigned_abs_mag = app_mag_to_abs_mag(app_mags, run_to_check.all_data.z[not_assigned].to_numpy())\n",
    "my_raw_abs_mag = app_mag_to_abs_mag(app_mags, run_to_check.all_data.z_obs[not_assigned].to_numpy())\n",
    "\n",
    "print(len(my_raw_abs_mag), len(my_assigned_abs_mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare absolute mags. Using my way of computing for both.\n",
    "x = plt.hist(my_raw_abs_mag, label=\"Truth\", bins=50, alpha=0.5)\n",
    "y = plt.hist(my_assigned_abs_mag, label=f\"{run_to_check.name} Assigned\", bins=50, alpha=0.5)\n",
    "plt.xlabel(\"Absolute Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yscale('log')\n",
    "plt.title(\"Compare Lost Galaxies Abs Mags\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Purity and Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_purity_and_completeness(*sets):\n",
    "\n",
    "    for s in sets:\n",
    "        print(s.name)\n",
    "        data = s.all_data\n",
    "\n",
    "        assigned_sats = data[data.is_sat == True]\n",
    "        print(f\"Purity of sats: {np.sum(assigned_sats.is_sat_truth) / len(assigned_sats.index):.3f}\")\n",
    "\n",
    "        true_sats = data[data.is_sat_truth == True]\n",
    "        print(f\"Completeness of sats: {np.sum(true_sats.is_sat) / len(true_sats.index):.3f}\")\n",
    "\n",
    "\n",
    "test_purity_and_completeness(all, fiberonly, nn_kd, fancy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find fraction of time the NN is in the same halo, similar z, etc\n",
    "\n",
    "There is another version of this directly on the MXXL data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resulting_halo_analysis(*sets):\n",
    "\n",
    "    for data in sets:\n",
    "\n",
    "        print(data.name)\n",
    "\n",
    "        #same_halo_mass = np.isclose(data.all_data['assigned_halo_mass'], data.all_data['mxxl_halo_mass'], atol=0.0, rtol=1e-03)\n",
    "        #same_mxxl_halo = data.all_data['assigned_halo_mass']\n",
    "        #data.all_data['same_mxxl_halo'] = same_mxxl_halo\n",
    "\n",
    "        lost_galaxies = data.all_data[data.all_data.fiber_assigned_0 == 0]\n",
    "        print(len(lost_galaxies), \"lost galaxies\")\n",
    "\n",
    "        # TODO understand this MXXL quirk\n",
    "        lost_galaxies = lost_galaxies[lost_galaxies['assigned_halo_id'] != 0]\n",
    "        print(len(lost_galaxies), \"lost galaxies after removing ones with no MXXL halo ID (no idea why)\")\n",
    "\n",
    "        lost_galaxies_same_halo = np.equal(lost_galaxies['assigned_halo_id'], lost_galaxies['mxxl_halo_id'])\n",
    "        print(\"Fraction of time NN-assigned halo ID is the same as the galaxy's actual halo ID: {0:.3f}\".format(np.sum(lost_galaxies_same_halo) / len(lost_galaxies_same_halo)))\n",
    "        \n",
    "        lost_galaxies_same_halo_mass = np.isclose(lost_galaxies['assigned_halo_mass'], lost_galaxies['mxxl_halo_mass'], atol=0.0, rtol=1e-03)\n",
    "        print(\"Fraction of time NN-assigned halo mass is \\'the same\\' as the galaxy's actual halo mass: {0:.3f}\".format(np.sum(lost_galaxies_same_halo_mass) / len(lost_galaxies_same_halo_mass)))\n",
    "      \n",
    "        z_thresh=0.01\n",
    "        lost_galaxies_similar_z = np.isclose(lost_galaxies['z'], lost_galaxies['z_obs'], atol=z_thresh, rtol=0.0)         \n",
    "        print(\"Fraction of time NN-assigned z is the target z +/- {0:.3f}:\".format(z_thresh), np.sum(lost_galaxies_similar_z) / len(lost_galaxies_similar_z))\n",
    "\n",
    "        z_thresh=0.005\n",
    "        lost_galaxies_similar_z = np.isclose(lost_galaxies['z'], lost_galaxies['z_obs'], atol=z_thresh, rtol=0.0)         \n",
    "        print(\"Fraction of time NN-assigned z is the target z +/- {0:.3f}:\".format(z_thresh), np.sum(lost_galaxies_similar_z) / len(lost_galaxies_similar_z))\n",
    "\n",
    "        z_thresh=0.003\n",
    "        lost_galaxies_similar_z = np.isclose(lost_galaxies['z'], lost_galaxies['z_obs'], atol=z_thresh, rtol=0.0)         \n",
    "        print(\"Fraction of time NN-assigned z is the target z +/- {0:.3f}:\".format(z_thresh), np.sum(lost_galaxies_similar_z) / len(lost_galaxies_similar_z))\n",
    "\n",
    "        z_thresh=0.001\n",
    "        lost_galaxies_similar_z = np.isclose(lost_galaxies['z'], lost_galaxies['z_obs'], atol=z_thresh, rtol=0.0)        \n",
    "        print(\"Fraction of time NN-assigned z is the target z +/- {0:.3f}:\".format(z_thresh), np.sum(lost_galaxies_similar_z) / len(lost_galaxies_similar_z))\n",
    "        \n",
    "        # TODO as a function of reshift. But we essentially already have this from the direct MXXL data plots\n",
    "\n",
    "        #z_bins = np.linspace(min(data.all_data.z), max(data.all_data.z), 20)\n",
    "        #z_labels = z_bins[0:len(z_bins)-1] \n",
    "        #data.all_data['z_bin'] = pd.cut(x = data.all_data['z'], bins = z_bins, labels = z_labels, include_lowest = True)\n",
    "\n",
    "        #groupby_z = lost_galaxies.groupby('z_bin')['same_halo_mass'].sum() / lost_galaxies.groupby('z_bin')['same_halo_mass'].count()\n",
    "\n",
    "        #plt.plot(z_labels, groupby_z)\n",
    "        #plt.xlabel('$z_{eff}$ (effective/assigned redshift)')\n",
    "        #plt.ylabel('Fraction Assigned Halo = True Host Halo')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_halo_analysis(fancy_1, nn_kd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxy Neighborhood Examiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fancy_1.all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_galaxies = data.loc[data['fiber_assigned_0'] == 0]\n",
    "#lost_galaxies_2 = nn.all_data.loc[nn.all_data['fiber_assigned_0'] == 0]\n",
    "obs_galaxies = data.loc[data['fiber_assigned_0'] == 1]\n",
    "#obs_galaxies_2 = nn.all_data.loc[nn.all_data['fiber_assigned_0'] == 1]\n",
    "print(\"Lost galaxies: \", len(lost_galaxies), \"Observed Galaxies: \", len(obs_galaxies))\n",
    "\n",
    "# TODO could use angular size / redshift relation as part of this :-)\n",
    "def getsize(z):\n",
    "    if z < 0.05:\n",
    "        return 300\n",
    "    elif z < 0.1:\n",
    "        return 200\n",
    "    elif z < 0.2:\n",
    "        return 120\n",
    "    elif z < 0.2:\n",
    "        return 75\n",
    "    elif z < 0.3:\n",
    "        return 45\n",
    "    elif z < 0.4:\n",
    "        return 25\n",
    "    elif z < 0.5:\n",
    "        return 15\n",
    "    elif z < 0.6:\n",
    "        return 8\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "nearby_angle = coord.Angle('5m')\n",
    "\n",
    "def neighbor_exam(target):\n",
    "    z_eff = target.z\n",
    "    target_dist_true = z_to_ldist(target.z_obs)\n",
    "\n",
    "    ra_max = (coord.Angle(target.RA*u.degree) + nearby_angle).value\n",
    "    ra_min = (coord.Angle(target.RA*u.degree) - nearby_angle).value\n",
    "    dec_max = (coord.Angle(target.Dec*u.degree) + nearby_angle).value\n",
    "    dec_min = (coord.Angle(target.Dec*u.degree) - nearby_angle).value\n",
    "\n",
    "    nearby = obs_galaxies.query('RA < @ra_max and RA > @ra_min and Dec < @dec_max and Dec > @dec_min')\n",
    "\n",
    "    close_neighbors = 0\n",
    "    if len(nearby) > 0:\n",
    "        close_neighbors = np.isclose(nearby.ldist_true.to_numpy(), target_dist_true, rtol=0.0, atol=20)\n",
    "\n",
    "    return (np.sum(close_neighbors), len(nearby), np.sum(close_neighbors)/len(nearby))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = coord.SkyCoord(ra=data.RA.to_numpy()*u.degree, dec=data.Dec.to_numpy()*u.degree, frame='icrs')\n",
    "\n",
    "# This is too slow when called 1 at a time, not using. \n",
    "# TODO Could be faster when batched for the whole sample?\n",
    "def neighbors_within(max_angle: coord.Angle, to_match: coord.Angle, catalog: np.ndarray, treekey: str):\n",
    "\n",
    "    angular_distance = coord.Angle(0*u.arcsec)\n",
    "    nth = 1 # cap at 100 for now, TODO remove when safe\n",
    "    neighbor_ind = []\n",
    "    neighbor_dist = []\n",
    "\n",
    "    while angular_distance < max_angle and nth < 100:\n",
    "        idx, d2d, d3d = coord.match_coordinates_sky(to_match, catalog, nthneighbor=nth, storekdtree=treekey)\n",
    "        angular_distance = d2d\n",
    "        nth = nth + 1\n",
    "        neighbor_ind.append(idx)\n",
    "        neighbor_dist.append(angular_distance)\n",
    "\n",
    "    return neighbor_ind, neighbor_dist\n",
    "\n",
    "def examine_around(target):\n",
    "\n",
    "    target_observed = target.fiber_assigned_0\n",
    "    #target = data.loc[index]\n",
    "\n",
    "    target_pos = coord.SkyCoord(ra=target.RA*u.degree, dec=target.Dec*u.degree, frame='icrs')\n",
    "\n",
    "    z_eff = target.z\n",
    "    #target_dist_true = z_to_ldist(target.z_obs)\n",
    "\n",
    "    ra_max = (coord.Angle(target.RA*u.degree) + nearby_angle).value\n",
    "    ra_min = (coord.Angle(target.RA*u.degree) - nearby_angle).value\n",
    "    dec_max = (coord.Angle(target.Dec*u.degree) + nearby_angle).value\n",
    "    dec_min = (coord.Angle(target.Dec*u.degree) - nearby_angle).value\n",
    "\n",
    "    # TODO replace with a non-angular search so all redshifts are treated equally\n",
    "    #indexes, angular_distances = neighbors_within(nearby_angle, target_pos, catalog, 'treekey_nnkd')\n",
    "    #nearby = data.iloc[indexes]\n",
    "    nearby = data.query('RA < @ra_max and RA > @ra_min and Dec < @dec_max and Dec > @dec_min')\n",
    "    nearby = nearby.drop(target.name) # drop the target itself from this df\n",
    "\n",
    "    nearby_obs = nearby.loc[nearby['fiber_assigned_0'] == 1]\n",
    "    nearby_unobs = nearby.loc[nearby['fiber_assigned_0'] == 0]\n",
    "\n",
    "    z_match = nearby_obs.query('z == @z_eff')\n",
    "    #assert len(z_match) == 1, len(z_match) # TODO need a better way to verify which row is the one that we assigned the z from\n",
    "    if len(z_match) > 0:\n",
    "        z_match = z_match.iloc[0]\n",
    "    #nearby_obs = nearby_obs.drop(z_match.name)\n",
    "\n",
    "    good_obs_z_filter = list(map(lambda a: close_enough(target.z_obs, a), nearby_obs.z))\n",
    "    nearby_obs_good_z = nearby_obs.loc[good_obs_z_filter]\n",
    "    nearby_obs_good_z_dim = nearby_obs_good_z.loc[nearby_obs_good_z.app_mag > 19.5]\n",
    "    nearby_obs_good_z = nearby_obs_good_z.loc[np.invert(nearby_obs_good_z.app_mag > 19.5)]\n",
    "\n",
    "    if len(good_obs_z_filter) > 0:\n",
    "        nearby_obs_other = nearby_obs.loc[np.invert(good_obs_z_filter)]\n",
    "    else:\n",
    "        nearby_obs_other = nearby_obs\n",
    "    nearby_obs_other_dim = nearby_obs_other.loc[nearby_obs_other.app_mag > 19.5]\n",
    "    nearby_obs_other = nearby_obs_other.loc[np.invert(nearby_obs_other.app_mag > 19.5)]\n",
    "\n",
    "    good_unobs_z_filter = list(map(lambda a: close_enough(target.z_obs, a), nearby_unobs.z))\n",
    "\n",
    "    nearby_unobs_good_z = nearby_unobs.loc[good_unobs_z_filter]\n",
    "    if good_unobs_z_filter:\n",
    "        nearby_unobs_other = nearby_unobs.loc[np.invert(good_unobs_z_filter)]\n",
    "        nearby_unobs_other_dim = nearby_unobs_other.loc[nearby_unobs_other.app_mag > 19.5]\n",
    "        nearby_unobs_other = nearby_unobs_other.loc[np.invert(nearby_unobs_other.app_mag > 19.5)]\n",
    "    else:\n",
    "        nearby_unobs_other = nearby_unobs_good_z # empty df\n",
    "        nearby_unobs_other_dim = nearby_unobs_good_z\n",
    "\n",
    "    nearby_unobs_good_z_dim = nearby_unobs_good_z.loc[nearby_unobs_good_z.app_mag > 19.5]\n",
    "    nearby_unobs_good_z = nearby_unobs_good_z.loc[np.invert(nearby_unobs_good_z.app_mag > 19.5)]\n",
    "\n",
    "    if target_observed:\n",
    "        title = \"Observed Galaxy {0}: z_true={1:.3f}, z_NN={2:.3f}\".format(target.name, target.z_obs, target.z)\n",
    "    else:\n",
    "        title = \"Lost Galaxy {0}: z_true={1:.3f}, z_NN={2:.3f}\".format(target.name, target.z_obs, target.z)\n",
    "\n",
    "    if len(nearby) > 1:\n",
    "\n",
    "        fig,ax = plt.subplots(1)\n",
    "        fig.set_size_inches(10,10)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        # Add virial radii or MXXL Halos to the observed galaxies\n",
    "        for k in range(len(nearby_obs)):\n",
    "            current = nearby_obs.iloc[k]\n",
    "            radius = current.mxxl_halo_vir_radius_guess_arcsec / 3600 # arcsec to degrees, like the plot\n",
    "            circ = Circle((current.RA,current.Dec), radius, color=get_color(0), alpha=0.10)\n",
    "            ax.add_patch(circ)\n",
    "\n",
    "        textsize = 9\n",
    "        dimalpha = 0.4\n",
    "\n",
    "        plt.scatter(nearby_obs_other.RA, nearby_obs_other.Dec, s=list(map(getsize, nearby_obs_other.z)), color=get_color(0), label=\"Obs ({0})\".format(len(nearby_obs_other)))\n",
    "        if len(nearby_obs_other_dim) > 0:\n",
    "            plt.scatter(nearby_obs_other_dim.RA, nearby_obs_other_dim.Dec, s=list(map(getsize, nearby_obs_other_dim.z)), color=get_color(2), alpha=dimalpha, label=\"Obs dim ({0})\".format(len(nearby_obs_other_dim)))\n",
    "        \n",
    "        plt.scatter(nearby_obs_good_z.RA, nearby_obs_good_z.Dec, s=list(map(getsize, nearby_obs_good_z.z)), color=get_color(2), label=\"Obs good z ({0})\".format(len(nearby_obs_good_z)))\n",
    "        if len(nearby_obs_good_z_dim) > 0:\n",
    "            plt.scatter(nearby_obs_good_z_dim.RA, nearby_obs_good_z_dim.Dec, s=list(map(getsize, nearby_obs_good_z_dim.z)), color=get_color(0), alpha=dimalpha, label=\"Obs good z dim ({0})\".format(len(nearby_obs_good_z_dim)))\n",
    "\n",
    "        plt.scatter(nearby_unobs_other.RA, nearby_unobs_other.Dec, marker='x', s=list(map(getsize, nearby_unobs_other.z)), color=get_color(0), label=\"Unobs ({0})\".format(len(nearby_unobs_other)))\n",
    "        if len(nearby_unobs_other_dim) > 0:\n",
    "            plt.scatter(nearby_unobs_other_dim.RA, nearby_unobs_other_dim.Dec, marker='x', s=list(map(getsize, nearby_unobs_other_dim.z)), color=get_color(0), alpha=dimalpha, label=\"Unobs dim ({0})\".format(len(nearby_unobs_other_dim)))\n",
    "        \n",
    "        plt.scatter(nearby_unobs_good_z.RA, nearby_unobs_good_z.Dec, marker='x', s=list(map(getsize, nearby_unobs_good_z.z)), color=get_color(2), label=\"Unobs good z ({0})\".format(len(nearby_unobs_good_z)))\n",
    "        if len(nearby_unobs_good_z_dim) > 0:\n",
    "            plt.scatter(nearby_unobs_good_z_dim.RA, nearby_unobs_good_z_dim.Dec, marker='x', s=list(map(getsize, nearby_unobs_good_z_dim.z)), color=get_color(2), alpha=dimalpha, label=\"Unobs good z dim ({0})\".format(len(nearby_unobs_good_z_dim)))\n",
    "        \n",
    "        # redshift data labels\n",
    "        for k in range(len(nearby_obs)):\n",
    "            plt.text(nearby_obs.iloc[k].RA, nearby_obs.iloc[k].Dec, \"{0:.3f}\".format(nearby_obs.iloc[k].z), size=textsize)\n",
    "        for k in range(len(nearby_unobs)):\n",
    "            plt.text(nearby_unobs.iloc[k].RA, nearby_unobs.iloc[k].Dec, \"{0:.3f}\".format(nearby_unobs.iloc[k].z), size=textsize)\n",
    "\n",
    "        # Circle assigned one\n",
    "        if len(z_match) > 0:\n",
    "            plt.scatter(z_match.RA, z_match.Dec, color=get_color(3), facecolors='none', s=getsize(z_match.z)*2, label=\"Assigned\")\n",
    "            plt.text(z_match.RA, z_match.Dec, \"{0:.3f}\".format(z_match.z), size=textsize)\n",
    "\n",
    "        # Target galaxy\n",
    "        if target_observed:\n",
    "            plt.scatter(target.RA, target.Dec, s=getsize(target.z_obs), color=get_color(1), label=\"Target\")\n",
    "        else:\n",
    "            plt.scatter(target.RA, target.Dec, s=getsize(target.z_obs), marker='X', color=get_color(1), label=\"Target\")  \n",
    "        plt.text(target.RA, target.Dec, \"{0:.3f}\".format(target.z_obs), size=textsize)\n",
    "\n",
    "        plt.xlim(ra_min, ra_max)\n",
    "        plt.ylim(dec_min, dec_max)\n",
    "        plt.xlabel('RA')\n",
    "        plt.xlabel('Dec')\n",
    "        plt.legend()\n",
    "        plt.title(title)\n",
    "        plt.draw()\n",
    "    \n",
    "    else:\n",
    "        print(\"Skipping empty plot for {0}\".format(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTS_TO_MAKE = 10\n",
    "GALAXY_POOL = lost_galaxies\n",
    "\n",
    "#START_INDEX = 777\n",
    "#for i in range(START_INDEX, START_INDEX + PLOTS_TO_MAKE):\n",
    "#    index = lost_galaxies.index[i]\n",
    "#    examine_around(index)\n",
    "print(\"Number of galaxies to choose from: \", len(GALAXY_POOL))\n",
    "indexes = np.random.randint(0, len(GALAXY_POOL)-1, size=PLOTS_TO_MAKE)\n",
    "for i in indexes:\n",
    "    target = GALAXY_POOL.iloc[i]\n",
    "    examine_around(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea: analyze entire neighborhood and look for groups of similar z galaxies, choose a z from the biggest group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 300\n",
    "close = np.empty(MAX)\n",
    "total = np.empty(MAX)\n",
    "frac = np.empty(MAX)\n",
    "for i in range(0,MAX):\n",
    "    target = lost_galaxies.iloc[i]\n",
    "    close[i], total[i], frac[i] = neighbor_exam(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_finished = 81408\n",
    "finished_close = close[0:max_finished]\n",
    "finished_total = total[0:max_finished]\n",
    "with open(ROOT_FOLDER + 'mxxl_lostgal_neighborhood_close.npy', 'wb') as f:\n",
    "    np.save(f, finished_close)\n",
    "with open(ROOT_FOLDER + 'mxxl_lostgal_neighborhood_total.npy', 'wb') as f:\n",
    "    np.save(f, finished_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROOT_FOLDER + 'mxxl_lostgal_neighborhood_close.npy', 'rb') as f:\n",
    "    close = np.load(f)\n",
    "\n",
    "with open(ROOT_FOLDER + 'mxxl_lostgal_neighborhood_total.npy', 'rb') as f:\n",
    "    total = np.load(f)\n",
    "\n",
    "frac = close / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,30,31)\n",
    "trash = plt.hist(close, bins=bins)\n",
    "plt.title(\"Lost Galaxies Neighbors at ~Correct z\")\n",
    "plt.xlabel(\"Count of Similar z Neighbors\")\n",
    "plt.ylabel(\"Count of Lost Galaxies\")\n",
    "print(\"Hopeless Fraction: \", np.sum(close==0) / len(close))\n",
    "print(\"Essentially Hopeless Fraction: \", (np.sum(close==0) + np.sum(close==1)) / len(close))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viable = close > 1\n",
    "frac[viable]\n",
    "trash=plt.hist(frac[viable], bins=30)\n",
    "plt.title(\"Viable Lost Galaxies: Correct z Neighbor Fraction\")\n",
    "plt.xlabel(\"Fraction with Similar z\")\n",
    "plt.ylabel(\"Count of Viable Lost Galaxies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
