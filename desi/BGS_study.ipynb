{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as c\n",
    "from astropy.wcs import WCS\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from pyutils import *\n",
    "import astropy.io.fits as fits\n",
    "import healpy as hp\n",
    "from astropy.table import Table,join\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"../bin/\"\n",
    "BGS_PREVIOUS_FOLDER = \"../bin/BGS v1.0/\"\n",
    "OLD_FILE = ROOT_FOLDER + \"BGS_BRIGHT_full.dat.fits\"\n",
    "FILE = ROOT_FOLDER + \"BGS_ANY_full.dat.fits\"\n",
    "RAND_FILE = ROOT_FOLDER + \"BGS_BRIGHT_0_full.ran.fits\"\n",
    "PROB_OBS_FILE = ROOT_FOLDER + \"mainbw-bright-allTiles_v1.fits\"\n",
    "FASTSPEC_FILE = ROOT_FOLDER + \"fastspec-iron-main-bright.fits\"\n",
    "\n",
    "# TODO ensure this is right\n",
    "def get_app_mag(flux):\n",
    "    \"\"\"This converts nanomaggies into Pogson magnitudes\"\"\"\n",
    "    return 22.5 - 2.5*np.log10(flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGS_N = hp.read_map(ROOT_FOLDER + 'BGS_BRIGHT_mapprops_healpix_nested_nside256_N.fits')\n",
    "BGS_S = hp.read_map(ROOT_FOLDER + 'BGS_BRIGHT_mapprops_healpix_nested_nside256_S.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(\n",
    "    BGS_N,\n",
    "    coord=[\"G\", \"E\"],\n",
    "    title=\"Histogram equalized Ecliptic\",\n",
    "    unit=\"Galaxies\",\n",
    "    norm=\"hist\",\n",
    "    min=0,\n",
    "    max=1,\n",
    ")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(\n",
    "    BGS_S,\n",
    "    coord=[\"G\", \"E\"],\n",
    "    title=\"Histogram equalized Ecliptic\",\n",
    "    unit=\"Galaxies\",\n",
    "    norm=\"hist\",\n",
    "    min=0,\n",
    "    max=1,\n",
    ")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table = Table.read(FILE, format='fits')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_table = Table.read(PROB_OBS_FILE, format='fits')\n",
    "j_table = join(u_table, p_table, keys=\"TARGETID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_table = Table.read(OLD_FILE, format='fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setxor1d(u_table.colnames, old_table.colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(u_table['TARGETID']))\n",
    "print(len(j_table['TARGETID']))\n",
    "print(len(p_table['TARGETID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(u_table['Z_not4clus'], bins=50)\n",
    "plt.title(\"Z_not4clus\")\n",
    "plt.yscale('log')\n",
    "print(np.min(u_table['Z_not4clus']), np.max(u_table['Z_not4clus']))\n",
    "print(u_table['Z_not4clus'].mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(u_table['ZWARN']))\n",
    "print(np.unique(u_table['ZWARN_MTL']))\n",
    "print(np.unique(u_table['SPECTYPE']))\n",
    "print(np.unique(u_table['NTILE']))\n",
    "print(np.unique(u_table['TARGET_STATE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table.add_index(['TARGETID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut to the galaxy data we actually need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = u_table\n",
    "\n",
    "APP_MAG_CUT = 19.5\n",
    "Z_MIN = 0.01\n",
    "Z_MAX = 0.8\n",
    "obj_type = table['SPECTYPE'].data.data\n",
    "dec = table['DEC']\n",
    "ra = table['RA']\n",
    "z_obs = table['Z_not4clus'].data.data\n",
    "target_id = table['TARGETID']\n",
    "flux_r = table['FLUX_R']\n",
    "flux_g = table['FLUX_G']\n",
    "app_mag = get_app_mag(table['FLUX_R'])\n",
    "app_mag_g = get_app_mag(table['FLUX_G'])\n",
    "g_r_apparent = app_mag_g - app_mag\n",
    "sdss_g_r = table['ABSMAG_SDSS_G'] - table['ABSMAG_SDSS_R'] \n",
    "#p_obs = table['PROB_OBS'] \n",
    "unobserved = table['ZWARN'] == 999999\n",
    "deltachi2 = table['DELTACHI2'].data.data\n",
    "ntiles = table['NTILE']\n",
    "abs_mag_sdss = table['ABSMAG_SDSS_R']\n",
    "\n",
    "before_count = len(dec)\n",
    "print(before_count, \"objects in FITS file\")\n",
    "\n",
    "# Make filter array (True/False values)\n",
    "galaxy_filter = np.logical_or(obj_type == b'GALAXY', obj_type == b'')\n",
    "galaxy_observed_filter = obj_type == b'GALAXY'\n",
    "app_mag_filter = app_mag < APP_MAG_CUT\n",
    "redshift_filter = z_obs > Z_MIN\n",
    "redshift_hi_filter = z_obs < Z_MAX\n",
    "deltachi2_filter = deltachi2 > 40\n",
    "abs_mag_sdss_filter = abs_mag_sdss < 100\n",
    "\n",
    "keep = np.all([galaxy_observed_filter, app_mag_filter, redshift_filter, redshift_hi_filter, deltachi2_filter, abs_mag_sdss_filter], axis=0)\n",
    "keep_3 = np.all([keep, ntiles >= 3], axis=0)\n",
    "unobserved_3 = np.all([ntiles >= 3, unobserved], axis=0)\n",
    "treat_as_unobserved_3 = np.all([galaxy_observed_filter, app_mag_filter, ntiles >= 3, np.invert(deltachi2_filter)], axis=0)\n",
    "eff_unobserved_3 = np.logical_or(unobserved_3, treat_as_unobserved_3)\n",
    "\n",
    "print(f\"There are {len(table['DEC'][galaxy_filter])} galaxy targets in the sample,of which {len(table['DEC'][galaxy_observed_filter])} are observed. Of these, {len(table['DEC'][keep])} are in the bright (<{APP_MAG_CUT} mag) sample and pass our quality of z-fit checks.\")\n",
    "print(f\"Of those, only {len(table['DEC'][keep_3])} are in the 3-pass coverage area.\")\n",
    "print(f\"There are {len(table['DEC'][unobserved_3])} unobserved galaxies in the 3-pass coverage area.\")\n",
    "print(f\"There are also {len(table['DEC'][treat_as_unobserved_3])} bad observed galaxies in the 3pass regionthat we will treat as unobserved, making a combined effective total of {len(table['DEC'][eff_unobserved_3])} 3pass unobserved galaxies.\")\n",
    "\n",
    "obj_type = obj_type[keep_3]\n",
    "dec = dec[keep_3]\n",
    "ra = ra[keep_3]\n",
    "z_obs = z_obs[keep_3]\n",
    "target_id = target_id[keep_3]\n",
    "flux_r = flux_r[keep_3]\n",
    "app_mag = app_mag[keep_3]\n",
    "app_mag_g = app_mag_g[keep_3]\n",
    "g_r_apparent = g_r_apparent[keep_3]\n",
    "#p_obs = p_obs[keep_3]\n",
    "unobserved = unobserved[keep_3]\n",
    "deltachi2 = deltachi2[keep_3]\n",
    "ntiles = ntiles[keep_3]\n",
    "abs_mag_sdss = abs_mag_sdss[keep_3]\n",
    "sdss_g_r = sdss_g_r[keep_3]\n",
    "\n",
    "after_count = len(dec)\n",
    "\n",
    "print(f\"\\nAfter all filters we have {after_count} of the original {before_count} rows.\")\n",
    "\n",
    "#print(\"Frac area after all filters\", estimate_frac_area(ra, dec))\n",
    "#fig=make_map(ra, dec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson from this analysis: the BGS data, workign with my 0.1^G-R with GAMA k-corrections, does not distribute a per logLgal bin G-R; the global 0.76 split seems to work for all bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = app_mag_to_abs_mag(app_mag_g, z_obs)\n",
    "R = app_mag_to_abs_mag(app_mag, z_obs)\n",
    "\n",
    "G_R = G - R\n",
    "\n",
    "Gk = k_correct(G, z_obs, g_r_apparent, band='g')\n",
    "Rk = k_correct(R, z_obs, g_r_apparent, band='r')\n",
    "\n",
    "G_R_k = Gk - Rk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of g-r computed a few ways\n",
    "junk=plt.hist(g_r_apparent, bins=300, alpha=0.5, label=\"g-r\")\n",
    "junk=plt.hist(sdss_g_r, bins=300, alpha=0.5, label='From LSS Pipeline')\n",
    "junk=plt.hist(G_R, bins=300, alpha=0.5, label=\"G-R\")\n",
    "junk=plt.hist(G_R_k, bins=300, alpha=0.5, label=\"0.1^(G-R) GAMA-style\")\n",
    "plt.legend()\n",
    "plt.xlim(0.0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can see global GLOBAL_RED_COLOR_CUT=0.76 here\n",
    "junk=plt.hist(G_R_k, bins=300, alpha=0.5, label=\"0.1^(G-R) GAMA-style\")\n",
    "plt.legend()\n",
    "plt.xlim(0.5, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyutils import *\n",
    "print(BGS_LOGLGAL_BINS)\n",
    "print(BINWISE_RED_COLOR_CUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_quiescent_BGS_gmr([5.8, 9.0, 14.5], [0.5, 0.9, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logLgal bins\n",
    "log_L_gal = abs_mag_r_to_log_solar_L(Rk) \n",
    "logLgal_bin_idx = np.digitize(log_L_gal, BGS_LOGLGAL_BINS)\n",
    "# 0 is less than the lowest, len(BGS_LOGLGAL_BINS) is greater than the highest entry in BGS_LOGLGAL_BINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(log_L_gal))\n",
    "print(np.max(log_L_gal))\n",
    "print(np.min(logLgal_bin_idx))\n",
    "print(np.max(logLgal_bin_idx))\n",
    "plt.hist(log_L_gal, bins=BGS_LOGLGAL_BINS, align='mid')\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot of G_R_k in each logLgal bin\n",
    "for i in range(0, len(BGS_LOGLGAL_BINS)+1):\n",
    "    galaxy_idx_for_this_bin = logLgal_bin_idx == i\n",
    "\n",
    "    plt.figure(dpi=120, figsize=(10, 6))\n",
    "    junk=plt.hist(G_R_k[galaxy_idx_for_this_bin], bins=np.arange(0,1.3,0.02), label=f\"0.1^(G-R) Bin {i}\", align='mid')\n",
    "    plt.legend()\n",
    "    plt.xlim(0.4, 1.2)\n",
    "    plt.xticks(np.arange(0.4, 1.2, 0.04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag1 = abs_mag_sdss\n",
    "mag2 = app_mag_to_abs_mag(get_app_mag(app_mag), z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mag1), len(mag2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Absolute Magnitudes\n",
    "bins = np.linspace(-25, -10, 100)\n",
    "my_counts, my_bins, my_p = plt.hist(mag2, label=\"my abs_mag\", bins=bins, alpha=0.5)\n",
    "alex_counts, alex_bins, alex_p = plt.hist(mag1, label=\"ABSMAG_SDSS_R\", bins=bins, alpha=0.5)\n",
    "plt.xlabel(\"Absolute Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Compare Absolute Mags\")\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "print(f\"The peak is shifted from ABSMAG_SDSS_R {alex_bins[np.argmax(alex_counts)]:.1f} to my {my_bins[np.argmax(my_counts)]:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=make_map(ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=make_map(ra[5], dec[5], alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(obj_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32,8))\n",
    "plt.hist(u_table['TARGET_STATE'])\n",
    "plt.title('Target State')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(z_obs))\n",
    "print(np.max(z_obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randoms Analysis for Footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtable = Table.read(RAND_FILE, format='fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in rtable.colnames:\n",
    "    if u_table.colnames.__contains__(c):\n",
    "        print(f\"Column {c} is in both files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dec = rtable['DEC']\n",
    "r_ra = rtable['RA']\n",
    "r_ntiles = rtable['NTILE']\n",
    "\n",
    "RANDOMS_DENSITY = 2500 # per square degree\n",
    "\n",
    "onepass_footprint = len(r_dec) / RANDOMS_DENSITY # in degrees squared\n",
    "onepass_frac_area = onepass_footprint / DEGREES_ON_SPHERE\n",
    "\n",
    "three_pass_filter = r_ntiles >= 3 # 3pass coverage\n",
    "r_dec3 = r_dec[three_pass_filter]\n",
    "r_ra3 = r_ra[three_pass_filter]\n",
    "\n",
    "threepass_footprint = len(r_dec3) / RANDOMS_DENSITY # in degrees squared\n",
    "threepass_frac_area = threepass_footprint / DEGREES_ON_SPHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BGS Y1 1pass Footprint calculated from randoms is {onepass_footprint} square degrees or frac_area={onepass_frac_area}\")\n",
    "print(f\"BGS Y1 3pass Footprint calculated from randoms is {threepass_footprint} square degrees or frac_area={threepass_frac_area}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastspec File Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul = fits.open(FASTSPEC_FILE, memmap=True)\n",
    "hdul[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read only the TARGETID and DN4000 columns into memory (all rows)\n",
    "hdul[1].data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ian-conda311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
