{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as c\n",
    "from astropy.wcs import WCS\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from pyutils import *\n",
    "import astropy.io.fits as fits\n",
    "import healpy as hp\n",
    "from astropy.table import Table,join\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"../bin/\"\n",
    "BGS_PREVIOUS_FOLDER = \"../bin/BGS v1.0/\"\n",
    "OLD_FILE = ROOT_FOLDER + \"BGS_BRIGHT_full.dat.fits\"\n",
    "FILE = ROOT_FOLDER + \"BGS_ANY_full.dat.fits\"\n",
    "RAND_FILE = ROOT_FOLDER + \"BGS_BRIGHT_0_full.ran.fits\"\n",
    "\n",
    "PROB_OBS_FILE = ROOT_FOLDER + \"mainbw-bright-allTiles_v1.fits\"\n",
    "\n",
    "# TODO ensure this is right\n",
    "def get_app_mag(flux):\n",
    "    \"\"\"This converts nanomaggies into Pogson magnitudes\"\"\"\n",
    "    return 22.5 - 2.5*np.log10(flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGS_N = hp.read_map(ROOT_FOLDER + 'BGS_BRIGHT_mapprops_healpix_nested_nside256_N.fits')\n",
    "BGS_S = hp.read_map(ROOT_FOLDER + 'BGS_BRIGHT_mapprops_healpix_nested_nside256_S.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(\n",
    "    BGS_N,\n",
    "    coord=[\"G\", \"E\"],\n",
    "    title=\"Histogram equalized Ecliptic\",\n",
    "    unit=\"Galaxies\",\n",
    "    norm=\"hist\",\n",
    "    min=0,\n",
    "    max=1,\n",
    ")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(\n",
    "    BGS_S,\n",
    "    coord=[\"G\", \"E\"],\n",
    "    title=\"Histogram equalized Ecliptic\",\n",
    "    unit=\"Galaxies\",\n",
    "    norm=\"hist\",\n",
    "    min=0,\n",
    "    max=1,\n",
    ")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We need:\n",
    "\n",
    "   'app_mag' CALCULATE IT from FLUX_R\n",
    "\n",
    "   'dec' GOT IT\n",
    "\n",
    "   'g_r' GOT IT (but k-corr?)\n",
    "\n",
    "   'ra' GOT IT\n",
    "\n",
    "   'z_obs' GOT IT\n",
    "\n",
    "   If ZWARN say multi fits (4), consider it LOST. Use DELTACHI2 < 40 instead of ZWARN (higher bar for good fit) We can actually use that info later if available.\n",
    "\n",
    "3 pass info is in the NTILE column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table = Table.read(FILE, format='fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_table = Table.read(PROB_OBS_FILE, format='fits')\n",
    "j_table = join(u_table, p_table, keys=\"TARGETID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_table = Table.read(OLD_FILE, format='fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setxor1d(u_table.colnames, old_table.colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(u_table['TARGETID']))\n",
    "print(len(j_table['TARGETID']))\n",
    "print(len(p_table['TARGETID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(u_table['Z_not4clus'], bins=50)\n",
    "plt.title(\"Z_not4clus\")\n",
    "plt.yscale('log')\n",
    "print(np.min(u_table['Z_not4clus']), np.max(u_table['Z_not4clus']))\n",
    "print(u_table['Z_not4clus'].mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(u_table['ZWARN']))\n",
    "print(np.unique(u_table['ZWARN_MTL']))\n",
    "print(np.unique(u_table['SPECTYPE']))\n",
    "print(np.unique(u_table['NTILE']))\n",
    "print(np.unique(u_table['TARGET_STATE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table.add_index(['TARGETID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the galaxy data we actually need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = u_table\n",
    "\n",
    "APP_MAG_CUT = 22.0\n",
    "Z_MIN = 0.01\n",
    "Z_MAX = 0.8\n",
    "obj_type = table['SPECTYPE'].data.data\n",
    "dec = table['DEC']\n",
    "ra = table['RA']\n",
    "z_obs = table['Z_not4clus'].data.data\n",
    "target_id = table['TARGETID']\n",
    "flux_r = table['FLUX_R']\n",
    "flux_g = table['FLUX_G']\n",
    "app_mag = get_app_mag(table['FLUX_R'])\n",
    "app_mag_g = get_app_mag(table['FLUX_G'])\n",
    "#g_r = app_mag - app_mag_g\n",
    "sdss_g_r = table['ABSMAG_SDSS_G'] - table['ABSMAG_SDSS_R'] \n",
    "#p_obs = table['PROB_OBS'] \n",
    "unobserved = table['ZWARN'] == 999999\n",
    "deltachi2 = table['DELTACHI2'].data.data\n",
    "ntiles = table['NTILE']\n",
    "abs_mag_sdss = table['ABSMAG_SDSS_R']\n",
    "\n",
    "before_count = len(dec)\n",
    "print(before_count, \"objects in FITS file\")\n",
    "\n",
    "# Make filter array (True/False values)\n",
    "galaxy_filter = np.logical_or(obj_type == b'GALAXY', obj_type == b'')\n",
    "galaxy_observed_filter = obj_type == b'GALAXY'\n",
    "app_mag_filter = app_mag < APP_MAG_CUT\n",
    "redshift_filter = z_obs > Z_MIN\n",
    "redshift_hi_filter = z_obs < Z_MAX\n",
    "deltachi2_filter = deltachi2 > 40\n",
    "abs_mag_sdss_filter = abs_mag_sdss < 100\n",
    "\n",
    "keep = np.all([galaxy_observed_filter, app_mag_filter, redshift_filter, redshift_hi_filter, deltachi2_filter, abs_mag_sdss_filter], axis=0)\n",
    "keep_3 = np.all([keep, ntiles >= 3], axis=0)\n",
    "unobserved_3 = np.all([ntiles >= 3, unobserved], axis=0)\n",
    "treat_as_unobserved_3 = np.all([galaxy_observed_filter, app_mag_filter, ntiles >= 3, np.invert(deltachi2_filter)], axis=0)\n",
    "eff_unobserved_3 = np.logical_or(unobserved_3, treat_as_unobserved_3)\n",
    "\n",
    "print(f\"There are {len(table['DEC'][galaxy_filter])} galaxy targets in the sample,of which {len(table['DEC'][galaxy_observed_filter])} are observed. Of these, {len(table['DEC'][keep])} are in the bright (<{APP_MAG_CUT} mag) sample and pass our quality of z-fit checks.\")\n",
    "print(f\"Of those, only {len(table['DEC'][keep_3])} are in the 3-pass coverage area.\")\n",
    "print(f\"There are {len(table['DEC'][unobserved_3])} unobserved galaxies in the 3-pass coverage area.\")\n",
    "print(f\"There are also {len(table['DEC'][treat_as_unobserved_3])} bad observed galaxies in the 3pass regionthat we will treat as unobserved, making a combined effective total of {len(table['DEC'][eff_unobserved_3])} 3pass unobserved galaxies.\")\n",
    "\n",
    "obj_type = obj_type[keep_3]\n",
    "dec = dec[keep_3]\n",
    "ra = ra[keep_3]\n",
    "z_obs = z_obs[keep_3]\n",
    "target_id = target_id[keep_3]\n",
    "flux_r = flux_r[keep_3]\n",
    "app_mag = app_mag[keep_3]\n",
    "app_mag_g = app_mag_g[keep_3]\n",
    "#p_obs = p_obs[keep_3]\n",
    "unobserved = unobserved[keep_3]\n",
    "deltachi2 = deltachi2[keep_3]\n",
    "ntiles = ntiles[keep_3]\n",
    "abs_mag_sdss = abs_mag_sdss[keep_3]\n",
    "sdss_g_r = sdss_g_r[keep_3]\n",
    "\n",
    "after_count = len(dec)\n",
    "g_r = app_mag_to_abs_mag(app_mag_g, z_obs) - app_mag_to_abs_mag(app_mag, z_obs) # TODO is this right\n",
    "\n",
    "print(f\"\\nAfter all filters we have {after_count} of the original {before_count} rows.\")\n",
    "\n",
    "#print(\"Frac area after all filters\", estimate_frac_area(ra, dec))\n",
    "#fig=make_map(ra, dec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO why is this not bimodal? \n",
    "# Maybe I don't go to app mags right...\n",
    "junk=plt.hist(g_r, bins=300, alpha=0.5)\n",
    "junk=plt.hist(sdss_g_r, bins=300, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_mag_new = app_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(app_mag_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(app_mag_new, label=\"my abs_mag\", bins=100, alpha=0.5)\n",
    "plt.hist(app_mag_old, label=\"my abs_mag\", bins=100, alpha=0.5)\n",
    "plt.xlabel(\"Apparent Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag1 = abs_mag_sdss\n",
    "mag2 = app_mag_to_abs_mag(get_app_mag(app_mag), z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mag1), len(mag2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Absolute Magnitudes\n",
    "bins = np.linspace(-25, -10, 100)\n",
    "my_counts, my_bins, my_p = plt.hist(mag2, label=\"my abs_mag\", bins=bins, alpha=0.5)\n",
    "alex_counts, alex_bins, alex_p = plt.hist(mag1, label=\"ABSMAG_SDSS_R\", bins=bins, alpha=0.5)\n",
    "plt.xlabel(\"Absolute Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Compare Absolute Mags\")\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "print(f\"The peak is shifted from ABSMAG_SDSS_R {alex_bins[np.argmax(alex_counts)]:.1f} to my {my_bins[np.argmax(my_counts)]:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=make_map(ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=make_map(ra[5], dec[5], alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(obj_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32,8))\n",
    "plt.hist(u_table['TARGET_STATE'])\n",
    "plt.title('Target State')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(z_obs))\n",
    "print(np.max(z_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table['Z_not4clus'].mask[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_table['ZWARN'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(u_table['ZWARN'])\n",
    "plt.title('ZWARN')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(u_table['ZWARN_MTL'])\n",
    "plt.title('ZWARN_MTL')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(z_obs, bins=50)\n",
    "plt.title('Redshift')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p_obs, bins=50)\n",
    "plt.title('Probabilty to Observe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(app_mag, bins=50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(get_app_mag(u_table['FLUX_G']) - get_app_mag(u_table['FLUX_R']) , bins=20)\n",
    "plt.title('g-r')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randoms Analysis for Footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtable = Table.read(RAND_FILE, format='fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in rtable.colnames:\n",
    "    if u_table.colnames.__contains__(c):\n",
    "        print(f\"Column {c} is in both files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dec = rtable['DEC']\n",
    "r_ra = rtable['RA']\n",
    "r_ntiles = rtable['NTILE']\n",
    "\n",
    "RANDOMS_DENSITY = 2500 # per square degree\n",
    "\n",
    "onepass_footprint = len(r_dec) / RANDOMS_DENSITY # in degrees squared\n",
    "onepass_frac_area = onepass_footprint / DEGREES_ON_SPHERE\n",
    "\n",
    "three_pass_filter = r_ntiles >= 3 # 3pass coverage\n",
    "r_dec3 = r_dec[three_pass_filter]\n",
    "r_ra3 = r_ra[three_pass_filter]\n",
    "\n",
    "threepass_footprint = len(r_dec3) / RANDOMS_DENSITY # in degrees squared\n",
    "threepass_frac_area = threepass_footprint / DEGREES_ON_SPHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BGS Y1 1pass Footprint calculated from randoms is {onepass_footprint} square degrees or frac_area={onepass_frac_area}\")\n",
    "print(f\"BGS Y1 3pass Footprint calculated from randoms is {threepass_footprint} square degrees or frac_area={threepass_frac_area}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ian-conda311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
