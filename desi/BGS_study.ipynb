{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as c\n",
    "from astropy.wcs import WCS\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from pyutils import *\n",
    "import astropy.io.fits as fits\n",
    "import healpy as hp\n",
    "from astropy.table import Table,join\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"../bin/\"\n",
    "DATA_FOLDER = '../data/'\n",
    "BGS_PREVIOUS_FOLDER = \"../bin/BGS v1.0/\"\n",
    "OLD_FILE = ROOT_FOLDER + \"BGS_BRIGHT_full.dat.fits\"\n",
    "BGS_ANY_FULL_FILE = ROOT_FOLDER + \"BGS_ANY_full.dat.fits\"\n",
    "RAND_FILE = ROOT_FOLDER + \"BGS_BRIGHT_0_full.ran.fits\"\n",
    "PROB_OBS_FILE = ROOT_FOLDER + \"mainbw-bright-allTiles_v1.fits\"\n",
    "FASTSPEC_FILE = DATA_FOLDER + \"fastspec-iron-main-bright.fits\"\n",
    "IAN_BGS_MERGED_FILE = DATA_FOLDER + \"ian_BGS_merged.fits\"\n",
    "\n",
    "# TODO ensure this is right\n",
    "def get_app_mag(flux):\n",
    "    \"\"\"This converts nanomaggies into Pogson magnitudes\"\"\"\n",
    "    return 22.5 - 2.5*np.log10(flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a merged master BGS data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastspecfit for DN4000\n",
    "hdul = fits.open(FASTSPEC_FILE, memmap=True)\n",
    "#hdul[1].columns\n",
    "data = hdul[1].data\n",
    "fastspecfit_id = data['TARGETID']\n",
    "DN4000 = data['DN4000'] # TODO there is also DN4000_OBS and DN4000_MODEL (and inverse variance)\n",
    "hdul.close()\n",
    "\n",
    "print(len(ids))\n",
    "print(len(DN4000))\n",
    "\n",
    "fastspecfit_table = Table([fastspecfit_id, DN4000], names=('TARGETID', 'DN4000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main file\n",
    "main_table = Table.read(BGS_ANY_FULL_FILE, format='fits')\n",
    "print(len(main_table))\n",
    "# Prob obs file\n",
    "p_table = Table.read(PROB_OBS_FILE, format='fits')\n",
    "print(len(p_table))\n",
    "\n",
    "# Join them all on TARGETID\n",
    "joined_table = join(main_table, p_table, keys=\"TARGETID\")\n",
    "print(len(joined_table))\n",
    "final_table = join(joined_table, fastspecfit_table, keys=\"TARGETID\")\n",
    "print(len(final_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to needed columns only and save\n",
    "final_table.keep_columns(['TARGETID', 'SPECTYPE', 'DEC', 'RA', 'Z_not4clus', 'FLUX_R', 'FLUX_G', 'BITWEIGHTS', 'PROB_OBS', 'ZWARN', 'DELTACHI2', 'NTILE', 'ABSMAG_SDSS_R', 'ABSMAG_SDSS_G', 'DN4000'])\n",
    "final_table.write(IAN_BGS_MERGED_FILE, format='fits')\n",
    "del(main_table)\n",
    "del(p_table)\n",
    "del(fastspecfit_table)\n",
    "del(final_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine data in Merged BGS File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table.read(IAN_BGS_MERGED_FILE, format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(table['Z_not4clus'], bins=50)\n",
    "plt.title(\"Z_not4clus\")\n",
    "plt.yscale('log')\n",
    "print(np.min(table['Z_not4clus']), np.max(table['Z_not4clus']))\n",
    "print(table['Z_not4clus'].mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(table['ZWARN']))\n",
    "#print(np.unique(table['ZWARN_MTL']))\n",
    "print(np.unique(table['SPECTYPE']))\n",
    "print(np.unique(table['NTILE']))\n",
    "#print(np.unique(table['TARGET_STATE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut to the galaxy data we actually need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this gets easilly out of sync with the .py file that does the 'production' filtering\n",
    "\n",
    "APP_MAG_CUT = 19.5\n",
    "Z_MIN = 0.01\n",
    "Z_MAX = 0.8\n",
    "obj_type = table['SPECTYPE'].data.data\n",
    "dec = table['DEC']\n",
    "ra = table['RA']\n",
    "z_obs = table['Z_not4clus'].data.data\n",
    "target_id = table['TARGETID']\n",
    "flux_r = table['FLUX_R']\n",
    "flux_g = table['FLUX_G']\n",
    "app_mag = get_app_mag(table['FLUX_R'])\n",
    "app_mag_g = get_app_mag(table['FLUX_G'])\n",
    "g_r_apparent = app_mag_g - app_mag\n",
    "sdss_g_r = table['ABSMAG_SDSS_G'] - table['ABSMAG_SDSS_R'] \n",
    "#p_obs = table['PROB_OBS'] \n",
    "unobserved = table['ZWARN'] == 999999\n",
    "deltachi2 = table['DELTACHI2'].data.data\n",
    "ntiles = table['NTILE']\n",
    "abs_mag_sdss = table['ABSMAG_SDSS_R']\n",
    "\n",
    "before_count = len(dec)\n",
    "print(before_count, \"objects in FITS file\")\n",
    "\n",
    "# Make filter array (True/False values)\n",
    "galaxy_filter = np.logical_or(obj_type == b'GALAXY', obj_type == b'')\n",
    "galaxy_observed_filter = obj_type == b'GALAXY'\n",
    "app_mag_filter = app_mag < APP_MAG_CUT\n",
    "redshift_filter = z_obs > Z_MIN\n",
    "redshift_hi_filter = z_obs < Z_MAX\n",
    "deltachi2_filter = deltachi2 > 40\n",
    "abs_mag_sdss_filter = abs_mag_sdss < 100\n",
    "\n",
    "keep = np.all([galaxy_observed_filter, app_mag_filter, redshift_filter, redshift_hi_filter, deltachi2_filter, abs_mag_sdss_filter], axis=0)\n",
    "keep_3 = np.all([keep, ntiles >= 3], axis=0)\n",
    "unobserved_3 = np.all([ntiles >= 3, unobserved], axis=0)\n",
    "treat_as_unobserved_3 = np.all([galaxy_observed_filter, app_mag_filter, ntiles >= 3, np.invert(deltachi2_filter)], axis=0)\n",
    "eff_unobserved_3 = np.logical_or(unobserved_3, treat_as_unobserved_3)\n",
    "\n",
    "print(f\"There are {len(table['DEC'][galaxy_filter])} galaxy targets in the sample,of which {len(table['DEC'][galaxy_observed_filter])} are observed. Of these, {len(table['DEC'][keep])} are in the bright (<{APP_MAG_CUT} mag) sample and pass our quality of z-fit checks.\")\n",
    "print(f\"Of those, only {len(table['DEC'][keep_3])} are in the 3-pass coverage area.\")\n",
    "print(f\"There are {len(table['DEC'][unobserved_3])} unobserved galaxies in the 3-pass coverage area.\")\n",
    "print(f\"There are also {len(table['DEC'][treat_as_unobserved_3])} bad observed galaxies in the 3pass regionthat we will treat as unobserved, making a combined effective total of {len(table['DEC'][eff_unobserved_3])} 3pass unobserved galaxies.\")\n",
    "\n",
    "obj_type = obj_type[keep_3]\n",
    "dec = dec[keep_3]\n",
    "ra = ra[keep_3]\n",
    "z_obs = z_obs[keep_3]\n",
    "target_id = target_id[keep_3]\n",
    "flux_r = flux_r[keep_3]\n",
    "app_mag = app_mag[keep_3]\n",
    "app_mag_g = app_mag_g[keep_3]\n",
    "g_r_apparent = g_r_apparent[keep_3]\n",
    "#p_obs = p_obs[keep_3]\n",
    "unobserved = unobserved[keep_3]\n",
    "deltachi2 = deltachi2[keep_3]\n",
    "ntiles = ntiles[keep_3]\n",
    "abs_mag_sdss = abs_mag_sdss[keep_3]\n",
    "sdss_g_r = sdss_g_r[keep_3]\n",
    "\n",
    "after_count = len(dec)\n",
    "\n",
    "print(f\"\\nAfter all filters we have {after_count} of the original {before_count} rows.\")\n",
    "\n",
    "#print(\"Frac area after all filters\", estimate_frac_area(ra, dec))\n",
    "#fig=make_map(ra, dec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Analysis\n",
    "\n",
    "Lesson from this analysis: the BGS data, workign with my 0.1^G-R with GAMA k-corrections, does not distribute a per logLgal bin G-R; the global 0.76 split seems to work for all bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = app_mag_to_abs_mag(app_mag_g, z_obs)\n",
    "R = app_mag_to_abs_mag(app_mag, z_obs)\n",
    "\n",
    "G_R = G - R\n",
    "\n",
    "Gk = k_correct(G, z_obs, g_r_apparent, band='g')\n",
    "Rk = k_correct(R, z_obs, g_r_apparent, band='r')\n",
    "\n",
    "G_R_k = Gk - Rk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of g-r computed a few ways\n",
    "junk=plt.hist(g_r_apparent, bins=300, alpha=0.5, label=\"g-r\")\n",
    "junk=plt.hist(sdss_g_r, bins=300, alpha=0.5, label='From LSS Pipeline')\n",
    "junk=plt.hist(G_R, bins=300, alpha=0.5, label=\"G-R\")\n",
    "junk=plt.hist(G_R_k, bins=300, alpha=0.5, label=\"0.1^(G-R) GAMA-style\")\n",
    "plt.legend()\n",
    "plt.xlim(0.0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can see global GLOBAL_RED_COLOR_CUT=0.76 here\n",
    "junk=plt.hist(G_R_k, bins=300, alpha=0.5, label=\"0.1^(G-R) GAMA-style\")\n",
    "plt.legend()\n",
    "plt.xlim(0.5, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyutils import *\n",
    "print(BGS_LOGLGAL_BINS)\n",
    "print(BINWISE_RED_COLOR_CUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_quiescent_BGS_gmr(np.array([5.8, 9.0, 14.5]), np.array([0.5, 0.9, 0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logLgal bins\n",
    "log_L_gal = abs_mag_r_to_log_solar_L(Rk) \n",
    "logLgal_bin_idx = np.digitize(log_L_gal, BGS_LOGLGAL_BINS)\n",
    "# 0 is less than the lowest, len(BGS_LOGLGAL_BINS) is greater than the highest entry in BGS_LOGLGAL_BINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(log_L_gal))\n",
    "print(np.max(log_L_gal))\n",
    "print(np.min(logLgal_bin_idx))\n",
    "print(np.max(logLgal_bin_idx))\n",
    "plt.hist(log_L_gal, bins=BGS_LOGLGAL_BINS, align='mid')\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot of G_R_k in each logLgal bin\n",
    "for i in range(0, len(BGS_LOGLGAL_BINS)+1):\n",
    "    galaxy_idx_for_this_bin = logLgal_bin_idx == i\n",
    "\n",
    "    plt.figure(dpi=120, figsize=(10, 6))\n",
    "    junk=plt.hist(G_R_k[galaxy_idx_for_this_bin], bins=np.arange(0,1.3,0.02), label=f\"0.1^(G-R) Bin {i}\", align='mid')\n",
    "    plt.legend()\n",
    "    plt.xlim(0.4, 1.2)\n",
    "    plt.xticks(np.arange(0.4, 1.2, 0.04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag1 = abs_mag_sdss\n",
    "mag2 = app_mag_to_abs_mag(get_app_mag(app_mag), z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Absolute Magnitudes\n",
    "bins = np.linspace(-25, -10, 100)\n",
    "my_counts, my_bins, my_p = plt.hist(mag2, label=\"my abs_mag\", bins=bins, alpha=0.5)\n",
    "alex_counts, alex_bins, alex_p = plt.hist(mag1, label=\"ABSMAG_SDSS_R\", bins=bins, alpha=0.5)\n",
    "plt.xlabel(\"Absolute Mag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Compare Absolute Mags\")\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "print(f\"The peak is shifted from ABSMAG_SDSS_R {alex_bins[np.argmax(alex_counts)]:.1f} to my {my_bins[np.argmax(my_counts)]:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=make_map(ra, dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randoms Analysis for Footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtable = Table.read(RAND_FILE, format='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dec = rtable['DEC']\n",
    "r_ra = rtable['RA']\n",
    "r_ntiles = rtable['NTILE']\n",
    "\n",
    "RANDOMS_DENSITY = 2500 # per square degree, Ashley Ross paper on LSS pipeline or elsewhere in docs\n",
    "\n",
    "onepass_footprint = len(r_dec) / RANDOMS_DENSITY # in degrees squared\n",
    "onepass_frac_area = onepass_footprint / DEGREES_ON_SPHERE\n",
    "\n",
    "three_pass_filter = r_ntiles >= 3 # 3pass coverage\n",
    "r_dec3 = r_dec[three_pass_filter]\n",
    "r_ra3 = r_ra[three_pass_filter]\n",
    "\n",
    "threepass_footprint = len(r_dec3) / RANDOMS_DENSITY # in degrees squared\n",
    "threepass_frac_area = threepass_footprint / DEGREES_ON_SPHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BGS Y1 1pass Footprint calculated from randoms is {onepass_footprint} square degrees or frac_area={onepass_frac_area}\")\n",
    "print(f\"BGS Y1 3pass Footprint calculated from randoms is {threepass_footprint} square degrees or frac_area={threepass_frac_area}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Healpix Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGS_N = hp.read_map(ROOT_FOLDER + 'BGS_BRIGHT_mapprops_healpix_nested_nside256_N.fits')\n",
    "BGS_S = hp.read_map(ROOT_FOLDER + 'BGS_BRIGHT_mapprops_healpix_nested_nside256_S.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(\n",
    "    BGS_N,\n",
    "    coord=[\"G\", \"E\"],\n",
    "    title=\"Histogram equalized Ecliptic\",\n",
    "    unit=\"Galaxies\",\n",
    "    norm=\"hist\",\n",
    "    min=0,\n",
    "    max=1,\n",
    ")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(\n",
    "    BGS_S,\n",
    "    coord=[\"G\", \"E\"],\n",
    "    title=\"Histogram equalized Ecliptic\",\n",
    "    unit=\"Galaxies\",\n",
    "    norm=\"hist\",\n",
    "    min=0,\n",
    "    max=1,\n",
    ")\n",
    "hp.graticule()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ian-conda311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
